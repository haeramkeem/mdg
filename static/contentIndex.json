{"index":{"title":"매디쏜 디지딸 갈든","links":["os.fall.2022.cse.ewha.ac.kr/(이화여대)-운영체제-강의록","os.spring.2021.cse.cnu.ac.kr/(충남대)-운영체제-강의록","pl.spring.2021.cse.cnu.ac.kr/(충남대)-프로그래밍-언어-개론-강의록"],"tags":[],"content":"\n    \n        \n    \n\n오리지날 씨리즈 §\n\n\n                  \n                  &quot;오리지날 씨리즈&quot; 는 Networked-thought 에 포함되지 않는, 강의 필기록과 같은 Sequential 한 문서를 모아놓는 항목입니다. \n                  \n                \n\n이화여대 온라인 강의 §\n\n(이화여대) 운영체제 강의록\n\n충남대 컴퓨터공학과 학부 강의 §\n\n(충남대) 운영체제 강의록\n(충남대) 프로그래밍 언어 개론 강의록\n"},"os.fall.2022.cse.ewha.ac.kr/(이화여대)-운영체제-강의록":{"title":"(이화여대) 운영체제 강의록","links":["os.fall.2022.cse.ewha.ac.kr/1.-운영체제란","os.fall.2022.cse.ewha.ac.kr/2.-System-Structure-&-Process-Execution","os.fall.2022.cse.ewha.ac.kr/3.-Process","os.fall.2022.cse.ewha.ac.kr/4.-Process-Management","os.fall.2022.cse.ewha.ac.kr/5.-CPU-Scheduling","os.fall.2022.cse.ewha.ac.kr/6.-Process-Synchronize","os.fall.2022.cse.ewha.ac.kr/7.-Deadlocks","os.fall.2022.cse.ewha.ac.kr/8-1.-Memory-Address","os.fall.2022.cse.ewha.ac.kr/8-2.-Physical-Memory-Allocation","os.fall.2022.cse.ewha.ac.kr/9.-Virtual-Memory","os.fall.2022.cse.ewha.ac.kr/10.-File-Systems","os.fall.2022.cse.ewha.ac.kr/11.-Disk-Scheduling"],"tags":[],"content":"Table of Contents §\n\n1. 운영체제란\n2. System Structure &amp; Process Execution\n3. Process\n4. Process Management\n5. CPU Scheduling\n6. Process Synchronize\n7. Deadlocks\n8-1. Memory Address\n8-2. Physical Memory Allocation\n9. Virtual Memory\n10. File Systems\n11. Disk Scheduling\n"},"os.fall.2022.cse.ewha.ac.kr/1.-운영체제란":{"title":"1. 운영체제란","links":[],"tags":[],"content":"운영체제 핵심 §\n\n\n운영체제의 핵심은 컴퓨터의 하드웨어 바로 위에 설치되어 아래로는 하드웨어 자원을 관리하고 위로는 사용자 혹은 사용자 애플리케이션을 위한 편의 기능을 제공하는 것이다.\n\n그래서 그 편의기능이 뭐냐\n사용자로 하여금 내가 실행시킨 프로그램만 실행되고 있게 느끼도록 해주고\n하드웨어를 제어하는 복잡한 작업을 대행하기 때문에 하드웨어에 대한 부분은 사용자가 고려하지 않아도 되게끔 해준다.\n\n\n자원 분배를 할때는 분배의 형평성과 효율성 (주어진 자원 내에서의 최고의 성능) 이 Trade-off 관계에 있게 되는데 운영체제는 이 둘을 적절하게 타협해서 분배를 한댄다\n\n뭐 예를들면 CPU 스케줄링할때 중요한 프로세스에다만 몰빵하면 중요하지 않은 프로세스는 CPU할당을 받지 못하게 되는 이러한 Trade-off\n\n\n\n운영체제, 커널 §\n\n커널은 운영체제의 핵심적인 부분으로 메모리에 항상 상주한다.\n따라서 좁은 의미의 운영체제는 커널만을 칭하고 (협의의 운영체제) 넓은의미에서는 커널 뿐 아니라 주변의 다른 시스템 유틸리티까지 포함한다 (광의의 운영체제).\n\n운영체제의 분류 §\n동시 작업 가능 여부 §\n\nSingle tasking: 한번에 하나의 작업만 처리\n\n일례로 MS-DOS 의 경우에는 한번에 하나의 작업만 처리할 수 있어 명령을 끝내기 전에 다른 명령을 실행시킬 수 없다\n\n\nMulti tasking: 한번에 여러개의 작업 처리\n\n사용자의 수 §\n\nSingle user: 머신을 한 번에 한 명의 사용자만 사용할 수 있는 운영체제\nMulti user: 머신을 한번에 여러명의 사용자가 (원격) 접속하여 사용할 수 있는 운영체제\n\n따라서 Multi user 를 위해서는 사용자 간의 격리를 위한 보안성이나 자원 할당 등의 부가적인 기능이 필요하다.\n\n\n\n작업 처리 형태 §\n\nBatch processing: 이건 작업을 바로 처리하는 것이 아니라 일정량 모아서 한번에 처리하는 형태\n\n따라서 작업을 요청하면 다른 작업이 일정량 모인 후에 실행되고 결과가 나올때 까지 기다려야 했다.\n지금은 거의 안쓰고 옛날 Punch card 같은 처리 시스템에서 많이 쓰였음\n\n\nTime sharing: CPU time을 잘게 쪼개 여러 프로세스를 돌아가며 실행시키는 형태\n\n뭐 지금의 운영체제가 다 그렇지 뭐\n다만 이건 시간상의 제약이 있지는 않다 → 시간을 쪼개 작업을 처리하지만 해당 시간 내에 끝내는 것을 목표로 하지는 않음\n\n\nReal time: 작업의 deadline이 있어 해당 deadline 전까지 작업을 끝마치도록 하는 형태\n\n시간이 중요한 시스템들 (뭐 원자력 제어 시스템이나 미사일 등) 을 위한 시스템\n시간 내에 끝나지 않았을때 진짜 ㅈ되는 것을 위한 것이 Hard realtime system 이고\n시간 내에 끝내야 하긴 하지만 ㅈ되지는 않는것 (뭐 동영상 스트리밍의 경우에는 1초에 24프레임을 불러와야 하니까) 을 위한 게 Soft realtime system 이라고 부르더라\n\n\n\nMulti-어쩌고 §\n\n프로세스를 병렬적으로 처리하는데에는 다음과같은 용어들이 있는데 어느정도는 구분할 수 있어야 한다\n\nMultitasking: 가장 범용적인 (범위가 큰) 용어 → 걍 프로세스가 여러개 작동될 수 있어 하나가 끝나기 전에 다른 하나가 실행될 수 있는 것\nMultiprogramming: 프로세스 여러개가 하나의 메모리에 적재될 수 있는 것\n\n뭐 당연히 Multitasking 을 위해서는 Multiprogramming 이 되어야 하고 어느정도는 Multitasking과 의미가 겹치지만 얘는 약간 메모리 측면을 강조한 용어라고 할 수 있다.\n\n\nTime sharing: 프로세스 여러개가 CPU time을 돌아가며 할당받는 것\n\n이것도 Multitasking 과 개념이 좀 겹치지만 얘는 CPU time을 강조한 용어라고 할 수 있다\n\n\nMultiprocess: 얘는 진짜 Multitasking과 차이가 없는거같은데\nMultiprocessor: 얘는 CPU가 여러개 달린 하드웨어적인 용어이다\n\n일반적으로 Multitasking 이라 할때는 싱글프로세서를 의미한다.\n\n\n\n\n\n운영체제의 구조 §\n\n\nCPU 스케줄링: CPU time 을 언제 누구에게 줄까?\n\n선입선출? 가장 빨리 끝나는 놈부터?\n\n\n메모리 관리: 메모리를 어떤 방식 프로세스들에게 할당해줄까?\n\n메모리를 어떻게 쪼개서 프로세스에게 할당할까?\n만일 메모리가 부족한 경우에 누군가를 디스크로 내보내야 한다면 누구를 내보낼까?\n\n\n파일 관리: 파일들을 디스크에 어떻게 저장해서 어떻게 읽을까?\n\n하나의 덩어리로 저장? 잘라서 저장?\n읽을때는 들어온 요청의 순서대로? 아니면 디스크 헤드랑 가장 자까이 있는 놈부터?\n\n\n입출력 관리: 속도도 느리고 제각각인 입출력장치랑 어떻게 상호작용할까?\n\nInterrupt 방식을 사용 → I/O 작업을 CPU가 계속 신경쓰는 게 아닌 작업이 끝났을 때 인터럽트를 걸어서 그때서야 CPU가 신경쓰도록 하는 방식\n\n\n"},"os.fall.2022.cse.ewha.ac.kr/10.-File-Systems":{"title":"10. File Systems","links":[],"tags":[],"content":"File 이란? §\n\n이름을 통해 접근할 수 있는 정보들의 집합 을 File 이라고 하더라\n일반적으로 너가 아는 것들 이외에도\nLinux 에서는 다양한 장치들도 File 로써 관리된다 → 표준입출력이나 디스크들도 Linux 에서는 파일로 관리된다\n그리고 당연히 디스크같은 비휘발성 저장장치에 저장된다\n\nFile Operation §\n\nCreate, Delete\nOpen, Close\n\n파일의 Metadata 를 메모리에 적재하는 것을 Open\n메모리에서 내려 다시 디스크에 저장하는 것은 Close 라고 한다.\n파일을 읽거나 쓰기 위해서는 반드시 Open 되어있어야 하고 작업이 끝난 이후에는 Close 를 해야 한다.\n\n\nRead, Write\nReposition (lseek)\n\n파일입출력할때 생각해보면 포인터 (커서) 가 있어서 어디까지 읽었는지를 기억하자네\n이 포인터 (커서) 의 위치를 딴데로 옮기는 연산을 Reposition (lseek) 이라 한다.\n\n\n\nFile Metadata (Attribute) §\n\n이름에서 유추할 수 있듯이\n파일 자체의 내용이 아니고 파일의 유형, 크기, 권한 등의 파일을 설명하는 정보들을 File Metadata 혹은 File Attribute 라고 한다\n\nFile System §\n\nFile System 은 당연히 운영체제에서 파일을 관리하는 부분을 의미한다.\n이놈은 파일, Metadata, 디렉토리 계층구조, 저장 방법이나 보안성 부분을 관리한댄다\n\nDirectory, Partition §\n\nDirectory 는 뭐 너가 아는 그 폴더가 맞는데\n\n좀 더 정확하게 정의해보면 거기에 속한 파일들의 메타데이터 전부 혹은 일부를 내용으로 갖고 있는 파일을 Directory 라고 한다\n\n\nPartition 혹은 Logical Disk 는 하드웨어 디스크가 아닌 하드웨어 디스크를 쪼개서 논리적으로 여러개의 디스크를 사용하는 것과 같은 효과를 내게 하는 것을 의미한다\n\n이렇게 파티션을 나눠서 File System 을 설치하거나 Swap area 를 마련하는 등으로 활용한다.\n\n\n\nFile Open Operation §\n\n위에서 잠깐 봤지만 좀 더 깊게 드가보자고\n\n\n\n사용자 프로세스는 /a/b 경로의 파일을 열기 위해 open 시스템 콜을 한다 → 당연히 IO 작업이니까 직접 하지는 못하고 시스템 콜을 사용해야 한다\nFile System 이 Root (/) 에서부터 재귀적으로 파일의 위치를 찾아나가기 시작한다\n\nRoot 디렉토리의 위치는 File System 이 알고 있기 때문에 일단 이놈을 open 한다\nOpen 하게 되면 그놈의 메타데이터가 메모리에 올라가게 되는데, 메모리의 커널 영역 중 Open File Table 이라는 곳에 올라가게 된다\n\nOpen File Table 은 시스템 전체에 대해 열려있는 파일의 메타데이터가 테이블 형식으로 저장되어 있는 메모리의 커널 영역 중 한 부분이다\n\n\nRoot 의 메타데이터를 통해 Root Directory 의 Content 위치를 찾아내게 되고, 여기에는 하위 파일들의 메타데이터가 저장되어 있기 때문에 a 의 메타데이터를 찾아서 마찬가지로 Open File Table 에 올린다 (Open 한다)\nOpen → Content Reference 작업을 반복적으로 수행한다.\n\n즉, a 의 메타데이터를 이용해 a 의 Content 에 접근하고, 여기에서 b 의 메타데이터를 찾아 Open File Table 로 올리며 그것을 이용해 b 의 Content 에 접근한다.\n\n\n\n\n경로의 파일에 접근했다면, 해당 파일의 Content 를 메모리의 커널 영역에 올린다\n\n이 때에는 Open File Table 에 올리는 것이 아니라 열려있는 파일의 내용을 캐싱하는 Buffered Cache 에 올리게 된다\n이렇게 함으로써 프로세스는 디스크가 아닌 메모리에 캐싱되어있는 데이터에 접근하기 때문에 더욱 빠르게 데이터를 읽어올 수 있고\n여러개의 프로세스가 해당 파일을 Open 했을 때에도 디스크 IO 작업이 여러번 일어나는 것이 아니고 캐싱되어있는 데이터가 제공된다 → 즉, 파일을 Open 할 때에는 일단 해당 파일이 Buffered Cache 에 존재하는지 먼저 확인하고 없다면 그때서야 디스크 IO 작업이 이루어진다\n\n\n커널 영역에 올라가 있는 파일 Content 를 사용자 프로세스 영역으로 복사해 그놈이 접근할 수 있게 한다.\n요청한 파일의 File Descriptor 를 반환함으로써 Open 시스템 콜이 완료된다.\n\n옛날에는 File Descriptor 개념이 쬐까 헷갈렸는데 지금 딱 정리해준다\n일단 파일을 Open 했으면 해당 파일의 메타데이터가 Open File Table 에 저장되어 있겠지\n그럼 Open File Table 에 저장되어 있는 메타데이터의 주소를 PCB 에 존재하는 배열중 하나인 File Descriptor Table 에 넣는다\n\n즉, File Descriptor Table 은 해당 프로세스가 Open 한 파일의 Open File Table 내에서의 메타데이터 주소들을 담는 배열이다\n\n\n이때, File Descriptor Table 내에서의 해당 파일에 대한 인덱스 번호를 File Descriptor 라고 하는 것이다\n뭐 옛날에 배운 것 처럼 File Descriptor 0번은 표준 입력, 1번은 표준 출력, 2번은 표준 에러이다 → 프로세스가 실행되면 저 세 파일은 자동으로 열린다는 소리이다\n\n\n\n\n등장한 Table 들을 좀 비교해보면\n\nOpen File Table: 시스템 전체에 대해 열려 있는 파일들에 대한 Table\nFile Descriptor: 프로세스 하나에 대해 그놈이 열어놓은 파일들에 대한 Table\n\n\nFile Offset Table: 이건 파일 하나를 여러 프로세스가 열었을 때 각각 어디를 읽고 있는지가 다를 것이기 때문에 각 프로세스들이 어디를 읽고 있는지를 보관하는 테이블이다\n\nFile Protection §\nAccess Control Matrix §\n\n\nAccess Control Matrix 는 단순하게 어떤 사용자가 어떤 파일에 대해 권한이 있는지를 Matrix 형태로 저장해 놓은 것이다\n하지만 이 방법은 다소 비효율적이다 → 특정 사용자가 권한을 갖고 있는 파일은 한정적이기 때문에 쓸데없는 용량을 많이 차지하기 때문\n따라서 이것을 행 혹은 열 방향으로 Linked List 형태로 관리하기도 한다\n\n특정 사용자가 접근할 수 있는 파일들을 모아놓은 것을 Capability 라고 하고\n특정 파일에 대해 접근할 수 있는 사용자들을 모아놓은 것을 ACL (Access Control List) 라고 한다\n\n\n\nGrouping §\n\n\n하지만 ACM 을 이용하는 방법도 그다지 효율적이지 않다\n따라서 Linux 같은 UNIX 기반의 시스템들은 Grouping 방식을 이용해 접근 권한을 관리한다\n즉, 파일 소유주 (Owner), 일련의 사용자 집합인 그룹 (Group), 모든 사용자 (Public)에 대한 접근 권한을 각각 3비트로 표현하게 된다\n\n뭔지 알제?\n3비트에 대해 첫 1비트는 Read 권한 유무, 두번째 1비트는 Write 권한 유무, 세번째 1비트는 Execute 권한 유무를 뜻한다\n\n\n이렇게 되면 파일의 권한을 단순히 9비트로 표현할 수 있게 되고, 파일 소유주가 아닌 사용자에 대한 권한은 해당 사용자를 그룹에 포함시키거나 Public 권한을 조정함으로써 간편하게 관리할 수 있다\n\nPassword §\n\n뭐 이건 많이 사용되는 방법은 아니고\n특정 파일이나 디렉토리에 암호를 걸어 암호를 맞춰야만 접근할 수 있게 하는 방법이다\n\nMounting §\n\n\n특정 디스크 (파티션)에 대한 접근은 Root 를 통해 할 수 있지만\n다른 디스크 (파티션)에 대한 접근은 특정 디렉토리를 해당 디스크의 루트를 가리키도록 하여 수행할 수 있다 → 이 방법을 Mounting 이라고 하더라\n\nFile Content Access Method §\nSequential Access §\n\nSequential Access (순차 접근) 은 이름에서부터 알 수 있듯이 파일의 내용을 앞에서부터만 순차적으로 읽을 수 있는 방법이다\n즉, ABC 에서 A와 C에 접근하기 위해서는 B 에 무조건 접근해야 한다\n카세트 테이프같은 경우가 이렇다 → 무적권 앞에서부터만 접근해야 되는 놈\n\nDirect Access (Random Access) §\n\nDirect Access (Random Access, 직접 접근) 은 반대로 파일의 내용을 임의의 순서로 접근할 수 있는 방법을 의미한다\n즉, ABC 에서 A에 접근한 이후에 바로 C를 접근하는 것이 가능하다\n이것은 하드웨어적 서포트가 필요하고 그러한 서포트가 있어도 데이터들을 어떻게 저장하냐 따라 순차접근을 해야 할 수도 있다네\n뭐 디스크나 CD, 플래시 메모리 등이 다 지원한다\n\nDisk Allocation Methods §\n\n일단 몇가지 개념들\n\nBlock (블럭) 혹은 Sector (섹터): 디스크에 데이터를 저장하는 단위\n\n\n\nContiguous Allocation §\n\n\n말그대로 파일 하나를 디스크에 연속적으로 저장하는 방법\n장점:\n\n디스크에서 데이터의 위치를 찾은 다음에는 쭉 읽어들이면 되기 때문에 IO 가 빠르다\n\n만약 데이터들이 산발적으로 저장되어 있다면 그들을 모두 찾아야되지만 뭉쳐져있기 때문에 한번만 찾으면 됨\n따라서 IO 속도가 중요한 Realtime File 이나 Process Swapping 등에서 사용될 수 있다\n\n\n데이터가 시작위치부터 연속적으로 존재하기 때문에 Random Access 가 가능하다\n\n시작위치에서 Offset 만 알면 바로 원하는 부분을 찾을 수 있기 때문\n\n\n\n\n단점:\n\n메모리 관리때와 마찬가지로 Hole (혹은 External Fragmentation) 이 발생할 수 있다\n\n파일의 크기와 딱 맞는 공간이 없을 수도 있으므로 남은 만큼은 외부 조각으로 남는 셈\n\n\n파일 사이즈를 키우기 힘들다\n\n파일 하나가 연속적으로 저장되어야 하는데 뒤에 다른 데이터가 존재한다면 파일 사이즈를 키우기 위해서는 뒤에 있는 놈을 재배치하거나 사이즈 키우는 것을 포기해야 한다\n늘어날 수 있는 공간만큼 미리 공간을 선점하게 할 수 있지만 그렇다 하더라고 늘어날 수 있는 파일의 크기는 한정되어 있고 선점된 공간은 Internal Fragmentation 으로 남게 된다\n\n\n\n\n\nLinked Allocation §\n\n\n말 그대로 Linked List 마냥 데이터들을 연결지어놓은 것\n장점:\n\nExternal Fragmentation 이 없다\n\n\n단점:\n\nRandom Access 가 안된다\n\n어떤 특정 섹터에 접근하기 위해서는 무적권 그놈 앞에 있는 섹터들을 모두 방문해야 한다\n\n\nReliability 문제\n\n포인터를 통해 쭉 연결되어있는데 중간에 하나의 섹터에 문제가 생겨서 (Bad Sector) 포인터가 유실되면 그놈 다음에 있는 모든 섹터에 접근할 수 없다\n\n\n공간 효율성 문제\n\n일단 하나의 섹터에 무조건 다음 섹터를 위한 포인터를 저장할 공간이 마련되어야 하고\n일반적으로 섹터 하나는 512 바이트로 구성되어 있는데 이 중 4 바이트가 포인터를 위한 공간으로 사용되어 508 바이트라는 애매한 숫자가 된다 → 알다시피 대부분의 데이터 포맷은 2의 배수 크기를 가지도록 정의되어있는 것이 많은데 512 가 아닌 508 로 하면 좀 애매하다는 얘기인듯\n\n\n\n\n단점 보완\n\n이 방식을 보완한 FAT (File Allocation Table) 파일시스템은 포인터들을 별도의 공간에 모아서 관리하기 때문에 Reliability 와 공간 효율성 문제를 해결한다\n하지만 알다시피 파일의 크기가 커지면 테이블의 크기도 너무 커지므로 FAT 으로 구성할 수 있는 파일의 크기는 한정되어 있다\n\n\n\nIndexed Allocation §\n\n\n이것은 파일이 저장되어 있는 섹터들의 번호 (인덱스) 를 모아놓은 별도의 블럭을 하나 구성하는 방법이다\nFAT 랑 솔직히 뭐가 다른지 잘 모르겠음\n장점\n\n연속적으로 저장하는 것이 아니기 때문에 External Fragmentation 이 발생하지 않는다\n인덱스 블럭을 통해 특정 섹터에 바로 접근할 수 있기 때문에 Random Access 도 가능하다\n\n\n단점\n\n파일 크기가 너무 작은 경우에는 비효율적이다\n\n파일의 크기가 512 Byte 보다 작을 경우에도 최소한 데이터 섹터 하나랑 인덱스 블럭 두개가 필요하다\n\n\n파일의 크기가 너무 커도 문제다\n\n파일의 크기가 너무 커서 하나의 인덱스 블럭에 다 안들어갈 수도 있기 때문\n이때는 인덱스 블럭의 마지막은 다음 인덱스 블럭을 가리키게 하는 방법 (Linked Scheme) 을 이용하던지\n인덱스 블럭을 계층적으로 구성하는 방법 → 인덱스 테이블이 다른 인덱스 테이블들을 가리키게 하는 방법 (Multi-level Index) 를 이용할 수 있다\n\n\n\n\n\nUNIX File System §\n\nBoot Block §\n\nBoot Block: 얘는 UNIX 만의 특징이 아니고 모든 파일 시스템이 파티션 맨 앞에 Boot Block 을 둔다\n\nBoot Loader (Bootstrap Loader) 는 말그대로 컴퓨터가 부팅될때 OS 가 디스크의 어디에 저장되어 있고 어떻게 시스템을 초기화해야할지 등을 알려주는 부분이다\n뭐 요즘 Linux 배포판에는 GRUB 가 부트로더로 내장되어있제\n\n\n\nSuper Block §\n\nSuper Block: 얘는 파티션 전체에 대한 메타데이터라고 생각하면 된다\n\n즉, 어디서부터 어디까지 어떤 정보가 저장되어 있고 (가령 여기부터 여기까지는 Inode List 이다 등)\n비어있는 섹션은 어디이고 사용중인 섹션은 어디인지 등의 정보를 저장함\n\n\n\nInode, Inode List Block §\n\nUNIX 에서 Inode 의 개념은 중요하니까 좀 자세하게 알아보자고\n일단 UNIX 에서 파일의 메타데이터를 어떻게 관리하는지 알아보면\n파일의 이름을 제외한 모든 메타데이터를 Inode 라는 단위로 저장한다\n\n\n\nInode 의 구조는 위와 같다\n\n일단 Mode 부터 Count 까지는 뭐 그냥 파일들의 메타데이터들이고 그 다음부터가 중요한데\nUNIX 는 위에 소개한 Allocation Method 중에서 Indexed Allocation 을 변형한 방법을 사용한다\n그래서 Direct Blocks 부분에 데이터 섹션들의 인덱스를 저장하게 되는데\n파일의 크기가 클 경우를 대비해 3단계까지 Multi-level Index 를 제공한다\n\n즉, Single Indirect 는 인덱스 블럭을 한번 더 거쳐야 데이터가 나오고 Double Indirect 는 두번 더 거쳐야 데이터가 나오며 Triple Indirect 는 세번 더 거쳐야 되는 식\n\n\n\n\n그러면 파일의 이름은 어디에 저장하느냐 → 디렉토리의 내용에 저장된다\n\n즉, 디렉토리는 하위 파일들에 대해 이름과 Inode 번호 두가지를 저장한다\n\n\n\n\n\n이러한 Inode 들이 모두 저장되어 있는 파티션의 한 부분을 Inode List 라고 부른다\n\n헷갈리지 마라 → 파일의 메타데이터는 파일과 함께 저장되어 있는 것이 아니고 별도의 공간에 함께 모여서 관리된다\n\n\n\n(MS) FAT File System §\n\n\n위에서도 언급했듯이 FAT 파일 시스템은 Linked Allocation 의 단점들을 개선한 것이다\nUNIX 와 대조되는 차이점들에 대해 살펴보면\n\n일단 UNIX 와는 다르게 거의 모든 메타데이터가 Directory 에 저장된다\n\nDirectory 에는 추가적으로 파일의 첫 블럭의 포인터가 적혀 있어 파일이 어디서부터 시작되는지 알 수 있게 해놓았다\n\n\nFAT 부분에는 각 파일들의 FAT 정보가 저장되어 있는데, 이 테이블에는 파일을 구성하는 각 블럭들에 대해 다음 블럭의 포인터가 저장되어 있다\n\n마지막 블럭에 대한 엔트리에는 EOF 값이 들어가 있어 더이상 블럭이 없음을 나타낸다\n\n\n\n\n그래서 FAT 파일시스템의 작동 원리에 대해 대략적으로 보면\n\nDirectory 에 적혀있는 포인터를 통해 파일을 읽어나가기 시작한다\n하나의 블럭을 다 읽었다면, FAT 을 보고 다음 블럭의 포인터가 어디를 가리키는지 확인한다.\n위의 과정을 EOF 가 등장할 때 까지 반복한다\n\n\n이렇게 하면 Linked Allocation 이 가지는 단점들을 모두 해소할 수 있다\n\nRandom Access 문제\n\n파일이 열린 다음에는 FAT 이 메모리로 올라오게 되는데\n포인터를 따라갈 때 데이터 블럭을 모두 뒤지는 것이 아니라 메모리 내에 있는 FAT 내부에서만 움직이므로 데이터 블럭에 접근할 필요가 없어 훨씬 빠른 시간에 접근이 가능하다\n\n\nReliability 문제\n\n일단 포인터가 FAT 에 저장되므로 Bad Section 이 일어나도 이후의 데이터에 접근이 가능하고\n고가용성을 위해 FAT 의 복제본을 여러개 유지하기 때문에 FAT 이 망가져도 복구가 가능하다\n\n\n공간 효율성 문제\n\n포인터가 FAT 에 저장되므로 데이터 섹션의 512 바이트 중 일부를 할애할 필요가 없다\n\n\n\n\n\nFree Space Management §\nBitmap (Bit Vector) §\n\n\n뭐 이건 간단하쥬?\n블럭의 크기만큼 비트를 마련한 다음에 해당 블럭이 비었는지 아닌지를 0과 1로 표현하는 방법\n당연히 Bitmap 을 마련해야 하기 때문에 추가적인 디스크 공간이 필요하지만\nContiguous Allocation 이 아니어도 연속적인 Free Space 에 저장하는 것이 IO 에 도움이 되므로 연속적인 Free Space 를 찾을 때 효과적인 방법이다\n\nLinked List §\n\n이건 Free Block 들에 다음 Free Block 의 포인터를 저장해서 링크드 리스트 형식으로 묶어놓은 것인데\n추가적인 디스크 공간이 필요 없다는 점에서는 좋지만\n각각의 블럭들을 모두 방문해야 하기 때문에 연속적인 Free Space 를 찾는 것은 오래걸린다\n\nGrouping §\n\n\n이건 Multi-level indexed 랑 유사한 방법인데\nFree Block 하나에 n - 1 개의 Free Block 포인터를 저장하고 마지막 에는 다음 Free Block Table 을 가리키게 하는 방법이다\n근데 특징은 Linked List 와 유사함 → 추가 공간은 필요없지만 결국 연속적인 Free Space 를 찾는 것은 쉽지 않다\n\nCounting §\n\n이건 연속적인 Free Block 을 쉽게 찾아내기 위해 고안된 방법인데\n일반적으로 Block 이 반납될때는 연속적인 블럭을 반환한다는 성질에서 착안한 방법이다\n따라서 연속적인 Free Block 에 대해 시작 Block 의 포인터와 몇개가 연속되어있는지의 개수를 저장한다\n\nDirectory Implementation §\nDirectory Contents §\n\nLinear List: 디렉토리 아래에 위치한 파일들을 리스트 형태로 저장하는 것\n\n\n\n위에서 보다시피 struct{FNAME, METADATA} 형식의 리스트로 구현한다\n\n당연히 구현이 간편하지만\n파일이 존재하는지 알기 위해서는 선형 탐색을 해야 한다는 단점이 있다\n\n\n\n\nHash Table: 이것은 List 의 인덱스를 결정할때 마지막 인덱스가 아닌 해시 함수를 통해 인덱스를 지정하는 방법이다\n\n\n\n해시 함수를 사용하기 때문에 상수시간의 탐색 시간이 걸리지만\n\n매우 한정된 범위로 해시 함수를 돌려야 하기 때문에 충돌 (Collision) 이 날 수가 있다\n\n이건 뭐 자구시간에 배운것처럼 충돌이 나는 애들만 리스트로 관리하는 방법 등을 사용할 수 있겠제\n\n\n\n\n\nMetadata §\n\n이건 파일들의 메타데이터를 어디에 보관할지에 관한 것인데\n앞에서 배운것처럼 UNIX 에서는 inode 에 따로 보관하고 FAT 에서는 파일 포인터 이외에는 디렉토리에 때려박는다\n\nFilename Support §\n\n일반적으로 struct{FNAME, METADATA} 형식으로 디렉토리 Content 의 Entry 를 저장하게 되는데 이때 각 Entry 의 크기는 고정되어 있다\n이말인 즉슨 파일의 이름의 크기는 일정 크기로 제한되어야 한다는 것인데\n파일의 이름 크기에 제한을 두지 않기 위해 아래와 같은 방법을 사용해서 이름이 긴 파일들을 관리할 수 있다:\n\n\n\n위 그림처럼 파일 이름이 너무 큰 경우에는 잘리는 만큼을 디렉토리의 맨 마지막 Entry 에 모두 때려박고\n\n해당 Entry 의 파일 이름을 저장하는 부분 마지막에 잘린 이름을 가리키도록 포인터를 두는 방법으로 해결할 수 있다\n\n\n\nVFS, NFS §\n\nVFS (Virtual File System) 은 운영체제 간의 상이한 파일시스템을 프로그래머가 고려하지 않아도 되게 하기 위해 고안된 통일된 인터페이스이다\n\n즉, 프로그래머는 이 인터페이스로 파일입출력을 이용하기만 하면 해당 파일을 관리하는 파일시스템에 따라 알아서 내부적인 조작을 해준다는 것\n\n\nNFS (Network File System) 은 알다시피 파일을 네트워크를 이용해 접근할 수 있게 해주는 파일시스템이다\n\n\n\n위 그림으로 좀 자세하게 알아보자고\n\nIO 시스템 콜이 발생하면 일단 VFS 인터페이스를 통해 해당 파일의 IO 작업이 진행되는데\n만일 해당 파일이 로컬에 없고 외부에 있다면 NFS Client 데몬을 이용해 외부에서 갖고오도록 한다\n해당 요청은 RPC → Network → RPC 를 거쳐 실제 파일이 위치한 머신 (서버) 의 NFS Server 데몬에 도달하게 된다\n그럼 NFS Server 데몬은 VFS 인터페이스를 이용해 파일을 읽어서 내용을 보내주게 되는 것\n\n이때 VFS 인터페이스가 왜 사용되는지에 살짝 의구심이 들 수도 있는데 어차피 NFS Server 도 IO 시스템 콜을 할 테니까 당연빠따로 VFS 인터페이스를 거치게 된다\n\n\n\n\n\nCaching §\nPage Cache, Buffer Cache §\n\n일단 개념적인 차이점\n\nPage Cache 는 Swap area 에서 페이지를 메모리에 올릴 때 캐싱을 해서 Swap area 까지 가지 않게 하기 위한 캐시이고\nBuffer Cache 는 파일 IO 에서 한번 읽어온 블럭들을 캐싱해서 다른 프로세스에서의 요청에 조금 더 빠르게 대응하기 위한 캐시이다\n\n\n이외에도 캐시의 크기는 작기 때문에 내용을 교체하기 위한 알고리즘 (Replacement Algorithm) 에서도 차이가 나는데\n\nPage Cache 의 경우에는 이전 강의에서 말한 것 처럼 주소변환이 MMU 에 의해 이루어지므로 페이지 참조 횟수를 알 수 없어 Clock 알고리즘을 사용하고\nBuffer Cache 의 경우에는 파일 IO 라는 것이 결국에는 시스템 콜이기 때문에 운영체제로 제어권이 넘어가 파일 참조 이력을 운영체제가 알고 있다 → 따라서 LFU, LRU 등의 알고리즘을 사용하게 됨\n\n\n\nMemory Mapped IO §\n\nMemory Mapped IO 혹은 Memory Mapped File 은 파일의 일부를 그냥 가상메모리에 매핑시켜서 메모리에의 데이터 변경이 바로 파일입출력과 연동되도록 하는 개념이랜다\n이렇게 작동한다 → 파일의 일부분이 메모리의 페이지에 올라와있어 여기에 변경이 이루어지다가 Swap out 이 되면 Swap area 가 아닌 파일에 내려가 변경부분이 반영이 되고 다시 해당 파일에 접근할때에는 Page Fault 가 발생해서 파일이 페이지로 올라오는 것\n\n따라서 페이지에 접근할때는 커널의 도움을 받지 않아도 된다\n또한 Buffer Cache 의 내용을 복사해오지 않아도 된다는 장점이 있다\n\n\n당연히 처음에는 IO 를 해야 하기 때문에 mmap 이라는 시스템 콜이 최초에 이루어진다\n\n따라서 최초에 Buffer Cache 를 한번 거치게 된다 → MMAP 의 경우에 Page Cache 만 사용하기 Buffer Cache 를 사용하지 않는다고 생각하면 오산낙지다\n\n\nMMAP 을 사용하는 대표적인 케이스는 프로세스의 코드-데이터-스택 구조에서의 코드 부분이다\n\n왜냐면 프로세스의 코드는 변경되지 않기 때문에 굳이 Swap area 로 내리지 않고 실행파일이 위치한 곳으로 내려도 되기 때문\n\n\n\nUnified Buffer Cache §\n\nUnified Buffer Cache 는 Page Cache 와 Buffer Cache 를 분리하지 않고 하나로 합쳐놓은 개념이다\n\n요즘의 운영체제는 모두 이 방법을 이용한다네\n\n\n그래서 파일 IO 를 할 때에도 페이지 단위 (4Kb) 로 캐싱해서 구지 두개를 별도의 모듈로 구성하지 않는다는 느낌인듯\n또한 메모리 영역자체도 구분을 하지 않고 올려놨다가 때에 따라서 파일 버퍼로 사용하던지 아니면 페이지 캐싱을 하는 식으로 운영한댄다\n\n\n\n위 그림이 UBC 를 이용하지 않은 경우와 이용한 경우를 비교한 사진인데\n\n일단 UBC 를 사용하지 않았을때에는\n\n일반적인 파일 IO 의 경우에는 오른쪽의 경로에 따라 Buffer Cache 에 올라갔다가 사용자 프로세스로 복사되는 과정이 이루어지고\nMMAP 을 이용할 경우에는 왼쪽의 경로에 따라 파일이 Page Cache 에 등록되지만 최초에는 파일 IO 를 위해 Buffer Cache 를 거치게 되는 것\n따라서 MMAP 을 사용하든 사용하지 않든 모두 Buffer Cache 를 거치게 된다\n\n\n하지만 UBC 를 사용했을 경우에는\n\n일반적인 파일 IO 에는 별 다를 바 없지만\nMMAP 의 경우에는 Buffer Cache 와 Page Cache 가 구분되지 않기 때문에 최초의 파일 IO 에 의한 캐싱이 마치 Page Cache 로도 사용되어 캐싱이 두번 중복되는 비효율성을 해결한다\nUBC 의 경우에는 동기화 문제를 고려해야 한다\n\nUBC 를 이용하지 않았을 경우에는 하나의 파일을 여러 프로세스가 공유해도 Buffer Cache 를 기반으로 각자의 메모리 공간에 파일이 있지만\nUBC 를 사용하게 되면 공유하는 메모리 공간에 파일이 올라와있는 것과 마찬가지이기 때문\n즉, UBC 의 경우에는 한놈이 MMAP 을 해서 사용하고 있는 파일의 공간 (Page Cache 로 기능) 과 다른 한놈이 MMAP 이 아닌 파일 IO 를 해서 올려놓은 공간 (Buffer Cache 로 기능) 이 같기 때문에 동기화 문제가 발생할 수 있다는 것\n\n\n\n\n\n\n"},"os.fall.2022.cse.ewha.ac.kr/11.-Disk-Scheduling":{"title":"11. Disk Scheduling","links":[],"tags":[],"content":"용어정리 §\nSector, Block §\n\nSector: 디스크에서 정보가 저장되는 가장 작은 단위\n\n하나의 섹터는 Header + Data (512byte) + Trailer 이렇게 세 부분으로 구성되고\nHeader 와 Trailer 에 섹터 번호하고 ECC(Error Correcting Code) 가 저장된다\n\nHeader 와 Trailer 에 드가는 정보는 Disk Controller 가 직접 접근하고 운영하는데\n만약 실제 데이터와 ECC 가 호환되지 않는다면 Bad Sector 로 간주하고 그에 따른 대응을 하게 된다\n\n\n\n\nBlock: 디스크 외부에서 바라봤을 때의 데이터 저장 단위\n\n이게 약간 헷갈릴 수도 있는데\nBlock 들이 디스크 내의 각 Sector 에 매핑되는 식으로 저장된다고 생각하면 됨\n그리고 Block 은 1차원 배열의 형태를 띈다 → Sector 의 경우에는 몇번째 원판의 몇번째 섹터 이렇게 2차원 배열로 생각할 수 있다면 Block 은 이런 물리적인 구분 없이 그냥 쭉 이어서 1차원 배열의 형태를 띈다는 것 → 뭔가 아닌거같기도 하고 확실하지 않음\n\n\n위와 같은 차이점때문에 섹터와 블럭의 사이즈는 같지 않을 수도 있는듯\n\n디스크의 구조 §\n\n\nPlatter: 디스크를 구성하는 각 원판\nTrack: Platter 내에서 같은 반지름을 가지는 Sector 의 집합\n\nCylinder 는 원래 여러 Platter 에 걸친 Track 들을 가상의 원통으로 묶은 것을 의미하는데 뭐 Track 이랑 비슷하게 생각해도 된다\n\n\nArm: 디스크를 읽어들이기 위한 막대\nRead-write Head: Arm 에서 실제로 데이터를 읽어들이는 부분\nSpindle: 디스크를 회전시키는 축\n\nFormatting §\n\nPhysical Formatting (Low-level Formatting): 디스크에 섹터들을 나누는 과정\nLogical Formatting: FAT 같은 파일 시스템을 디스크에 구성하는 과정\n\nPartitioning, Booting §\n\nPartitioning: 하나의 물리 디스크를 여러개의 논리 디스크로 나누는 과정\nBooting: 컴퓨터를 초기화하는 과정\n\n부팅은 다음과 같은 순서대로 일어난다\n\nROM 에서 Small Bootstrap Loader 를 실행시킨다\n\n메모리는 기본적으로 휘발성이지만 비휘발성의 아주 작은 공간인 ROM 이 존재한다\nCPU 는 메모리에밖에 접근할 수 없기 때문에 ROM 에 있는 부트로더를 실행함\n이놈은 Small Bootstrap Loader 라고 불리는데 이건 부팅을 시작하기 위한 기본적인 코드인 디스크에서 부트로더 전체를 메모리에 올리도록 하는 코드가 들어있다\n\n\nSector 0 에서 Full Bootstrap Loader 를 가져와서 실행\n\n위에서 SBL 이 부트로더 전체를 메모리에 올리는 역할을 한다고 했자네\n이때의 부트로더를 Full Bootstrap Loader 라고 하고 이것은 Sector 0에 저장되어 있다\nSector 0은 디스크에서 가장 최외각 트랙의 첫번째 섹터로 무적권 FBL 가 저장되도록 예약되어 있다\n\n\n\n\n\n\n\nDisk Access Time §\n\n디스크에서 데이터를 읽어오는 과정은 아래와 같이 세 부분으로 나눌 수 있다\n\nSeek Time: 디스크의 암(헤드)을 데이터가 위치한 실린더로 움직이는데 걸리는 시간\nRotational Latency: 암이 제대로 위치한 뒤에 디스크가 회전해 원하는 섹터가 헤더 위로 회전해오는데 걸리는 시간\nTransfer Time: 실제 데이터의 전송 시간\n\n\nDisk Bandwidth: 단위 시간동안 전송된 바이트의 수\n디스크에서 데이터를 읽어올 때 가장 오래 걸리는 것은 Seek Time 이고 Disk Bandwidth 를 극대화 하기 위해 섹터를 읽는 순서를 최적화하는 작업을 Disk Scheduling 이라고 한다\n\nDisk Scheduling §\n\nDisk Bandwidth 를 최대화 하기 위해서는 Seek Time 을 최소화 해야 한다고 했으므로 요청된 섹터들의 트랙 (실린더)를 기준으로 어떤 섹터를 먼저 읽을 지 결정한다\n\nFCFS (First Come First Service) §\n\n\n딱히 뭐 설명할 것도 없다\n그냥 무지성 선입선출\n당연히 비효율적이어서 안쓴다\n\nSSTF (Shortest Seek Time First) §\n\n\n이건 현재 헤드의 위치를 기준으로 가장 가까운 놈부터 처리하는 방식인데\n예상하듯이 Starvation 문제가 발생한다 → 한곳에 요청이 몰리면 그와는 멀리 있는 요청은 계속 순위가 밀리기 때문\n\nSCAN (+ C-SCAN, N-SCAN) §\n\n\nSCAN 은 기본적으로 다음과 같이 작동한다\n\n헤드가 디스크의 끝(최외각 혹은 최내각) 트랙으로 움직인다\n헤드가 반대쪽 끝으로 움직이면서 경로 상에 있는 요청들을 처리한다\n2번 과정을 반복한다\n\n\n따라서 가장 기본이 되는 SCAN 은 아래 그림 한장으로 설명된다\n\n\n\n\n\n보면 약간 엘리베이터와 비슷하기 때문에 엘리베이터 스케줄링이라고도 부른다\n\n이 방식은 Seek Distance 로 최적화 할 수 있고 Starvation 도 안생기는 장점이 있지만\n트랙의 위치에 따라 대기시간이 고르지 않다는 문제가 있다\n\n헤드가 한번 끝에서 끝까지 움직이는데 10초의 시간이 걸린다 하면\n가운데 트랙의 경우에는 가장 오래 걸려도 헤드가 절반을 움직이고 또 절반을 되돌아오면 되기 때문에 10초가 걸리지만\n외곽에 있는 트랙의 경우에는 헤드가 한번 쭉 움직이고 또 반대방향으로 쭉 되돌아와야 하기 때문에 최대 20초가 걸릴 수 있다\n\n\n\n\n위와 같은 문제를 해결하기 위한 SCAN 의 변형이 C-SCAN 이다\n\n헤드가 디스크의 끝(최외각 혹은 최내각) 트랙으로 움직인다\n헤드가 반대쪽 끝으로 움직이면서 경로 상에 있는 요청들을 처리한다\n위 과정을 반복한다\n\n\n보면 그냥 SCAN 과의 차이점은 3번 과정인데 그냥 SCAN 의 경우에는 양방향에 대해 경로상의 요청을 처리하지만\nC-SCAN 의 경우에는 단방향에 대해 요청을 처리한다 → 즉, 한쪽 방향으로 움직일 때만 요청을 처리하고 반대방향으로 되돌아 갈 때는 요청을 처리하지 않고 그냥 움직인다는 것\n따라서 아래의 그림으로 한장 정리가 가능하다\n\n\n\n\n\n따라서 이 방법을 사용하면 기존의 SCAN 방식에 있던 대기시간 불균형을 해소할 수 있다\nSCAN 방식의 변형 중에는 N-SCAN 이라는 놈도 있는데\n\n얘는 SCAN 과 유사하지만 이동중에 들어온 요청에 대해서는 경로상에 있어도 처리하지 않는다는 차이점이 있다\n즉, 한 방향으로 이동하기 전에 들어온 요청에 대해서만 이동하면서 처리하고 이동하는 중간에 들어온 요청은 지금 처리하지 않고 다시 반대방향으로 되돌아갈 때 처리한다는 입장임\n\n\n\nLOOK (+ C-LOOK) §\n\n\n위그림은 C-LOOK 이다\nSCAN 과 LOOK 의 차이점은 헤드가 어디까지 움직이냐에 달려 있다\n\nSCAN 의 경우에는 무조건 최외각-최내각에서 방향 전환을 하는 반면\nLOOK 의 경우에는 해당 방향에 더 이상 요청이 없으면 방향 전환을 한다\n즉, 트랙이 199까지 있을 때 요청된 트랙의 가장 큰 값이 180이면 SCAN 은 (오름차순일 때) 180 을 들르고 199를 간 다음에 내려가는 반면 LOOK 의 경우에는 180 을 들른 다음에 바로 내려간다\n\n\nSCAN 과 C-SCAN 의 차이와 동일하게 LOOK 과 C-LOOK 은 양방향이냐 단방향이냐의 차이밖에 없다\n\nDisk Scheduling Algorithm 의 특징 §\n\n일단 보통 SCAN 이나 LOOK 계열의 스케줄링 방식을 사용하고\n그리고 필요한 경우 쉽게 교체될 수 있도록 OS 와 별도의 모듈로 내장된다고 한다\n실제 Disk Bandwidth 는 이러한 알고리즘적 측면 외에도 파일을 어떤 방식으로 저장할지도 큰 영향을 끼친다고 한다 (연속 할당? 분할 할당?)\n\nSwap Area Management §\n\n일단 디스크를 사용하는 이유를 보면\n\n메모리의 경우에는 휘발성이기 때문에 비휘발성의 데이터 저장 장치가 필요했고\n메모리보다 저렴하되 메모리의 역할을 보조해줄 수 있는 저장장치가 필요하기 때문이다\n\n\n위 이유 중 두번째를 위한 것이 앞에서도 계속 나온 Swap Area 인데 어떻게 관리되는지 대강 알아보면\n\n\n\n뭐 요즘 우분투는 그냥 파티션 안쓰고 파일시스템으로 스왑영역을 관리하지만 디스크를 파티션해서 Swap Area 를 지정해 주는 것이 많이 쓰였다고 하더라\n\n일반적인 파일 시스템과 Swap Area 의 차이점은\n\n일단 파일보다 훨씬 더 빈번하게 참조되고\n메모리를 대체하는 공간이기 때문에 데이터들이 임시적이다 → 잠깐 머물렀다가 프로세스가 종료되면 사라지기 때문\n따라서 공간 효율성보다는 속도 효율성이 훨씬 중요하고 일반적으로 데이터를 나눠 저장하는 것이 아닌 한 덩어리로 저장 (Sequential Allocation) 하게 되고 블럭의 크기도 512바이트가 아닌 512Kb 등의 훨씬 큰 사이즈를 갖게 된다\n\n\n\n\n\nRAID §\n\n\nRAID (Redundant Array of Independant Disks): 는 디스크 여러개를 묶어서 고가용성과 속도 등의 이점을 얻고자 하는 방법이다\nInterleaving, Striping (분산 저장): 여러개의 디스크에서 데이터를 부분적으로 병렬적으로 읽어옴으로써 속도를 향상시키는 방법\nMirroring, Shadowing (중복 저장): 여러개의 디스크에 데이터를 중복해서 저장해서 Disk Failure 등의 문제 상황을 방지하는 방법\n\n단순히 중복해서 저장하는 것만이 아니고 Parity (에러 탐지 코드) 도 추가적으로 구성하기도 한다\n\n\n"},"os.fall.2022.cse.ewha.ac.kr/2.-System-Structure-&-Process-Execution":{"title":"2. System Structure & Process Execution","links":[],"tags":[],"content":"System Structure §\n\n\nCPU + Memory = Computer\n나머지 디스크 키보드 등은 IO Device 라 부른다.\nMemory 는 CPU 의 작업공간이라 할 수 있음 → Instruction들을 하나씩 메모리에서 읽어다 실행시키게 됨 → PC가 메모리의 주소를 가리키기 때문\n\nCPU의 유일한 업무는 PC가 가리키는 Instruction을 가져와서 실행시키는 것 밖에는 없다.\n\n\nDevice controller: 각 device들을 관리하는 작은 CPU같은놈\n\nDevice controller 는 제어정보를 위한 Control register와 Status register 도 추가적으로 가진다\n또한 정보를 임시적으로 저장하기 위한 Buffer 도 존재함 → Local buffer\n\n이 Local buffer 에는 CPU(근데 대부분 DMA Controller) 가 접근해서 IO처리가 끝난 데이터들을 가져온다.\n\n\n근데 이제 Device controller 가 실행해야 되는 Instruction은 어떤 형태로 제공되느냐\n니가 많이 들어봤던 펌웨어 가 이러한 역할을 해준다 → 펌웨어가 약간 디바이스의 OS라 할 수 있는거지\nDevice driver: 컨트롤러가 하드웨어였다면 얘는 소프트웨어다 → 각 장치별 처리 루틴을 담은 OS 의 코드 일부분\n\n펌웨어는 실제로 디바이스 컨트롤러가 실행하는 Instruction이고 Device Driver 는 CPU가 실행하는 디바이스를 관리하기 위한 Instruction 이라는 차이가 있더라\n\n\n\n\nMode bit: 현재 실행중인 Instruction이 User mode 인지 Kernel mode 인지를 저장하는 플래그\n\n일반 사용자 프로세스가 시스템적으로 중요한 작업을 직접 할 수 없도록 하드웨어적으로 막아놓음\n0: 모니터(커널, 시스템) 모드 → 보안을 해칠 수 있는 중요한 명령어(Previleged instruction)들을 수행할 때\n1: 사용자 모드 → 일반 사용자 프로세스가 사용할 수 있는 안전한 명령어\nOS로 전환되기 전에는 해당 플래그가 0으로 바뀌고 다시 사용자 모드로 가기 전에는 1로 바뀐다.\nMode bit 이 1일때는 특정 프로세스의 메모리 공간밖에 접근할 수 없고 0일때는 모든 메모리 공간에 접근할 수 있다더라\n\n\nInterrupt line: IO 등의 인터럽트들이 들어오는 통로\n\nCPU는 메모리랑만 작업하고 그 외의 것들에는 관여하지 않는다\n따라서 IO 등의 작업이 필요할 경우에는 해당 작업을 Device controller 등에게 위임한 뒤 다시 메모리에 있는 Instruction들을 실행한다.\n만일 Device controller 가 작업을 마치게 되면 그때 인터럽트를 걸게 되는데\nCPU는 Instruction 하나를 실행한 이후 매번 Instuction line 을 체크해서 들어온 인터럽트가 있는지 확인하고\n인터럽트가 있으면 해당 인터럽트를 먼저 처리하게 된다\n얘는 소프트웨어적으로 큐형식으로 작동한다기보다는 하드웨어적 버스로 구성되어 전기신호를 보냄으로써 인터럽트가 걸리게 하는거 같다 → 근데 확실하지는 않음\n\n\nTimer: 프로그램의 CPU time을 재는 타이머\n\n프로그램이 IO 등을 만나면 이거때문에 더이상 해당 프로세스에서는 작업하지 못하므로 제어권이 딴놈에게 넘어가지만\n만일 IO가 안일어나면 이놈만 CPU를 잡아먹고있는 Monopolize 가 발생한다\n따라서 Context switching 이 일어나기 전에 Timer를 설정해놓고 실행하다가 타이머가 종료되면 Timer 인터럽트를 걸어 딴놈으로 옮겨갈 수 있도록 함\n\n\nDMA(Direct Memory Access): IO 디바이스에 의한 인터럽트는 생각보다 빈번하게 발생하기 때문에 매번 CPU에 인터럽트를 걸면 경장히 비효율적이다.\n\n따라서 저 DMA라는 놈이 중간다리 역할을 하게 되는데\n이름에서부터 알 수 있듯이 얘도 CPU와 마찬가지로 메모리에 접근할 수 있다.\n따라서 인터럽트가 발생할때마다 CPU대신 이놈이 메모리에 적재를 해주고\n몇 바이트 수준이 아닌 블럭 단위의 좀 많이 데이터가 모이면 그때 한번에 인터럽트를 걸어서 CPU가 알 수 있도록 해준다.\n근데 메모리에 CPU랑 DMA가 같이 접근하게 되면 동기화 문제가 발생하기 때문에\nMemory controller 가 마치 세마포마냥 접근을 중재해주게 되는 것이다.\n\n\n\nTrap, Syscall, Exception §\n\n프로세스는 IO 등의 커널 함수가 필요하면 직접 실행하거나 OS가 먼저 해주는게 아니라 프로세스가 OS에 요청하는 식으로 작동한다.\n왜냐면 사용자 프로그램이 실행되고 있을때는 Mode bit 이 1이기 때문에 권한이 없어 메모리의 커널 영역으로 점프하지 못하기 때문\n따라서 일반적인 함수나 분기, 반복과는 다른 방식으로 작동한다.\n사용자 프로세스는 커널 함수를 요청하기 위해 일종의 인터럽트를 걸어 해당 함수가 실행될 수 있도록 하는데 → 이런 인터럽트를 거는 과정 덕분에 Mode bit 이 0으로 바뀔 수 있고 따라서 커널 영역의 Previleged Instruction들을 실행할 수 있더라.\n이렇게 사용자 프로세스가 커널 함수를 호출하는 것을 **Syscall(System call)**이라고 한다.\n사용자 프로세스가 인터럽트 비스무리한걸 거는 경우가 한가지 더 있는데 바로 어떤 값을 0으로 나누려 하는 경우 등의 Exception 이 발생했을 때이다.\nSyscall하고 Exception을 합쳐서 사용자 프로세스가 거는 인터럽트 비스무리한걸 Trap 혹은 Software Interrupt 이라고 하더라\nSyscall 또한 어찌보면 사용자가 요청하는 커널 함수이기때문에 올바른 요청이냐에 대한 검증이 선행된다.\n그니까 대략 이런식으로 움직임 → IO 의 경우 예시임\n\nIO가 필요할 때 프로세스(A)는 해당 기능을 호출한다. (Syscall - Software Interrupt)\nOS가 CPU를 차지하며 해당 Device controller 에게 일을 시킨다.\n다른 프로세스(B)로 CPU가 전환\nIO 작업이 끝나면 해당 Device controller 에 의해 IO 인터럽트 발생 (Interrupt - Hardware Interrupt)\n그러면 DMA가 Device 에 있던 Buffer에서 데이터를 가져다가 메모리에 적재하고 즉당한 시점에 CPU에 인터럽트를 건다\nCPU 가 다시 OS로 전환되며 해당 인터럽트를 처리\nIO 인터럽트때문에 멈춰있던 프로세스(B)로 CPU가 넘어오며 진행 → 무조건은 아니고 일반적으로는 거렇다더라\nIO를 요청한 프로세스(A)로 CPU가 넘어오며 다시 작업 진행\n\n\n\nInterrupt Handling §\n\nInterrupt Service Routine: 얘는 특정 인터럽트가 걸렸을때 실행되는 Instruction 모음이다. = 해당 인터럽트를 처리하는 커널 함수\nInterrupt Vector Table: 얘는 위의 ISR들에 대해 인터럽트 번호-ISR 주소(위치) 를 매핑시켜놓은 테이블이다\n\n이것 덕분에 특정 인터럽트가 발생했을 때 그걸 처리하는 ISR이 어느 위치에 있는 지 알 수 있게 되고 해당 ISR 이 실행되게 되는 거다.\n\n\n\nSynchronous, Asynchronous IO §\n\n\n얘는 뭐가 좋고 뭐가 나쁘고가 아니고 걍 구현방식의 차이인데\n먼저 Synchronous IO 는 IO요청을 한 다음에 해당 IO가 끝날때까지 요청한 프로세스는 기다리다가 IO 인터럽트가 걸리면 그제서야 다시 프로세스가 재개되는 방식이고\nAsynchronous IO 는 끝날때까지 기다리지 않고 요청하는 작업을 끝내자마자 요청한 프로세스로 돌아갔다가 나중에 IO 인터럽트가 걸리면 데이터를 가져와서 계속 일하는 방식이다.\n일반적으로는 Synchronous 의 경우에는 읽기 작업에 많이 사용된다 → (보통은) 데이터를 읽어들인 다음에 그 데이터를 가지고 계속 작업하는 것이 순리이므로\n그리고 Asynchronous 는 쓰기 작업에 많이 사용된다 → (보통은) 데이터를 화면이나 디스크에 쓴 다음에는 프로세스에서 해당 데이터를 쓸 일이 많지 않기 때문\n물론 뭐 정해진건 아니다 → 읽기 요청도 Asynchronous 로 구현하거나 쓰기 요청도 Synchronous 로 할 수도 있다\n\nImplementation of Synchronous IO §\n\nSynchronous IO 는 구현방법이 2가지 인데 보통 후자의 방법으로 많이 한다.\n먼저 첫번째는 IO가 끝날때까지 Busy waiting을 하는 방법이다 → 즉, IO가 끝날때까지 CPU가 해당 프로세스와 함께 대기하는 방법\n\n하지만 당연하게도 이 방법은 비효율적이다\n비싼 자원인 CPU가 놀고 있다는 점에서도 그렇고\nIO가 하나 걸리면 딴거를 못하니까 IO 요청도 한번에 하나밖에 못하기 때문\n\n\n그래서 두번째 방법은 해당 프로세스로 CPU time 을 주지 않는 방법이다\n\n이렇게 하면 해당 프로세스가 어차피 실행되지 않기 때문에 자동으로 대기상태가 되는 효과가 있고\nCPU가 다른 프로세스로 옮겨가기 때문에 CPU time을 낭비하지도 않으며\n다른 IO syscall이 들어와도 일 시켜놓고 또 다른 프로세스로 넘어가면 되기 때문에 IO 요청도 여러개 받을 수 있다.\n\n\n\nIO Instruction Type §\n\n\nIO를 하는 방법에는 두가지가 있는데\n위 그림에서 왼쪽이 일반적인 상황으로 메모리에 접근하는 명령어와 디바이스에 접근하는 명령어(Special Instruction)가 별개로 존재하여 사용하는 방식과\n오른쪽처럼 각 디바이스들을 메모리처럼 취급해서 확장 메모리 주소를 붙인 다음 메모리 접근 명령어를 그대로 사용하는 방식이 있다 → 이 방식을 Memory Mapped IO 라고 부르더라\n\nMemory Hierarchy §\n\n\nPrimary: 레지스터, 캐시(S-Memory), 램(DRAM) → 빠르고 비싸고 (따라서 용량이 작고) 휘발성이고 바이트단위로 접근이 가능해서 CPU가 실행시킬 수 있고 (Executable)\nSecondary: 느린 대신 싸고 (용량 크고) 비휘발성이고 바이트단위가 아닌 섹터 등의 단위로 접근할 수 있어서 CPU는 실행시킬 수 없다.\n메모리에 접근하는것도 10개 정도의 Instruction이 소요되기에 이를 보완하기 위해 캐쉬 메모리를 두는거고\n재사용의 목적으로 처음에 접근할때는 물론 오래 걸리지만 한번 접근해서 캐쉬에 올려놓고 나서는 그 다음부터는 아래까지 안내려가도 되기 때문에 훨씬 빠르게 사용할 수 있음 → 이런거를 캐싱이라 한댄다.\n\nProgram Execution §\n\n\n뭐 옛날에 배운것처럼 프로그램이 메모리에 올라가서 실행가능한 상태가 되었을때는 프로세스라고 하는데\n메모리에 올라가기 전에 한 단계를 더 거친다 → Virtaul Memory 할당\n이건 다음과 같은 식으로 이루어진다\n\nVirtual Address Space 할당 → 프로세스 하나마다 주소 0부터 시작하는 가상의 메모리 공간을 할당하고\n\n이 가상 메모리 공간에는 많이 들어봤던 Code, data, heap-stack 이 드간다\n\n\nAddress translation 을 통해서 가상 메모리 공간을 실제 메모리에 할당한다.\n\n근데 가상 메모리 공간이 실제 메모리에 할당될때는 연속적인 공간에 할당되는게 아니고 쪼개서 당장 필요한것만 메모리에 올려놓고 나머지는 디스크의 Swap area 로 다시 내려놓았다가 사용할 일이 있으면 그때 가져오는 방식으로 작동함\n\n\n\n\n\nKernel §\n\n\nKernel 이 차지하는 메모리 공간도 당연히 Code, Data, Stack의 형태로 구성된다\n뭐 Code 에는 자원 관리나 인터럽트 처리하는 코드 및 편의기능이 드가있고\nData 에는 CPU, 메모리, 디스크를 관리하기 위한 자료구조들과 PCB가 적재된다\n\n다음시간에 배우겠지만 프로세스가 하나 실행되면 해당 프로세스의 상태같은 제어정보를 담기 위한 자료구조가 하나씩 생성되며 이들을 PCB(Process Control Block)이라고 부른다.\n\n\nStack에는 위 그림에서는 좀 헷갈리게 이름이 붙여져 있지만 결국에는 커널도 여러개의 함수로 구성되어있기 때문에 커널 함수가 실행될때마다 스택에 쌓이게 된다\n\n즉, 어떤 프로세스가 어떤 함수를 호출하면 그때 스택에 ~프로세스가 호출한 ~함수 의 형식으로 스택이 쌓이게 되는 거다\n따라서 커널은 프로세스별로 스택을 만들어서 특정 프로세스가 호출한 커널 함수 정보를 관리한다.\n\n\n\nFunctions §\n\n함수는 고급 언어 수준 뿐만 아니라 어셈블리어에서도 존재한다 → 어떤 언어로 코드를 작성해도 컴파일 이후에는 결국에는 걔네들이 다 함수형태로 바뀌게 된댄다\n함수에는 세가지 분류가 있다\n사용자 정의 함수: 말그대로 사용자가 정의한 함수\n라이브러리 함수: 사용자가 정의한 게 아니고 다른 사람이 라이브러리로 만들어놓은 함수\n\n라이브러리 함수도 당연히 컴파일 이후 바이너리에 함께 들어있게 되고\n따라서 프로세스가 된 이후에 일반 프로세스의 Code 공간에 존재하게 된다.\n\n\n커널 함수: 커널 프로그램의 함수\n\n이 함수를 호출하는게 결국에는 Syscall 인거고\nSyscall 이 필요한 이유를 좀 다른 관점에서 보면 Virtual memory에서 Address space 는 프로세스마다 갖고 있고 Address jump는 해당 Address space 내에서만 가능하기 때문에 다른 Address space 에 속하는 커널 함수로는 점프할 수가 없어서 Syscall 이 필요한 거라고 볼 수도 있다.\n\n\n\n\n\n그래서 프로세스 하나와 커널과의 상호작용만 보면 (Time sharing 같은거 다 빼고)\n사용자 함수나 라이브러리 함수가 실행될때는 해당 프로세스의 주소공간에서 User mode(Mode bit 1) 로 작동하다가\nSyscall이 발생하면 Kernel mode(Mode bit 0) 으로 변경되어 커널 함수가 실행되는 것이다.\n"},"os.fall.2022.cse.ewha.ac.kr/3.-Process":{"title":"3. Process","links":[],"tags":[],"content":"Process and Context §\n\n일단 뭐 프로세스는 Program in Execution 을 의미한다.\n여기서 이제 프로세스의 문맥(Context) 가 중요한데\n이건 특정 프로세스가 어느 한 시점에 어떤 상태인지를 나타내는 정보라고 생각하면 된다\n다음과 같이 세개로 분류해볼 수 있다\n\nCPU 상태( → 레지스터 상태): PC 나 다른 레지스터에 어떤 값이 들어와있었나\nMEM 상태: Code 부분에는 어떤 것들이 담겨있고 Data의 변수들에는 어떤 값이 들어있고 Stack에는 어떤 함수 호출이 쌓여있는지 등등\nKernel 상태: 프로세스를 제어하기 위한 정보인 PCB에 어떤 값이 들어가있는지 혹은 해당 프로세스가 어떤 Syscall 을 호출해서 어떤 커널 함수들이 Kernel stack에 쌓여있는지\n\n\n프로세스의 상태 관리가 필요한 이유는 Context switching 때문이다 → Time sharing등을 위해 실행중인 프로세스를 바꾸려면 실행중이던 프로세스의 상태를 완전히 백업하여 백업된 Context 를 다시 불러왔을 때 이전에 실행중이던 상태 그대로 재개되어야 하기 때문시\n\n5 State Process Model §\n\n\n우리 빵효경 교수님은 5 State Process Model 로 설명을 한다\n5가지 상태중에 중요한건 가운데에 3가지인 Running, Ready, Waiting(Blocked) 인데\nRunning 은 CPU를 할당받아 한창 실행이 되고 있는 상태고\n\n위 그림에서 보이는것처럼 Running 상태가 끝나는건 3가지 경우가 있다\n타이머 종료\n프로그램 종료 (Exit)\n이벤트 발생 → 자발적 CPU 반납\n\n\nReady 는 다른건 다 준비됐고 CPU만 할당받으면 다시 실행할 수 있는 상태를 의미한다\n\n얘는 위 그림에서 보이는것처럼 프로세스가 생성되어 CPU만 받으면 되는 상태까지 오거나\nRunning 상태였다가 Timer 가 끝나서 CPU를 뺏겼거나\nBlock 을 먹었다가 Event 가 종료되어 다시 준비완료\n\n\n그리고 Blocked 는 Syscall 등의 이벤트에 의해 지금 당장 CPU를 할당해주어도 실행할 수 없는 상태를 의미한다\n\n여기서 이벤트는 IO 같은 Syscall 혹은 Interrupt 일 수도 있지만\n조리퐁같은 경우에도 이벤트가 된다 → 다른 쓰레드가 이미 공유 데이터를 쓰고있어서 현재 프로세스가 접근할 수 없는 경우에도 이벤트라고 말할 수 있다\n\n\n\nPCB (Process Control Block) §\n\n\n앞에서도 누누이 말했듯 커널에 저장되어 프로세스를 제어하기 위한 정보가 PCB (Process Control Block) 이고\n4개정도의 파트로 이루어진다\nOS 관련 정보에는 (1) 프로세스의 상태 (2) PID (3) 스케줄링 정보와 (4) 우선순위 정보가 드가고\nCPU 관련 정보에는 PC를 포함한 레지스터의 값들\nMEM 관련 정보에는 해당 프로세스의 Code, Data, Stack 의 위치 (메모리 주소) 정보\nFile 관련 정보에는 이놈이 열어놓은 파일 디스크립터들이 드간다.\n\nContext Switch §\n\n\nContext Switch 는 한 프로세스에서 다른 프로세스로 CPU 를 바꿔주는 과정인데\n다음과 같은 과정을 거친다\n\nA(중고)의 문맥 (PC, Reg, MEM 등) 을 전부 A의 PCB에 때려넣는다\nB(새삥)의 PCB에서 이전 문맥을 가져다가 전부 세팅을 한다\n\n\n근디 중요헌건 Context switch는 사용자 프로세스가 교체되었을 때에만 Context switch 라고 한다는 것이다.\n아래 그림 봐봐라\n\n\n\n(1) 같은 경우에는 Interrupt 혹은 Syscall 이 일어나서 ISR 이나 Syscall func 가 싱행된 후에 다시 원래 프로세스로 돌아왔다 → 이경우에는 Context switch 라고 하지 않는다 이거야\n\n일반적으로는 굳이 프로세스 교체가 필요하지 않은 이벤트의 경우에는 Context switch가 일어나지 않고 원래놈으로 되돌아온다\n\n\n하지만 (2) 같은 경우에는 이건 못참지\n\nTimer interrupt의 경우에는 의도적으로 프로세스를 교체하기 위한 거고\nIO 의 경우에도 오래걸리기 때문에 거의 대부분 프로세스가 Block 된다\n즉, 이런 경우에는 원래의 프로세스로 되돌아갈 수 없기 때문에 새로운 프로세스가 굴러들어오고, 따라서 Context switch 가 되었다고 표현한다.\n\n\n이건 사용자 → 커널 전환보다 사용자 → 사용자 전환이 훨신 오버헤드가 크기 때문이랜다\n\n예를들면 캐쉬를 비우는 Cache flush 의 경우에는 사용자 → 커널 전환에서는 완전 싹 비울 필요가 없기 때문에 이거로 인한 오버헤드가 현저히 적어진댄다\n\n\n\nProcess Queues §\n\n\n프로세스의 상태를 관리하기 위해 위처럼 Process Queue 가 소프트웨어적으로 구성되어있다\n하지만 프로세스는 선입선출로 관리되지 않기 때문에 아마 우선순위큐로 구현이 되어있지 않을까 싶은데\n어쨋든 대기 상태 큐인 Ready Queue하고\nBlock 먹은 이후 각 디바이스에서의 처리를 기다리는 Device Queues 가 있댄다\n마지막으로 모든 프로세스를 담는 Job Queue 가 존재한다\n그리고 큐에 들어가는 각각의 원소들은 PCB로\n아까 PCB의 그림에서 보면 PCB에 Pointer field 가 존재하는데 이걸 통해 각각의 PCB 들이 큐의 형태로 연결되어있게 된댄다\n\nScheduler §\n\nShort term scheduler(→ CPU Scheduler): 어떤 프로세스에게 CPU를 줄지 말지 결정하는 스케줄러\n\n즉, Ready queue 에 있는 프로세스들 중 어떤넘을 Running 으로 바꿀지 결정한다\n프로세스는 아주 찰나의 순간만 CPU를 잡고 있다가 쫒겨나므로 매우 빈번하게 Scheduling 이 발생한다 → 따라서 이름이 Short term 인 것임\n\n\nLong term scheduler(→ Job Scheduler): 어떤 프로세스에게 메모리를 줄지 말지 결정하는 스케줄러\n\n즉, New 상태에 있는 프로세스들 중 어떤놈을 Ready로 바꿀지 결정한다\n이건 Multiprogramming level 을 결정하는데에 아주 중요한 역할을 한다\n\n메모리에 너무 적은 프로세스가 올라가면 CPU가 비효율적이고 반대로 너무 많은 프로세스가 올라가있어도 중요한 부분이 메모리에 올라가지 못하기 때문에 IO가 너무 많이 일어나 CPU가 비효율적으로 작동한다\n따라서 Degree of Multiprogramming 을 제어할 필요가 있고 이것 제어하는게 Long term scheduler 인 것\n\n\n하지만 요즘의 Time sharing system에서는 사용하지 않고 일단 전부 Ready 로 박는다 → 이유는 바로 다음의 스케줄러가 존재하기 때문\n\n\nMedium term scheduler(→ Swapper): 어떤 프로세스를 스왑할지 결정하는 스케줄러\n\nLong term scheduler 가 사용되지 않는 대신 이놈이 Degree of Multiprogramming을 관장한다.\n즉, 프로세스 몇개가 메모리에 올라갈지 결정하는 것을 메모리에 적재될 시점부터 정하는게 아니고 적재한 다음에 결정하겠다는 소리임\n얘를 이용해 일단 프로세스가 생성되면 무적권 Ready 박고 Multiprogramming level 이 너무 높아지면 이 스케줄러를 이용해 프로세스 몇개를 디스크로 방출시켜서 낮추는 방식으로 작동한다더라\n\n\n\n7 State Process Model §\n\n\n일단 먼저 주의할점은 맨 위에 Running 두개는 사실 하나의 상태라는 점이다\n\n프로세스의 상태를 논할때는 무적권 사용자 프로세스를 말하지 커널 프로세스의 경우에는 상태의 개념이 없다\n그래서 만일 사용자 프로세스가 작동하다가 이벤트가 발생해 커널 함수가 실행되는 경우에도 여전히 Running 상태라고 말하며 위의 그림에서는 그걸 Monitor mode 라고 구분지어준 것 뿐임\n\n\n그래서 Medium term scheduler 가 등장하면서 새로운 상태인 Suspended ~가 등장하게 됐는데\n이건 Blocked 랑은 완전히 다른 개념이다 → Blocked 의 경우에는 IO 등의 이벤트가 완전히 해결되고 난 뒤에는 다시 Ready 로 돌아오지만\nSuspended 의 경우에는 메모리에서 아주 퇴출된 상태를 의미하며 이놈이 메모리로 다시 올라오기 위해서는 Medium term scheduler 에 의해 다시 머리채가 잡혀 올라와야 한다는 것\n그래서 메모리에 올라와있을 때를 Active 라고 하고 스왑되어 나갔을때는 Inactive 라고 한다\n\nThread §\n\n\n쓰레드 별거 없다\n만약 동일한 코드를 이용해 여러개의 프로세스를 실행시키면 각 프로세스마다 주소공간하고 PCB가 생성되게 될텐데\n이렇게 하면 Data 나 Code 등의 부분은 중복해서 메모리에 올라가므로 아주 비효율적이다 이말이야\n그래서 Thread 라는 것을 생각해내게 됐는데\n이건 Lightweight process 로 하나의 프로세스 내에서 별개의 작업을 하려고 할 때 공유할 수 있는 부분은 최대한 공유하고 분리해야만 하는 것만 분리시키자는 개념이다\n\n전통적인 프로세스를 Heavyweight process 라고도 하며 이것은 쓰레드를 한개만 갖고 있는 프로세스와 동일하다\n\n\n그래서 일단 분리해야 되는 부분은 다음과 같다\n\nPC: 당연히 쓰레드들마다 코드의 다른 부분을 실행시키고 있을 것이기 때문에 PC는 각 쓰레드마다 하나씩 있어야 할 것이다\nReg set: 마찬가지로 레지스터의 값들도 쓰레드마다 다를게 분명하다\nStack: 쓰레드들마다 코드의 다른 부분을 실행할 것이기 때문에 호출된 함수들도 다를것이고, 따라서 Stack 도 별도로 관리되어야 할 것이다\n\n\n즉, PCB 의 구조에서 프로세스의 실행과 관련된 부분인 CPU 관련 필드, 그리고 주소 공간에서 스택이 쓰레드마다 갖고 있게 되는 것이다.\n\n\n공통적인 부분은 프로세스 내에서 위의 세개를 뺀 나머지 (Data, Code 등등) 이며 이 부분을 Task 라고 하더라\n쓰레드의 장점은 크게 네가지가 있다\n\nResponsiveness: 하나의 프로세스 내에서 하나의 쓰레드가 블락먹어도 다른 쓰레드가 계속 일을 할 수 있기 때문에 사용자에게 더 빠른 응답을 제공해 줄 수 있다.\nResource Sharing: 쓰레드는 최소한만 생성하고 대부분 공유하기 때문에 메모리를 덜먹는다\nEconomy: 이건 위의 장점에 의해 산출되는 장점인데 대부분 공유하기 때문에 Creating 혹은 Context Switching 을 할 때 일반적인 프로세스를 생성하거나 갈아치울때보다 현저리 적은 오버헤드를 가진다\nUtilization of MP(Multi Processor) Architectures: 프로세서가 여러개인 경우 쓰레드를 여러 프로세서에서 실행시켜 병렬작업이 가능해진다.\n\n\n쓰레드 종류는 Kernel Thread 와 User Thread 가 있댄다\n\nKernel Thread 는 쓰레드의 존재를 커널도 알고 따라서 Context switch 도 커널에 의해 이루어지지만\nPOSIX 같은 User Thread 는 쓰레드의 존재를 커널은 모르고 라이브러리 형태로 제공된다 → 따라서 Context switch 등도 프로세스 딴에서 관리된다.\n\n\n"},"os.fall.2022.cse.ewha.ac.kr/4.-Process-Management":{"title":"4. Process Management","links":[],"tags":[],"content":"Process Lifecycle §\nProcess Creation §\n\n프로세스는 (Init process 가 아니라면)부모프로세스가 반드시 존재하고, 부모 프로세스를 복제하는 방식으로 자식 프로세스가 생성된다\n\n뭐 init process 는 알다시피 sysvinit 이나 systemd 등이 있겠제\n따라서 프로세스는 init process 를 루트로 하는 트리형식의 계층 구조를 형성하게 된다\n이렇게 자식을 복제하는 것은 fork() 시스템 콜을 이용해 수행할 수 있다\n프로세스 생성이 시스템 콜인 이유는 사용자 프로세스가 직접 하기에는 어려운 작업이고 아마 보안상의 문제도 껴있을거다\n\n\n자식 프로세스도 당연히 프로세스니까 자원을 할당받을텐데 여기에는 몇가지 정책(모델) 이 존재한다\n\n자원을 부모와 공유하여 운영체제로부터 받지 않는 모델\n자원을 부모와 일부만 공유하고 나머지는 운영체제로부터 할당받는 모델\n부모와 공유하지 않고 전부 운영체제로부터 할당받는 모델\n\n\n생각해보면 자식 프로세스는 부모 프로세스와 독립적인 프로세스이기 때문에 자원을 공유하지 않고 운영체제로부터 할당받는게 맞는 거 같지만\nUNIX 같은 경우에는 효율성을 위해 일단 부모와 공유하는 방식을 사용한다\n\n뭔소리냐면\nfork() 과정에서 부모꺼를 복제한다고 했자네\n근데 자원을 복제하면 결국에는 똑같은게 두개가 생길거 아님 → 뭐 프로세스의 Data, Code, Stack 같은게 똑같은게 두개가 생기게 될거아님\n이게 좀 낭비같은거야\n그래서 UNIX 에서는 일단 자원을 복사하지 않고 공유하고 있다가 부모랑 달라지면 그때 복사를 하는 방식을 이용한다\n즉 Lazy copy 라고 말할 수 있는거임 → 이걸 Copy-On-Write (COW) 라고 표현한다\n\n\n\n\n복제하는 과정을 좀 더 자세히 살펴보면\n\n일단 fork() 가 불려지면 운영체제는 PID 를 제외한 부모의 모든 것(뭐 PCB나 바이너리 같은것들 → 앞에서 배운 Process context 에서 PID 만 뺀거라고 생각해도 된다)을 복사한다\n그리고 자식 프로세스에게 새로운 주속 공간을 할당한다\n\n\n하지만 fork() 만 존재한다면 모든 프로세스가 부모랑 같은 작업만 할거 아니냐 → 그래서 (일반적으로는) fork() 이후에 exec() 이라는 시스템 콜이 사용된다\n\nexec() 은 기존에 존재하던 프로세스에 새로운 프로그램을 덮어 씌우는 시스템 콜인데\n일반적으로 fork() 이후에 exec() 시스템 콜이 호출되는 식으로 프로그램이 프로세스로 변환된다\n따라서 프로세스의 생성은 fork → exec 이 두가지 단계를 거친다고 할 수 있다\n물론 저 두 단계는 독립적이어서 fork() 만 해서 부모를 복사하기만 할 수도 있다\n\n\n\nProcess Execution §\n\n자식 프로세스가 생성되었을 때 부모가 취할 수 있는 동작은 두가지가 있는데\n\n그냥 별개의 프로세스로써 자식이랑 같이 공존하며 실행되거나\n자식 프로세스가 종료되어야 진행이 가능한 경우에는 block 을 먹어서 자식이 종료될때까지 기다릴 수도 있다 (wait() 시스템 콜)\n\n\n\nProcess Termination §\n\n프로세스가 자발적으로 종료될 때에는 일단 exit() 시스템 콜을 이용한다\n\n프로그래밍 언어에서 지원하는 라이브러리(뭐 예를 들면 go 의 os 같은 거) 를 통해 exit() 시스템 콜을 호출할 수도 있고\n아니면 프로그램 코드가 종료되면 (뭐 마지막 중괄호가 닫히는 등의 main() 함수가 리턴되는 시점) exit() 시스템 콜이 작동되도록 컴파일러가 넣어주는 등의 방법 등\n여러가지의 방법이 있지만 어쨋든 자발적으로 프로세스가 종료될때는 exit() 시스템 콜이 무조건 호출된다\nexit() 이 호출된 다음에는 자식이 부모에게 output data 를 보내게 되고\n프로세스의 각종 자원들이 운영체제한테 반납된다\n\n\n그럼 자발적이지 않은 경우는 무엇이냐 → 부모 프로세스가 자식의 수행을 종료시키는 경우가 존재한다\n\n뭐 자식이 너무 많은 자원을 먹어서 한계치를 넘어선 경우랄지\n자식이 하고 있는 작업이 불필요해진 경우랄지\n부모가 종료된 경우랄지\n\n운영체제는 (init process 가 아닌 이상) 부모가 없는 프로세스가 존재하도록 하지 않는다\n따라서 부모가 종료될때는 자식을 전부 종료시킨 후에 종료되도록 하는데\n자식한테 또 자식이 있을 경우에는 또 그 자식이 종료되는 절차를 밟을 거 아님\n그래서 부모가 종료될때는 자식을도 단계적으로 종료되게 된다\n\n\n\n\n\nProcess Syscall §\nFork §\n\n\n이제 이건 fork() 시스템 콜에 대한 C 언어 코드 예제인데\n일단 흔히 나올 수 있는 질문 중 하나는 부모 코드에 fork() 가 있는데 부모 코드를 그대로 복제하면 자식 코드에도 fork() 가 있을 것이고 그럼 자식도 fork() 를 해서 자식이 무한대로 생성되는거 아니냐 인데\n\n아니다\n앞서 fork() 를 할 때에는 Process context 전체를 복사한다고 했자네\n따라서 PC 값도 복사가 되기 때문에 자식 프로세스는 프로그램의 맨 처음부터 실행하는 것이 아니라 fork() 가 호출된 바로 다음 시점부터 실행된다\n\n\n그럼 PC 값이 복사된다면 부모와 자식은 같은 Physical memory address 의 instruction 을 실행하게 될까\n\n그것도 아니다\n왜냐면 PC 에 들어가는 값은 Virtual memory address 이기 때문에 PC 값이 같긴 하지만 실제로 참조하는 Address space 는 다르고 따라서 다른 Physical memory address 를 참조하게 된다\nPhysical memory address 에 대해서 CPU 는 알지 못한다 → CPU 가 사용하는 주소는 전부 Logical (뭐 Virtual address랑 거의 같다고 재철소장님이 그랬으니까) 이고 이걸 Physical address 로 바꾸는 건 CPU 가 아니라 Memory Management Module 이 BASE 랑 LIMIT 레지스터 값을 이용해 수행한다\n참고\n\nDifference between program counter in the executable and program counter in the main memory\nDoes the program counter generate the virtual address or a physical address in a cpu?\n\n\n\n\n부모와 자식이 코드가 동일하다면 어떻게 다른 작업을 하도록 할 수 있을 까?\n\nC 언어에 구현되어 있는 fork() 함수는 호출했을 때에 PID 값을 반환하도록 되어 있는데\n생각해보면 호출된 이후에는 부모와 자식 이렇게 프로세스가 두개가 생기므로 fork() 함수는 각 프로세스에게 두번 PID 값을 반환한다고 생각할 수 있다\n근데 이때 부모 프로세스에게는 양수 정수값을 반환하는 방식으로 생성된 자식 프로세스의 PID 값을 반환해주고\n자식 프로세스에게는 0을 반환해준다\n이걸 이용해서 하나의 코드로 부모와 자식에게 다른 일을 시킬 수 있다\n\n\n\nExec §\n\n\nexec() 시스템 콜은 위에서 말한 것처럼 새로운 프로그램으로 현재 프로세스를 덮어씌우는 것을 수행한다\n그래서 C 언어에서는 이 시스템 콜을 위해 execlp() 라는 함수를 제공해주는데\n뭐 문법은 위에 사진 보던가 너가 찾아봐라\n\n3번째 인자부터 해당 프로그램의 Args 들이 들어가는데\n마지막 인자는 null string 을 넣어서 닫아줘야 한다네\n\n\n중요한건 exec() 시스템 콜을 호출하고 나면 새로운 프로그램이기 때문에 main() 함수의 맨 첫번째 줄부터 실행하게 된다\n\n어찌보면 당연한 얘기지 → 프로그램이 새로 프로세스가 됐는데 당연히 Process context 는 없는게 맞지\n\n\n다음은 exec() 을 실행하고 난 뒤에는 원래의 프로그램으로 되돌아오지는 못한다는 거다\n\n이것도 당연한 얘기다 → 기존의 프로세스가 새로운 프로그램으로 덮어씌워졌으니까 원래꺼는 없어지고 되돌아오지도 못하는게 인지상정\n\n\n마지막으로는 fork() 와 exec() 은 별개의 시스템 콜이기 때문에 fork() 없이도 exec() 을 호출하는게 가능하다는 거다\n\n따라서 이때에는 자식이 생기는 방식이 아니라 그냥 나 자신이 새로 태어나게 된다\n\n\n\nWait §\n\n\nwait() 은 별거 없다\n그냥 부모가 자식 끝날때까지 block 되어 기다리게 하는 시스템 콜이 wait() 이다\n\n그래서 wait() 이 호출되면 커널은 해당 프로세스를 block 시켰다가\n해당 프로세스의 자식 프로세스가 모두 종료되면 다시 ready 로 바꾼다\n\n\n위 그림은 그냥 예제고 → 읽어보면 걍 별거 없다\nwait() 을 이용한다고 할 수 있는 프로그램이 Shell 프로그램이다\n\n결국에는 쉘의 경우에도 입력한 프로그램을 시키는 것이기 때문에 해당 프로그램을 자식 프로세스호 실행시키고 wait 하다가 끝나면 다시 커서를 깜빡이게 하는 방식으로 활용한다.\n\n\n\nInter Process Conmunication (IPC) §\n\nIndependent Process: 프로세스는 기본적으로 각자 독립적으로 작동하고 다른 프로세스에 영향을 끼지지 않는다 (뭐 부모 - 자식 관계는 예외)\nCooperating Process: IPC 를 이용하면 다른 프로세스의 수행에 영향을 끼칠 수 있다\n\nMessage Passing §\n\n\nIPC 의 분류중에 Message Passing 은 일단 커널을 브로커로 해서 메시지를 전달하는 방법 (Message System)이다\n\n따라서 공유 메모리나 공유 변수 등을 사용하지 않는다\n\n\n뭐 인터페이스가 두가지 종류가 있다네\n\nDirect Communication\n\n\n얘는 수신 프로세스를 명확하게 명시하는 방식이랜다\n\n\nIndirect Communication\n\n\n그리고 얘는 수신 프로세스를 명시하지 않고 메일박스(?) 나 포트번호 등을 이용해서 메시지를 간접적으로 전달하는 방식이라네\n\n\n\n\n\nShared Memory §\n\n\n얘는 말 그대로 공유 메모리를 커널로부터 할당받아서 두 프로세스가 메모리에 존재하는 데이터를 공유하는 방법이다\n얘도 당연히 커널의 힘을 빌려야 하긴 하지만 Message Passing 의 경우에는 매번 커널에 의존하지만 얘는 공유 메모리를 처음 매핑할때만 커널에 의존한다는 차이점 정도가 존재한다\n\nThread §\n\n뭐 쓰레드는 프로세스가 아니기 때문에 IPC 라고 하기에는 좀 뭐하지만\nThread 끼리는 메모리를 공유하기 때문에 통신이 아주 간편맨하댄다\n"},"os.fall.2022.cse.ewha.ac.kr/5.-CPU-Scheduling":{"title":"5. CPU Scheduling","links":[],"tags":[],"content":"CPU, IO Burst §\n(사진 사라짐)\n\n프로세스가 실행되는 것은 (일반적으로) CPU 를 연속적으로 사용하다가 IO 때문에 Block 되있거나 하는 것의 반복이라고 할 수 있는데 이때\nCPU 를 연속적을 사용하는 구간을 CPU Burst 라고 하고\nIO 때문에 Block 먹어있는 구간을 IO Burst 라고 한다\n\nCPU, IO Bound Job §\n(사진 사라짐)\n\n이 그래프는 한 CPU Burst 의 실행시간과 CPU Burst 의 빈도를 나타낸 그래프인데\n보면 왼쪽은 CPU Burst 의 기간이 아주 짧고 빠르게 반복된다\n\n이것은 잦은 IO 에 의해 CPU Burst 와 IO Burst 가 빈번하게 반복되는경우인데\n이러한 Job (== Process) 들을 IO Bound Job 이라고 한다\n일반적으로 IO 는 표준 입출력 등의 사람과 Interaction 하기 위한 것이 많기 때문에 사람과의 interaction 이 잦은 경우에 IO Bound Job 이 된다\n\n\n그리고 오른쪽의 Job 들은 한번 CPU 가 잡으면 오랫동안 사용하여 CPU Burst 의 기간이 길고 따라서 빈도는 낮아지는데 (당연히 한번 잡았을때 길게 쓰니까 빈도는 작아질 수 밖에 없다)\n\n이러한 Job 들을 CPU Bound Job 이라고 부르고 일반적으로 연구 등의 목적을 위해 복잡한 계산을 오랫동안 진행하는 Job 들인 경우가 많다\n\n\n뭐 그래서 IO Bound Job 이 사람과의 상호작용이 잦기 때문에 CPU Bound Job 이 너무 CPU 를 오래 잡고 있어 사용자 Response 가 늦어지는 일이 벌어지지 않게 하기 위해 CPU Scheduling 을 한다네\n\nScheduler, Dispatcher §\n\nCPU Scheduler: Ready 인 프로세스 중에 Running 상태가 될 프로세스를 고르는 커널 프로세스\n\nCPU Scheduling 이 발생하는 경우는 대표적으로 다음과 같다\n\n프로세스가 CPU Time 을 _자진 반납_하는 경우 (Non-preemptive)\n\nIO 등의 사유로 CPU Time 을 반납 (Running → Blocked)\nProcess Terminate 로 CPU 반납 (Running → Exit)\n\n\n프로세스가 CPU Time 을 빼앗기는 경우 (Preemptive)\n\nTimer interrupt (Running → Ready)\nIO 가 완료된 프로세스의 우선순위가 현재 프로세스보다 높을 때 (Blocked → Ready)\n\n\n\n\n\n\nDispatcher: 현재의 프로세스에서 CPU Scheduler 가 고른 프로세스로 Context switch 를 진행하는 커널 프로세스\n\nCPU Scheduling §\n고려사항들 §\n\nReady 상태인 (CPU Burst 에 진입한) 프로세스 중 누구한테 CPU 를 줄 것인가?\n한번 CPU 를 받았으면 끝날때까지 계속 쓰게 할 것인가 아니면 중간에 뺏을 것인가?\n\nPerformance Index (Measure, Criteria) §\n\nPerformance Index 는 성능을 측정하는 척도를 의미하는데 아래와 같이 두개로 나눌 수 있다\nSystem Performance: 얼마나 시스템의 자원을 효율적으로 굴리느냐\n\nCPU Utilization: 얘는 CPU 이용률을 의미한다\n\n“률” 이기 때문에 당연히 전체에서 부분이 차지하는 비율을 의미하는데\nCPU Utilization 에서는 “시간” 을 기준으로 측정한다 → 즉, 시스템이 작동하고 있는 전체 시간 중에서 CPU 가 일을 하고 있는 비율이 얼마냐\n\n\nThroughput: 얘는 처리량을 의미하는데\n\nCPU Utilization 이 시간에 대한 값이었다면 얘는 양을 나타내는 값이다\n즉, 단위시간동안 처리한 작업의 양을 의미하는 것\n\n\n\n\nProgram Performance: 사용자가 느끼는 프로세스의 빠릿빠릿함\n\nTurnaround Time: 한번의 CPU Burst 동안 걸린 시간의 총합\nWaiting Time: 한번의 CPU Burst 동안 CPU 가 할당되지 않고 기다린 시간의 총합\nResponse Time: 한번의 CPU Burst 동안 CPU 가 처음으로 할당되기까지 걸린 시간\n그냥 이렇게만 보면 멍게소리인가 싶을텐데 한번의 CPU Burst 에 어떤 일들이 일어나는지를 생각해보면 알기 쉽다\n\n먼저 IO Burst 가 끝나고 CPU Burst 에 들어온 시간이 0초라고 해보라\n그러고 바로 CPU 를 할당받을 수 있으면 기모찌하겠지만 인생이란게 그렇게 녹록하지 않아서 4초에 CPU 를 할당받아서 작업을 했다라고 치면\n첫 4초가 Response Time 이 되는 것\n\n즉, CPU Burst 가 시작된 이래로 얼마나 빨리 CPU 가 할당되었느냐 이다\n\n\n그리고 만일 Preemptive 로 스케줄링되어 6초에 CPU 를 빼앗겼다가 7초에 다시 받고 10초에 IO 가 생겨서 IO Burst 로 빠져나갔다고 치면\n일단 기다린 시간을 다 합쳐보면 맨 처음 4초에 중간에 1초 기다렸으니까 5초 → 이게 Waiting Time 이 된다.\n\n즉, Waiting Time 은 처음의 Response Time에다가 CPU Burst 중간중간에 쉬는시간까지 다 합친 값이다\n\n\n그리고 전체적으로는 10초가 걸렸으므로 이게 Turnaround Time 이 된다\n\n즉, Turnaround Time 은 IO Burst 사이의 시간 간격이라고 생각할 수도 있고\nWaiting Time 에다가 CPU Time 까지 합친 시간이라고 생각할 수도 있다\n\n\n\n\n\n\n\n스케줄링 알고리즘 분류 §\n\nPreemptive: 하나의 프로세스가 너무 오래 CPU 를 차지하지 못하도록 중간에 뺏는 알고리즘\nNon-preemptive: 하나의 프로세스가 CPU 를 먹으면 IO 등의 이슈가 없는 한 계속 들고 있게 하는 알고리즘\n\nPriority Scheduling §\n\n그냥 단순하게 생각해서 우선순위에 따라 다음 프로세스를 선택하는 방식인데\nPreemptive 의 경우에는 당연히 우선순위가 높은 놈이 들어오면 빼앗고 Non-preemptive 의 경우에는 높은놈이 들어와도 빼앗지 않았다가 그놈이 끝나면 그 다음 우선순위 높은놈에게 주는 방식\n주의할 점은 일반적으로 UNIX(Linux) 계열에서는 숫자가 낮을수록 우선순위가 높은 거다\n\nSyslog 생각해봐도 emerg 가 0 이잖여\n\n\n\nStarvation, Aging §\n\n이후에 등장하는 스케줄링 알고리즘에서 Starvation 이라는 말이 나오는데 이건 알고리즘의 부작용으로 특정 프로세스가 CPU 를 할당받지 못하는 상황을 의미한다\n\n만일 우선순위가 낮은 프로세스의 경우 해당 프로세스보다 우선순위가 높은 프로세스가 항상 존재한하면 해당 프로세스는 영원히 CPU 를 받지 못한다.\n\n\n이를 해결하기 위한 방법으로 Aging 이 있는데 이건 우선순위가 낮은 프로세스가 오랫동안 CPU 를 할당받지 못하면 자연스럽게 우선순위가 높아지게 하는 방법을 의미한다\n\nScheduling Algorithms §\nFCFS (First Come First Serve) §\n\n\n뭐 별거 없다 → 선입선출\n\n당연히 무지성 선입선출이기 때문에 Non-preemptive 이다\n\n\n\n얘의 문제점은 예상하시는 바와 같이 앞에 오래걸리는 놈이 하나 버티고 있으면 그 뒤에 있는 놈들은 다 지연된다는 거다\n\n\n예를 들어 아래의 두개 상황을 비교해봐라\n(사진 사라짐)\n\n첫번째의 경우는 앞에 오래걸리는 애가 있어서 평균 Waiting Time 이 17이나 되지만\n만일 앞에 짧은 애가 오면 평균 Waiting Time 은 3으로 거의 1/6 이 줄어든다\n이렇듯 FCFS 에서 앞에 오래걸리는 한놈때문에 나머지가 전부 지연되는 것을 Convoy effect 라고 하더라\n\n\n\nSJF (Shortest Job First) 혹은 SPN (Shortest Process Next) §\n\n\nFCFS 를 보면서 ‘그럼 제일 적게걸리는 놈한테 먼저 주면 되는거 아닌가’ 라고 생각했으면 이게 그거다\n\n\n즉, CPU Time 이 제일 적은 놈에게 우선적으로 CPU 를 주는 것\n\n\n얘는 이제 Non-preemptive 하고 Preemptive 두가지 버전이 있는데\n\n\nNon-preemptive SJF 은 일단 CPU 를 CPU Time 이 적은놈한테 주되 이걸 빼앗을 수는 없으므로 더 짧은 놈이 들어와도 일단은 현상유지하는 것이고\n\n\nPreemptive SJF 는 CPU Time 이 더 짧은 놈이 오면 CPU 를 빼앗아서 이놈한테 주는거다\n\n그런데 이때 CPU Time 은 지금 실행중인 놈의 남은 시간과 새로운 놈의 시간을 비교하기 때문에 SRTF (Shortest Remaining Time First 혹은 그냥 SRT) 라고도 부른다\n또한 이 경우는 평균 Waiting Time 이 최소가 되는 것으로 알려저 있다 (Waiting Time Optimal)\n\n똑똑이들이 증명해놨다네\n\n\n\n\n\n뭐 아주 좋아보이지만 아쉽게도 얘도 문제가 있다\n\nStarvation: 눈치챘겠지만 앞에 짧은 애들만 오면 긴놈은 절대로 CPU 를 받을 수 없다.\n그리고 CPU Time 는 사전에 알지 못하는 값이다\n\n\n\nCPU Time 을 예측하는 방법으로 Exponential Averaging 이라는게 있는데 다른 분야에도 등장하는 개념이라니까 간단하게 짚고 넘어가면\n\nt(n) 은 n 번째의 CPU Time 이고\n따우(n) 은 n 번째의 CPU Time 예측값일때\nExponential Averaging 의 공식은 다음과 같다\n\n(사진 사라짐)\n\n이 식을 전개해보면\n\n(사진 사라짐)\n\n가 되는데 상수 a 가 0 &lt; a &amp;&amp; a &lt; 1 이기 때문에 제곱할수록 작아진다\n즉, 제일 최근의 값은 1에 그나마 가까우므로 가중치가 높아지고 옛것으로 갈수록 0에 가까워지니까 가중치가 낮아지는 것으로도 생각할 수 있는 것\n찾아보니까 이 개념은 머신러닝에서도 사용되는듯\n\n\n\nRR (Round Robin) §\n\n지겹다 지겨워 그냥\n알다시피 무지성 돌라돌라골림판이다\n\n즉, 일정한 Time Quantum 으로 CPU Time 을 난도질해서 해당 시간이 끝나면 다른 프로세스에게 또 Time Quantum 만큼의 CPU Time 만 주는 방법이다\n\n\n얘는 다양한 CPU Time 을 가지는 프로세스들이 섞여있을 때 맛집이 된다\n\n스케줄링 할 때 CPU Time 을 예측할 필요도 없고\nCPU Time 크든 작든 돌아가며 CPU 가 할당되므로 Starvation 에 빠질 우려도 없다\n심지어 CPU Time 길수록 Waiting Time 도 늘어나는 합리성까지 보여준다\n\n\n하지만 CPU Time 이 전부 똑같을때는 똥된다\n\n단순히 FCFS 를 생각해도 100 짜리 4개가 들어오면 100, 200, 300, 400 의 시간에 프로세스가 종료되지만\nRR 로 돌리면 다같이 돌다가 전부 400에 프로세스가 종료되기 때문\n이렇듯 CPU Time 이 같은 경우에는 비효율적이나 일반적인 상황이 아니기 때문에 대부분 효율적이다\n\n\nTime Quantum 이 극단적이 되면 어찌되는가\n\nq 가 너무 커지면 FSFC 와 다를바가 없어서 비효율적이고\nq 가 너무 작아지면 Context Switching 의 오버헤드가 너무 커져 비효율적이 된다\n\n\n\nMulti-level Process Queueing §\n\n위에 소개된 알고리즘들은 전부 프로세스를 큐 하나에 때려박고 적당히 꺼내서 CPU 를 할당해주는 방식이었다면\n지금부터 소개되는 알고리즘들은 프로세스를 우선순위에 따라 여러 큐에 넣어서 관리하는 방법들이다\n이러한 방식은 일반적으로 큐마다 다른 스케줄링 알고리즘을 사용하고\n상위 우선순위의 큐가 비지 않아 Starvation 이 발생할 것을 방지하기 위해 CPU 를 차등 분배한다\n\n즉, 상위 우선순위의 큐가 비어야만 하위 큐로 가는게 아니고\n우선순위가 높은 큐에는 CPU 를 더 많이 할당해주고 낮은 큐에는 적게 할당하는 식으로 유도리있게\n\n\n\nMulti-level Queue §\n(사진 사라짐)\n\n얘는 프로세스의 특성에 따라 우선순위를 두고 우선순위에 따른 큐를 여러개 만들어 상위 우선순위의 큐가 비어야 그 아래 큐에 있는 프로세스에게 CPU 가 할당될 수 있도록 하는 Preemptive 한 방식이다\n\n위 그림은 그렇게 여러개의 큐를 나누어놓은 예시 그림임\n\n\n하지만 이러한 방식은 우선순위 변동의 유연함이 없어 문제가 있더라\n\nMulti-level Feedback Queue (Feedback Scheduling) §\n(사진 사라짐)\n\n얘는 RR 방식의 큐를 여러개 준비해놓고 아래로 내려갈수록 Quantum 값이 증가하게 해놓은 다음\n처음 들어온 프로세스는 제일 우선순위가 높은 큐에 넣고\nQuantum 내에 끝내지 못하면 그 아래 큐로 내려보내는 방식이다\n이 방식은 SJF 알고리즘에서 CPU Time 을 알 수 없다는 단점을 해결했다고 볼 수 있는데 왜냐면\n일단 처음에는 CPU Time 을 알 수 없으니까 Quantum 을 짧게 하는 대신 우선순위를 높여주고\n해당 Quantum 내에 끝내지 못했다면 Quantum 을 좀 더 오래 가져가는 대신 우선순위가 낮아지게 함으로써\n자연스럽게 빨리 끝나는 프로세스는 우선순위가 높아지고 오래걸리는 프로세스는 우선순위가 낮아지는 효과를 볼 수 있다\n\n그 외의 여러가지 CPU Scheduling 방식들 §\nMulti-processor Scheduling §\n\n프로세스들이 고만고만한 경우 (Homogeneous): 하나의 큐에 다 때려넣고 여러개의 CPU 들이 나눠먹거나\n\n반드시 특정 CPU 에서만 실행되어야 하는 경우에는 걔를 위해 CPU 하나를 할당해주고 나머지를 나눠먹거나\n\n\nCPU 부하 분산 (Load Sharing): 놀고 있는 CPU 가 없도록 하기 위해 공동 큐를 두거나 CPU 마다 큐를 구성\nSymmetric Multiprocessing: CPU 들이 동등한 자격으로 스스로 스케줄링 하는 방식\nAsymmetric Multiprocessing: 얘는 마스터를 선출하는거마냥 스케줄링 작업을 전담하는 CPU 를 하나 선출해서 나머지는 이놈이 스케줄링한거에 그냥 따르는 방식\n\nReal Time Scheduling §\n\n일반적으로 Real Time 이라고 하면 주어진 시간 내로 반드시 종료되야 하는 것을 의미하는데\nHard Real Time: 말 그대로 → 시간 내에 반드시 끝나야 함\nSoft Real Time: 얘는 시간 내에 끝나야 하긴 하지만 그렇지 못한다고 해서 큰 문제가 생기지 않는 경우를 의미하는데\n\n그냥 일반적인 스케줄링에서 우선순위를 좀 높여주는 방식으로 해결 가능하고\n동영상 재생이 대표적인 예시다 → 1초에 24프레임 이상을 로드해야되지만 그렇지 못했다고 해서 지구멸망은 아닌\n\n\n\nThread Scheduling §\n\nUser Thread 의 경우: Local Scheduling 이라고 부르는데 OS 는 이 쓰레드의 존재를 모르기 때문에 POSIX Thread 같은 라이브러리들이 직접 해준다\nKernel Thread 의 경우: Global Scheduling 이라고 부르는데 Short-term scheduler 가 프로세스 스케줄링하는것과 동일하게 해준다\n\nAlgorithm Evaluation §\n\n\nQueueing Model: 아래 그림처럼 입력 데이터(Arrival Rate) 를 확률분포로 주고 이때의 출력(Service Rate) 를 이용해 성능을 측정\n\n다분히 이론적이어서 많이는 사용하지 않는댄다\n\n(사진 사라짐)\n\n\nImplementation &amp; Measurement: 실제로 코드를 작성해 커널을 빌드하여 성능 측정\n\n\nSimulation: 커널 전체가 아닌 해당 알고리즘만 코드로 작성해 실제 OS에서의 작동 방식을 분석해 만든 입력 데이터 (Trace) 를 이용한 방법\n\n"},"os.fall.2022.cse.ewha.ac.kr/6.-Process-Synchronize":{"title":"6. Process Synchronize","links":[],"tags":[],"content":"Concurrency, Race Condition §\n(사진 사라짐)\n\n일반적으로는 위 그림처럼 데이터를 저장하는 곳하고 연산하는 곳하고는 분리되어 있으며\n연산하는 곳에서 데이터를 읽어들여 연산한 다음 저장하는 방식으로 작동되는데\n\n(사진 사라짐)\n\n위 그림처럼 동일한 데이터에 여러 연산이 접근하게 되면 문제가 생길 수 있다\n이렇게 여러 연산이 하나의 데이터에 동시에 접근하는 문제를 Concurrency Problem, 동시성 문제 라 부르고\n동시성 문제가 발생하게 되는 상황을 연산간 경쟁한다는 의미로 Race Condition 이라고 부르더라\n이를 해결하기 위해서는 데이터의 접근 순서를 제어하는 로직이 필요하고 이런걸 Process Synchronization (프로세스 동기화) 라고 한다.\n\nCommon Race Condition Situations §\n\n커널 데이터\n\n\n일반 프로세스의 경우에는 자신만의 메모리 공간이 있기 때문에 동시성 문제 잘 발생하지 않지만\n\n\n커널의 경우에는 여러 프로세스가 Syscall 등을 이용해 공유할 수 있고\n(사진 사라짐)\n\n위 처럼 프로세스가 Syscall 을 해 커널모드에서 실행되다가 타임아웃이 난 후에 다른 프로세스로 넘어갔다가 여기서도 Syscall 을 걸어 커널 데이터를 변경하는 경우에 동시성 문제가 생길 수 있다\n이때는 커널모드일때는 CPU 를 Preempt 하지 못하게 하고 커널모드가 끝나야 빼앗을 수 있게 함으로써 해결할 수 있다\n\n\n\n커널모드에서 작업을 하다가 인터럽트가 걸리면 하던걸 멈추고 또 다른 커널 작업인 인터럽트 핸들링을 하게 되므로 이런 경우에도 문제가 생긴다\n(사진 사라짐)\n\n위 그림이 그 예시인데\n이러한 경우는 커널 모드 실행중일때는 인터럽트가 걸리지 않게 하는 방식으로 해결할 수 있다\n\n\n\n\n공유 메모리, 쓰레드\n\n일반 프로세스에서 동시성 문제가 발생하는 경우 중 제일 흔한거는\n프로세스 간 공유 메모리를 할당받았거나\n멀티쓰레드 프로그래밍을 할 때이다\n\n멀티쓰레드의 경우에는 쓰레드 간 메모리가 공유되기 때문에 동시성 문제가 생길 수 있다\n\n\n\n\n\nHandling Concurrency §\nCritical Section §\n(사진 사라짐)\n\n코드 상에서 공유 데이터 공간에 접근하는 부분을 Critical Section 이라고 한다.\n그리고 Entry / Exit Section 에서 Critical Section 에 들어가는 프로세스들을 Lock 을 거는것처럼 관리하게 된다.\n별로 중요한건 아니지만 공유데이터에 접근하지 않는 부분을 Remainder Section 이라고 한다\n\n충족해야 할 조건들 §\n\nMutual Exclusion: 상호 배제 → 하나의 프로세스가 Critical section 에 들어가 있으면 다른 프로세스는 들어가서는 안된다\nProgress: 현재 Critical section 에 들어가있는 프로세스가 없다면 Critical section 에 들어가고자 하는 프로세스는 거기 에 들어갈 수 있어야 한다.\nBounded Waiting: 다른 프로세스가 Critical section 에 들어가 있어서 나머지 프로세스가 대기해야 한다면, 대기 시간이 유한해야 한다.\n\n즉, 하나의 프로세스가 들어가서 빠져나오지 않는 상황이 발생하거나\n특정한 몇개의 프로세스만이 Critical section 에 접근하여 나머지 프로세스들은 들어갈 수 없는 상황 (뭐 예를 들면 두개의 프로세스가 번갈아가며 들어가 다른 프로세스가 접근할 수 없는 상황) 이 되면 안된다.\n\n\n\nAlgorithm 1 §\n\n프로세스 0 번의 코드가 다음과 같고\n\n// global variable: int turn = 0;\ndo {\n\twhile (turn != 0);\n\tcritical_section();\n\tturn = 1;\n\tremainder_section();\n} while (1);\n\n프로세스 1 번의 코드가 다음과 같다면\n\n// global variable: int turn = 0;\ndo {\n\twhile (turn != 1);\n\tcritical_section();\n\tturn = 0;\n\tremainder_section();\n} while (1);\n\n일단 Mutual Exclusion 은 달성할 수 있다\n\n0번 프로세스는 turn 이 0이 될 때까지 기다리고\n1번 프로세스는 turn 이 1이 될 때까지 기다리기 때문에\n두놈이 같이 들어가는 상황은 막을 수 있음\n\n\n하지만 Progess 는 안된다\n\n왜냐면 한놈이 Critical section 에 들어가는 것이 다른놈에게만 의존하기 때문에 한놈이 안드가게 되면 다른놈도 들어가지 못한다\n가령 1번이 들어가려면 turn 값이 1이어야 되는데 0번이 들어가지 않은 경우에는 turn 값이 0으로 남아있어 1번이 절대 들어가지 못하게 된다\n\n\n\nAlgorithm 2 §\n\n이번에는 프로세스 0 번의 코드가 다음과 같고\n\n// global variable: boolean flag[2] = {false, false};\ndo {\n\tflag[0] = true;\n\twhile (flag[1]);\n\tcritical_section();\n\tflag[0] = false;\n\tremainder_section();\n} while (true);\n\n프로세스 1 번의 코드가 다음과 같다면\n\n// global variable: boolean flag[2] = {0, 0};\ndo {\n\tflag[1] = true;\n\twhile (flag[0]);\n\tcritical_section();\n\tflag[1] = false;\n\tremainder_section();\n} while (true);\n\n이번에도 Mutual Exclusion 은 달성할 수 있다\n\n서로의 flag 가 올라가있는지 체크하면서 대기하기 때문에\ncritical_section() 에는 한번에 한놈만 드갈 수 있다.\n\n\n그리고 Algorithm 1 에서의 문제점도 해결할 수 있다\n\n프로세스가 연속해서 들어가고싶어할 경우에도 상대방의 flag 는 계속 false 이기 때문에 문제되지 않는다\n\n\n하지만 이 경우에도 Progress 가 해결되지는 않는다\n\n그건 Context switch 때문인데\n프로세스 0번이 flag[0] 을 true 로 바꾼 다음에 Contect switching 이 일어나서\n프로세스 1번이 flag[1] 을 true 로 바꾼다면\n지금 아무도 드가있지 않지만 둘 다 true 로 되어 있어 아무도 들어가지 못하는 상황이 됨\n\n\n\nAlgorithm 3 (Peterson’s algorithm) §\n\n이번에는 프로세스 0 번의 코드가 다음과 같고\n\n// global variable: int turn = 0;\n// global variable: boolean flag[2] = {false, false};\ndo {\n\tflag[0] = true;\n\tturn = 1;\n\twhile (flag[1] &amp;&amp; turn == 1);\n\tcritical_section();\n\tflag[0] = false;\n\tremainder_section();\n} while (true);\n\n프로세스 1 번의 코드가 다음과 같다면\n\n// global variable: int turn = 0;\n// global variable: boolean flag[2] = {0, 0};\ndo {\n\tflag[1] = true;\n\tturn = 0;\n\twhile (flag[0] &amp;&amp; turn == 0);\n\tcritical_section();\n\tflag[1] = false;\nremainder_section();\n} while (true);\n\n보면 Algorithm 1 과 Algorithm 2 를 합쳐놓은 느낌인데 이 경우에는 모든 경우의 수를 만족할 수 있다\n하나하나 따져보는 건 나중에 시간 많을때 해보고 그냥 느낌만 잡자면\nwhile 문에서 상대방의 flag 를 검사하기 때문에 일단 두명이 같이 드가는 것은 불가능하고\n만일 Algorithm 2 에서처럼 둘 다 flag 가 올라가있는 경우에는 turn 값을 이용해 한놈은 드갈 수 있게 해주는 방식이다\n하지만 이 방식은 작동은 하지만 다소 비효율적이다 → Busy Waiting 이기 때문\n\n어쨋든 while 문을 통해 계속 CPU 와 메모리를 먹으면서 기다리기 때문에\n불필요한 자원소모라고 할 수 있기 때문\nSpin lock 이라는 용어도 알아두라\n\n\n\nHardware approach (Atomic solution) §\n\n값을 읽는 작업과 쓰는 작업을 하나의 instruction 에서 처리할 수 있다면 동시성 문제가 좀 쉽게 해결될 수 있다\n간단하게 생각해서 아래와 같은 코드로 두 프로세스가 돌아간다고 할 때\n\n// global variable: boolean is_lock = false;\ndo {\n\twhile (is_lock);\n\tis_lock = true;\n\tcritical_section();\n\tis_lock = false;\n\tremainder_section();\n} while (1);\n\n\n두번째 줄에서 is_lock 값을 확인해서 false 가 나와 세번째 줄을 수행하려 할 때\n\nContext switch 가 일어나 다른 프로세스가 is_lock 값을 바꾸고 Critical section 으로 들어간다면\n다시 돌아왔을 때 is_lock 을 확인하지 않고 Critical section 으로 들어가기 때문에 두 프로세스가 모두 Critical section 에 진입하게 된다\n\n\n\n하지만 값을 읽는것과 쓰는 작업을 한번에 해주는 instruction 가 있다면 위와 같은 상황은 해결이 된다\n\n아래의 코드에서 test_and_set() 함수는 변수의 값을 읽는 것과 값을 true 로 바꾸는 작업을 한번에 한다고 가정하면\n\n(사진 사라짐)\n\n즉, test_and_set() 함수가 변수의 값을 읽고 false 라면 true 로 바꾸고 true 여도 true 로 바꾸는 작업을 한다면\n\n\n\n// global variable: boolean is_lock = false;\ndo {\n\twhile (test_and_set(is_lock));\n\tcritical_section();\n\tis_lock = false;\n\tremainder_section();\n} while (1);\n\n그럼 2번째 줄을 수행한 다음 Context switch 가 일어나도 is_lock 값이 이미 바뀌어있기 때문에 다른 프로세스는 Critical section 으로 드가지 못한다\n\nSemapore §\n\nSemapore 은 동시성 처리를 위한 추상 자료형이다\n\n즉, Semapore 는 Property 와 Method 만 정의되고 구현방식은 정의되지 않는다\n\n\nSemapore 의 Property 는 다음의 특징을 가져야 한다\n\nInteger: 셀 수 있는 정수값을 가진다\nSemapore 의 정수값은 자원에 접근할 수 있는 프로세스의 개수를 나타낸다\n즉, 0보다 클 경우에는 해당 프로세스가 자원에 접근할 수 있다는 것을 나타내고 그렇지 않다면 대기해야 한다는 것을 의미한다\n\n\n그리고 Method 는 다음과 같으며 해당 Method 들은 Atomic 하게 작동한다\n\nP: Semapore 의 값이 0보다 클 경우에는 1을 감소시키고 그렇지 않을 경우에는 대기한다.\n\nP 연산의 경우에는 Lock 을 거는 작업을 담당한다\n1을 감소시키기 때문에 접근할 수 있는 프로세스의 개수를 하나 감소시켜 한 자리를 차지하는 셈인 거고\n0 이하일 경우에는 대기하기 때문에 자리가 없을 경우 대기하는 것으로 해석할 수 있다\n\n\nV: Semapore 의 값을 1 증가시킨다\n\nV 연산의 경우에는 Lock 을 해제하는 작업을 담당한다\n즉, 1을 증가시키기 때문에 Lock 을 풀고 한 자리를 내어놓는 것으로 해석할 수 있다\n\n\n\n\n\nImplementation 1: Busy waiting (Spin lock) §\n\nGo 로 대충 수도코드 적어보자고\n일단 struct\n\ntype Semapore struct {\n\tcount int\n}\n\n그리고 method 두개\n\nfunc (s *Semapore) P() {\n\tfor s.count &lt;= 0 {}\n\ts.count--\n}\nfunc (s *Semapore) V() {\n\ts.count++\n}\n\n뭐 간단하죠?\n근데 위에서 언급한것처럼 이 경우에는 반복문이 돌면서 기다리기 때문에 CPU와 메모리의 낭비이다\n\nImplementation 2: Block wakeup (Sleep lock) §\n\n\n이번에는 대기할때 반복문을 도는게 아니고 아예 프로세스의 상태를 Blocked 상태로 바꿔버리는 방법이다\n(사진 사라짐)\n\n\n즉, 위 그림과 같이 IO 큐 등의 여러 큐들에 추가적으로 공유데이터에 접근하는 것을 기다리는 큐를 하나 더 둬서 대기시킨다\n\n\n그래서 보통 아래처럼 구현한다\n(사진 사라짐)\n\nPCB 큐를 둬서 하나의 세마포에 대기하도록 함\n\n\n\n간단히 수도코드 적어보자고\n\n\n세마포는 다음처럼 생각할 수 있음\n\n\ntype Semapore {\n\tvalue int\n\twait  []int\n}\n\n그리고 다음처럼 메소드들을 구현할 수 있을 것이다\n\nfunc (s *Semapore) P() {\n\tif s.value--; s.value &lt; 0 {\n\t\ts.wait = append(s.wait, os.Getpid())\n\t\tos.Block() // Pseudo method `Block()`\n\t}\n}\nfunc (s *Semapore) V() {\n\tif s.value++; s.value &lt;= 0 {\n\t\tos.WakeUp(s.wait[0]) // Pseudo method `WakeUp(pid int)`\n\t\ts.wait = s.wait[1:]\n\t}\n}\n\ns.value++; s.value &lt;= 0 의 이유: 일단 1을 더해줬는데도 0과 같거나 작다는 것은 1을 더해주기 전에는 0보다 작았었기 때문에 대기하던 프로세스가 있음을 의미\n\nBusy-wait vs Block-wakeup §\n\n일반적으로는 Block-wakeup 방식이 더 좋기는 하지만\nBlock-wakeup 방식의 Context switch 에 오버헤드가 존재하기 때문에 Critical section 이 아주 짧은 경우에는 Busy-wait 방식이 오히려 더 좋을 수 있다\n\nSemapore 종류 §\n\nCountable semapore: 값이 2 이상이 될 수 있는 세마포\n\n보통 자원의 수를 세는 용도로 사용됨\n\n\nBinary semapore(Mutex): 값이 0또는 1만이 되는 세마포\n\n프로세스의 Mutual exclusion 을 위해 사용됨\n\n\n\nDeadlock, Starvation §\n\nDeadlock 은 둘 이상의 프로세스가 서로의 이벤트 종료를 기다리고 있는 상황이라고 할 수 있다\n\n그니까 쉽게 말하면 내가 끝나려면 너가 끝나야되는데 너가 끝나려면 내가 끝나야되는 상황\n\n\nStarvation 은 둘 이상의 프로세스가 자기네들끼리만 우선권을 획득해서 일부 프로세스가 우선권을 영원히 획득할 수 없는 상태를 말한다\n이 둘은 그 다음에 나오는 굶주린 소크라테스 보면 딱 이해됨\n\nBounded-Buffer Problem §\n(사진 사라짐)\n\n이 문제는 다음과 같다:\n\n공유 메모리에 있는 버퍼에는 값을 넣을 수 있는 칸이 n 개가 있다 → Bounded-buffer, 유한 버퍼\n여러 Producer 가 값을 생산하여 버퍼의 한 칸에 채워넣는다\n여러 Consumer 는 Producer 가 생산하여 버퍼에 채워넣은 값을 가져가 비운다\n\n\n이 문제에는 다음과 같은 동시성 관리가 필요하다:\n\nProducer 혹은 Consumer 프로세스는 한번에 한놈만 공유 버퍼에 접근해야 한다\n\n만일 그렇지 않은 경우에는 두 Producer 가 한번에 같은 칸에 접근해서 하나의 값이 덮어씌워지거나\n두 Consumer 가 한번에 같은 칸에 접근해서 문제가 되거나 (뭐 같은 값을 두번 가져가거나 null 을 가져가거나 등등)\n\n\nProducer 는 비어있는 칸이 있어야 값을 쓸 수 있고 Consumer 는 채워져있는 칸이 있어야 값을 가져올 수 있다\n\n\n그래서 이 문제에는 세개의 세마포가 사용된다\n\n공유 버퍼에의 접근을 제어할 Mutex\nProducer 입장에서의 자원 관리\n\n즉, 비어있는 칸이 Producer 입장에서의 자원이므로 이것을 관리할 empty_sem 이 하나 필요하다\n\n\nConsumer 입장에서의 자원 관리\n\n즉, 채워져있는 칸이 Consumer 입장에서의 자원이므로 이것을 관리할 full_sem 이 하나 필요하다\n\n\n\n\n따라서 Producer 와 Consumer 는 다음의 과정을 거쳐 작업을 수행한다\n\nProducer\n\n비어있는 칸이 있는지 확인하고 없으면 기다림\n공유데이터에 Lock 을 걺\n데이터 입력\nLock 을 풂\n채워져 있는 칸의 개수를 1 증가시킴\n\n\nConsumer\n\n채워져 있는 칸이 있는지 확인하고 없으면 기다림\n공유데이터에 Lock 을 걺\n데이터를 가져감\nLock 을 풂\n비어있는 칸의 개수를 1 증가시킴\n\n\n\n\n이를 바탕으로 수도코드를 적어보면 다음과 같다\nProducer\n\n/**\n * Shared memory\n * var buf *bufio.ReadWriter\n *\n * Semapores\n * var mutex semapore_t = 1\n * var empty_sem semapore_t = n\n * var full_sem semapore_t = 0\n */\nfunc produce() []byte { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tvalue := produce()\n\t\tP(empty_sem)\n\t\tP(mutex)\n\t\tbuf.Write(value)\n\t\tV(mutex)\n\t\tV(full_sem)\n\t}\n}\n\nConsumer\n\n/**\n * Shared memory\n * var buf *bufio.ReadWriter\n *\n * Semapores\n * var mutex semapore_t = 1\n * var empty_sem semapore_t = n\n * var full_sem semapore_t = 0\n */\n \nfunc consume(value []byte) { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tP(full_sem)\n\t\tP(mutex)\n\t\tvar value []byte\n\t\tbuf.Read(value)\n\t\tV(mutex)\n\t\tV(empty_sem)\n\t\tconsume(value)\n\t}\n}\n\n세마포 값은 다음과 같은 이유이다\n\nmutex 의 경우에는 상보배제해야되므로 값이 1이고\nempty_sem 의 경우에는 처음에는 모두 비어있으니까 값이 n 이고\nfull_sem 의 경우에는 처음에는 채워져있는게 하나도 없으니까 값이 0이다\n\n\n그리고 과정을 차근차근 보면\n\n일단 Producer 는 empty_sem 을 하나 먹고 값을 쓰되\n릴리즈 과정에서 empty_sem 을 릴리즈하는게 아니고 full_sem 을 릴리즈해서 1을 증가시킨다\n그럼 Consumer 는 full_sem 을 먹고싶은데 일단은 full_sem 이 0이니까 기다리다가\nProducer 가 full_sem 을 1 증가시키면 그걸 낼름 먹어서 값을 가져온다\n그리고 이번에는 full_sem 을 릴리즈하는게 아니고 empty_sem 을 릴리즈해서 1을 증가시키는 방식\n\n\n\nReaders-Writers Problem §\n\n이 문제는 DB 에서의 동시성 문제에 대한 간략한 예시이다:\n\nDB 에서 값을 읽는 것은 여러개가 접근해도 된다\nDB 에 값을 쓰는 것은 한놈만 접근해야 된다\n\n\n이 문제에서는 다음의 세마포를 사용해 동시성을 관리할 수 있다:\n\nDB 에 배타적으로 값을 write 하기 위한 세마포\nReader 의 개수를 세어서 Reader 가 있는 경우에는 Writer 가 접근하지 못하도록 해야 하는데 이때 Reader 들의 개수를 세기 위한 공유 변수에의 세마포\n\n\n따라서 다음과 같이 수도코드를 작성할 수 있다\nWriter\n\n/**\n * Shared memory\n * var db *bufio.ReadWriter\n * var readCount int = 0\n *\n * Semapores\n * var db_sem semapore_t = 1\n * var rc_sem semapore_t = 1\n */\n \nfunc getValue() []byte { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tvalue := getValue()\n\t\tP(db_sem)\n\t\tdb.Write(value)\n\t\tV(db_sem)\n\t}\n}\n\nReader\n\n/**\n * Shared memory\n * var db *bufio.ReadWriter\n * var rc int = 0\n *\n * Semapores\n * var db_sem semapore_t = 1\n * var rc_sem semapore_t = 1\n */\n \nfunc useValue(value []byte) { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tP(rc_sem)\n\t\tif rc++; rc == 1 {\n\t\t\tP(db_sem)\n\t\t}\n\t\tV(rc_sem)\n \n\t\tvar value []byte\n\t\tdb.Read(value)\n \n\t\tP(rc_sem)\n\t\tif rc--; rc == 0 {\n\t\t\tV(db_sem)\n\t\t}\n\t\tV(rc_sem)\n \n\t\tuseValue(value)\n\t}\n}\n\n차근차근 보면\ndb_sem 하고 rc_sem 은 어차피 상호배제를 위한거니까 값이 1이고\n\nWriter 의 경우에는 db_sem 을 잠그는 것 밖에 할게 없다\n하지만 Reader 의 경우에는 rc 를 건들기 위해 아래위로 rc_sem 을 이용하여 한번에 한놈만 접근할 수 있게 하고\n첫 Reader 의 경우에만 db_sem 을 잠그고 마지막 Reader 만 db_sem 을 풀어 이것에 대한 상호배제를 하게 한다\n\n\n하지만 위의 코드는 Starvation 이 일어날 수 있다\n\n왜냐면 Reader 가 다 빠져나간 경우에만 db_sem 이 풀리기 때문에 Reader 가 계속 들어오면 Writer 가 들어올 수 없기 때문\n\n\n\nDining-Philosophers Problem §\n(사진 사라짐)\n\n이건 배부른 돼지보다는 나은 배고픈 소크라테스의 고분분투기를 다룬 문제다\n일단 상황은\n\n소크라테스들이 자리에 앉아 생각을 하다가\n배고프면 자신의 양쪽에 있는 젓가락을 둘 다 잡아 식사를 하고\n이후에 다시 내려놓고 생각을 하는 고달픈 인생이다\n\n\n이 상황을 타개할 수 있는 가장 간단한 해결법은 다음과 같다\n\n왼쪽에 Lock 을 걸고 오른쪽에 Lock 을 걸어서 식사를 하고 차례대로 Lock 을 푸는 것\n\n\n하지만 이것은 다음과 같은 문제가 생긴다\n\nDeadlock: 만약 모든 소크라테스가 왼쪽의 젓가락을 잡으면 아무도 식사하지 못한다\nStarvation: 만약 자신의 양옆에 있는애들이 번갈아서 식사하면 나는 굶어 죽어 배부른 돼지보다도 못하게 된다\n\n\n이것을 해결할 수 있는 방법은 대표적으로\n\n한번에 4명의 소크라테스만 앉게 한다\n옆의 소크라테스를 유심히 보다가 젓가락을 모두 잡을 수 있을 때에만 식사를 한다\n비대칭 → 짝수번째 소크라테스는 오른쪽부터, 홀수번째 소크라테스는 왼쪽부터\n\n\n\nMonitor §\n\n동시성문제는 실행시에 무조건 발생하는 것이 아니라 코드를 잘못 작성했을 때 특정 조건이 맞을때에만 발생하기 때문에\n세마포를 잘못 사용했을 때에 이것을 감지해내기 어렵다\n따라서 개발자 입장에서 실수를 줄일 수 있는 더 상위 추상화가 여러 프로그래밍 언어들에서 지원되는데 이것이 Monitor 이다\n\n(사진 사라짐)\n\n\n그래서 위처럼 구성됨\n\n\n모니터에서는 공유 데이터와 그것에 접근할 수 있는 유일한 방법인 메소드를 묶어 하나의 class 로 구현하게끔한다\n\n\n구현한 뒤에는 Monitor 에는 한번에 하나의 프로세스만이 접근할 수 있도록 알아서 제어되기 때문에 Mutex 의 사용이 불필요하다\n\n즉, 명시적으로 공유데이터를 잠그거나 푸는 로직을 작성하지 않아도 된다는 소리임\n모니터에 접근한 프로세스가 종료되거나\n뒤에 나오는 Condition 에 의해 Block 되는 등의 방식으로 모니터 사용이 끝나면 다른 프로세스가 모니터에 들어와서 사용하게 된다\n\n\n\n그리고 모니터에는 Condition 기능도 제공되는데 이것은 Countable semapore 를 대체하는 기능이다\n\nBinary semapore(Mutex) 의 경우에는 모니터에서 알아서 해주니까 별다른 로직이 필요 없었지만\n상호배제가 아닌 자원 개수 관리를 위한 Countable semapore 를 위해서 Condition 이 제공된다는 것이다\n\n\n\nCondition 은 다음과 같은 두가지 기능을 가진다\n\nCondition.wait(): 얘는 현재의 프로세스를 Block 시키고 해당 Condition의 큐에 추가한다\nCondition.signal(): 얘는 해당 Condition의 큐에서 프로세스 하나를 꺼내 Ready 로 바꾼다\n\n자고 있는 프로세스가 없을 경우에는 아무 작업도 하지 않는 로직도 signal() 에 내부적으로 구현되어 있다\n\n\n즉, 하나의 Condition 변수는 하나의 줄을 의미하고 두가지 기능으로 프로세스를 줄세우거나 줄에서 꺼내는 작업을 할 수 있는 것이라 생각하면 된다\n다만 세마포의 P와 V는 자원의 개수를 값으로 가지고 필요한 자원이 있는지 없는지는 내부적으로 확인하는 대신\nCondition 을 사용할 때에는 필요한 자원이 있는지 없는지에 대한 로직은 개발자가 알아서 작성하고 재우거나 깨우는 것만 Condition 변수를 이용한다는 차이점이 있다\n\n\n\n즉, Condition 을 통해 자원이 존재하지 않을 때 프로세스를 재우고 자원이 생기면 깨우는 로직을 손쉽게 구현할 수 있다\n(사진 사라짐)\n\n그래서 위에서 살펴본 Bounded-Buffer 문제를 Monitor 를 이용해 살펴보면 위처럼 됨\nBounded-Buffer 가 Property 로 드가있고\n여기에 접근할 수 있는 produce 와 consume 이 Method 로 드가있으며\nMonitor 자체에서 Mutex 가 지원되므로 Mutex 에 관련한 로직은 삭제되었고\n자원 개수 관리에 대한 부분만 Condition 으로 대체된 것을 확인할 수 있다\n\n그리고 Condition 으로 full 과 empty 두개의 줄을 생성하고\n조건에 따라 적절하게 프로세스를 해당 줄에서 대기하게 하거나 줄에서 꺼내는 등의 작업을 하게 됨\n\n\n\n\n\nMonitor vs Semapore §\n\n모니터와 세마포는 다음과 같은 방식으로 (거의) 1:1 변환된다\n\n모니터 하나당 Mutex 를 위한 세마포를 선언한다\n모니터의 Condition 하나당 Countable semapore 를 선언한다\n모니터 메소드의 로직 중 자원 체크 &amp; wait 혹은 signal 부분을 P 혹은 V 로 대체한다\n\n\n"},"os.fall.2022.cse.ewha.ac.kr/7.-Deadlocks":{"title":"7. Deadlocks","links":[],"tags":[],"content":"(원문 사라짐)"},"os.fall.2022.cse.ewha.ac.kr/8-1.-Memory-Address":{"title":"8-1. Memory Address","links":[],"tags":[],"content":"Logical, Physical, Symbolic Address §\n\n\nLogical Address (Virtual Address): 프로세스 각각이 가지는 가상 주소 공간 속의 주소\n\n즉 메모리 전체에 이 프로세스 하나만 올라가있다고 상상했을 때의 주소를 의미한다\n따라서 메모리 주소는 0번부터 시작\n이제부터는 별다줄로다가 LA라 표현해보자고\n\n\nPhysical Address: 실제 메모리의 주소\n\n실제 메모리의 주소이기 때문에 하위 주소에는 커널이 들어가고 상위 주소에 유저 프로세스들이 올라가게 된다\n얘는 PA 라 표현해보자고\n\n\nSymbolic Address 라는 것은 코드 작성시에의 변수를 의미하는 것\n\n즉, 코드에는 메모리 주소가 아닌 사람이 읽을 수 있는 형태의 문자열인 변수를 사용하게 되는데 이것을 Symbolic Address 라고 하는 것\n\n\n\nAddress Binding §\n\nAddress Binding: LA 를 PA 로 바꾸는 과정\n\n메모리에 접근하기 위해서는 LA 가 아니라 PA 가 필요한데 이를 위해 주소 변환 과정이 필요하게 된다\n\n\n\nBinding 시점에 따른 분류 §\n\nBinding 시점에 따라 종류를 세 가지로 나눠볼 수 있다\n\n\n\nCompile Time Binding: 컴파일 시점에 PA 까지 결정되는 것\n\n컴파일 시점에는 SA 가 LA 로 바뀌기 때문에 이때의 주소를 PA로 사용한다는 것은\n항상 LA와 PA 가 같고\n프로세스는 항상 (별도의 조치가 없는 한) PA 0번부터 적재되게 된다\n뭐 당연히 현대의 컴퓨터에서는 사용되지 않았지만 옛날에 컴퓨터에서 하나의 프로세스만 작동되던 시절에는 이런 방식의 바인딩을 사용했다더라\nLA 와 PA 가 같기 때문에 이러한 코드를 Absolute Code(절대 코드) 라고 부르고 컴파일러는 이것을 생성하게 된다\n\n\nLoad Time Binding: 프로그램이 프로세스가 되어 메모리에 적재되는 시점에 PA 를 결정하는 것\n\n얘는 위에놈보다 좀 더 합리적이제\n메모리 사용 현황은 계속해서 바뀌어서 컴파일 시점에는 메모리의 어느 부분에 적재할지 알기 힘들기 때문에 메모리에 적재할때 LA 와 PA 를 바인딩하자는 개념\n이때에는 컴파일러가 Relocatable Code (재배치 가능 코드) 를 생성한다\n\n\nRuntime Binding: Load Time Binding 과 유사하나 최초에 메모리에 적재된 이후에도 새롭게 바인딩이 될 수 있는 방법\n\n이것은 이제 프로세스의 Swapping 을 지원하기 위해 나온 것이다\n왜냐면 프로세스가 Swap out 되면 디스크로 쫒겨나게 되는데 이후에 다시 Swap in 할 때 기존의 PA 가 아닌 새로운 PA 에 바인딩될 수 있도록 해야 하기 때문\n당연히 요즘의 운영체제에서는 이 방법을 사용한다\n프로세스가 시작되고 종료되기 전까지 PA 가 계속 바뀔 수 있으므로 주소 변환 과정을 CPU 가 아닌 MMU 라는 별도의 하드웨어를 이용해 처리한다\n\n\n\nCPU 입장에서 §\n\n위 그림을 자세히 보면\n코드가 적재되는 위치만 바뀌고 코드에 작성되어 있는 주소는 바뀌지 않잖어\n따라서 CPU가 사용하는 (바라보는) 주소는 LA 이다\n왜냐하면 코드에 작성되어 있는 주소를 바꾸기 위해서는 컴파일을 새로 해야 되는데 Compile Time Binding 이 아닌 이상 불가능 하기 때문에 코드에 작성되어 있는 주소는 LA 로 놔두고 적재 위치만 바꾸게 되는 것\n\nMemory Management Unit (MMU) §\n\n\nMMU 는 주소 변환을 해주는 하드웨어 유닛인데\n다음과 같은 방식으로 작동한다\n\n일단 CPU 가 LA 를 이용해 주소를 달라고 요청\nLA 는 무적권 0번부터 시작하기 때문에 LA 가 곧 프로세스 주소 공간의 시작점으로부터의 Offset 을 나타냄 → 프로세스가 적재되어 있는 실제 메모리 상의 시작점의 주소만 알면 여기에 LA 를 더함으로써 PA 를 구할 수 있다\n\n이 시작점의 주소는 MMU 내의 Base Register (BA) 혹은 Relocation Register 에 저장된다\n\n\nPA 를 알아낸 이후에는 여기에 저장되어 있던 것을 읽어 CPU 로 전달\n\n\n\n\n\n위의 그림이 MMU 의 작동 과정을 나타내는 그림인데\nMMU가 주소 변환을 할 때에는 LA 가 유효한지를 먼저 검사하게 된다\n왜냐면 만약 프로세스의 주소 공간의 크기가 3000일 때 이것보다 큰 LA 요청이 들어오게 된다면 프로세스 바깥의 주소 공간을 참조하게 되는 것 이므로 다른 프로세스의 주소공간에 무단 침입하는 셈이기 때문이다\n따라서 MMU 에서는 Limit Register 라는 또 다른 레지스터를 이용해서 프로세스 주소 공간의 크기를 저장해 놓고 이것보다 큰 LA 요청이 들어오면 트랩을 걸어 기각시키게 된다\n\nDynamic Loading, Overlay §\n\n일단 Dynamic Loading 이라는 것은 프로세스의 전체가 메모리에 올라가는 것이 아닌 필요한 부분만 올라가는 기법을 의미한다\n이렇게 하는 이유는 당연히 메모리 효율을 올리기 위함 → 프로그램에는 자주 사용되지 않는 오류 처리 루틴이 많이 포함되어 있기 때문에 프로세스 전체를 올리는 것은 자주 사용하지 않는 부분까지 모두 올리는 것이어서 비효율적이다\nDynamic Loading 의 정확한 정의는 OS의 힘을 빌리지 않고 메모리에 동적으로 적재되는 것을 뜻한다\n\n현대의 OS 에서는 뒤에 나올 페이징 기법을 이용해서 프로세스를 동적으로 메모리에 올리게 되는데 이것은 Dynamic Loading 이 아님\n하지만 이 용어를 딱히 구별해서 사용하지는 않는다 → 정확한 정의와는 무관하게 페이징 기법을 사용하는 것도 Dynamic Loading 이라고 부르긴 한다\n\n\nOverlay 라는 것은 Dynamic Loading 과 유사하지만 용어가 등장한 배경이 좀 다르다\n\n일단 Overlay 도 프로세스를 쪼개서 메모리에 올리는 방법이지만\nOverlay 는 메모리의 크기가 너무 작아 프로세스 하나조차 올릴 수 없는 시절에 프로그램을 작성할 때 어느부분을 올릴지 수작업으로 프로그래밍하는 방법을 의미한다\n하지만 Dynamic Loading 의 경우에는 메모리의 크기는 넉넉하지만 사용율을 높이기 위해 라이브러리의 힘을 빌려서 동적으로 적재하는 것을 일컫는다\n\n\n\nSwapping §\n\n\n일단 Swapping 이라는 것은 프로세스 전체를 디스크 등의 Backing store 로 쫒아내는 것을 말한다\n앞선 강의에서 잠깐 언급되었던 것 처럼 Swapping 은 중기 스케줄러 (Mid-term Scheduler, Swapper) 에 의해 어떤 놈이 방출될지 결정된다\n\n당연히 우선순위가 높은 놈 보다는 낮은 놈을 방출시키는게 좋겠제 → 이것을 Swapper 가 결정하게 되는 것\n\n\n이 Swapping 은 Runtime Binding 이 필수적이다\n\nCompile Time Binding 이나 Load Time Binding 의 경우에는 Swap out 되었어도 원래 위치로 되돌아 와야 하기 때문에 비효율적\nRuntime Binding 이 되어야 Swap in 될 때 비어있는 공간으로 쓱 드갈 수 있기 때문에 필수적이다\n\n\nSwapping 에서는 읽어들여야 할 데이터의 양이 많기 때문에 대부분 Transfer Time 이 차지한다고 한다\n\n이놈은 뒤에 디스크 부분에서 배울거라는데\n디스크가 데이터를 읽어들일 때는 디스크 헤드가 움직이는 Search Time 하고\n데이터를 읽어서 보내는 Transfer Time 이 있는데\n\n파일입출력같은 경우에는 Transfer Time 보다는 Search Time 이 더 오래 걸리는 반면\nSwapping 의 경우에는 보내야 할 데이터의 양이 많아 Transfer Time 이 더 오래걸린다고 하더라\n\n\n\n\n이놈도 페이징 기법과 연루되면서 용어가 좀 모호하게 쓰인다\n\n원래는 프로세스 전체가 디스크로 쫒겨나는 것을 의미하지만\n정확한 정의와 다르게 페이징 기법에 따라 페이지가 쫒겨나는 것도 Swapping 이라고들 하더라\n\n\n\nDynamic Linking §\n\n일단 Static Linking 이라는 용어부터 알 필요가 있다\n\ngcc 로 컴파일 할때 보면 라이브러리들을 오브젝트 파일로 만들어서 링크시켜주는 과정을 통해 라이브러리 내에 있던 코드가 내 코드에 포함되도록 하자네\n이렇게 라이브러리에 있던 코드를 내 코드에 포함시키는 것을 Static Linking 이라고 한다\n\n\n반면에 Dynamic Linking 은 라이브러리 코드를 내 코드에 포함시키지 않고 필요에 따라 불러오는 것을 의미한다\n\nDynamic Linking 을 하면 라이브러리 코드는 별도의 코드로 존재하고\n내가 해당 코드를 사용할 때에는 코드 전체를 가져오는 것이 아니라 해당 코드를 참조할 수 있는 작은 코드 조각 (해당 코드를 가리키는 포인터라고 생각하면 됨 → Stub 이라고 부르더라)을 코드에 넣어서 실행시점에 링크시켜 주는 것을 의미한다\n리눅스에서 .so 파일 본적 있제? 이것이 Dynamic Linking 을 위한 코드이다 → Shared Object 의 약자임\n윈도우에서는 .dll 파일 본 적 있을텐데 이것이 Dynamic Linking Library 의 약자이다\n\n\n"},"os.fall.2022.cse.ewha.ac.kr/8-2.-Physical-Memory-Allocation":{"title":"8-2. Physical Memory Allocation","links":[],"tags":[],"content":"Memory Section §\n\n앞서 배운것 처럼\n메모리의 하위 주소는 OS 영역으로 커널 코드가 드가게 되고\n상위 주소는 사용자 프로세스 영역으로 사용자 프로세스들이 적재된다\n\nContiguous Allocation §\n\nContiguous Allocation 은 프로세스 전체를 그냥 메모리에 때려박는 것을 의미한다\n\nFixed Partition (고정 분할 방식) §\n\n\n_고정 분할 방식_은 메모리 공간을 사이즈별로 미리 분할해놓고 프로세스를 나눠놓은 공간에 집어넣는 것을 의미한다\n사이즈가 작은 것부터 시작해서 나눠 놓은 공간에 프로세스가 드갈 수 있으면 거기 넣고 아차 싶으면 다음 공간 따라서 찾은 다음에 드갈 수 있는 데에다가 넣는 방식\n이때 프로세스들 사이사이에 사용되지 않은 부분을 External Fragmentation (외부 조각) 이라 하고\n하나의 분할 내에서 사용되지 않은 부분을 Internal Fragmentation (내부 조각) 이라 한다\n\nVariable Partition (가변 분할 방식) §\n\n\n솔직히 분할을 미리 나눠놓고 넣는 방식은 너무 비효율적이자네\n그래서 공간을 분할하지 않고 일단 프로세스를 차례차례 넣어놓는 방식을 _가변 분할 방식_이라 한다\n이때에는 External Fragmentation 만 발생한다 → 분할이 따로 존재하지 않기 때문에 프로세스가 종료되면 사이사이에 빈공간이 남게 되는 것\n가변 분할 방식에서 External Fragmentation 을 Hole 이라고도 한다\n\n\n\n운영체제는 프로세스가 할당되어 있는 공간과 비어있는 공간인 Hole 들에 대한 정보를 관리하고 프로세스를 적재할 때 활용하게 된다\n\n즉, 프로세스가 종료되면 Hole 에 포함시키고 프로세스가 적재될 때에는 드갈 수 있는 Hole 을 하나 골라서 적재하게 되는 것\n\n\n\nDynamic Storage Allocation Problem §\n\n이건 Hole 들 중에서 어떤 Hole 에 프로세스를 적재시킬지 결정하는 알고리즘들을 일컫는다\n\n\nFirst Fit: Hole 들을 순차탐색하다가 프로세스가 드갈 수 있는 첫번째 Hole 에다가 넣음\n\n장점: Hole 을 탐색하는 시간이 적게 걸림\n단점: 해당 Hole 이 최선의 선택이 아닐 수 있음\n\n\nBest Fit: 프로세스가 드갈 수 있는 Hole 들 중에 가장 작은 Hole 에 넣음\n\n가장 작은 Hole 에 넣기 때문에 더 작은 Hole 이 생길 수 있으므로 작은 Hole 들이 많이 생긴다\n장점: 최적의 Hole 에 넣을 수 있음\n단점: Hole 을 탐색하는 시간이 오래걸림\n\n\nWorst Fit: 프로세스가 드갈 수 있는 Hole 들 중에 가장 큰 Hole 에 넣음\n\n가장 큰 Hole 에 넣기 때문에 큰 Hole 들이 많이 생긴다\n얘는 단점이 많다\n\nHole 을 탐색하는 시간이 오래 걸림\n큰 Hole 에는 더 큰 프로세스가 들어갈 수 있지만 굳이 여기 넣어서 더 작은 Hole 로 만들어버림\n\n\n\n\n\n\n실험 결과 First Fit 과 Best Fit 에 비해 Worst Fit 의 효율성이 더 안좋은 것으로 알려져 있다\n\nCompaction §\n\nCompaction 은 External Fragmentation 을 없애기 위해 프로세스의 위치를 이동시켜 Hole 들을 하나로 모으는 것을 의미한다\n당연하게도 바인딩을 체크하는 등의 아주 많은 작업이 필요하기 때문에 오버헤드가 크다\n따라서 이것을 효율적으로 하기 위해 모든 프로세스를 옮기는 것이 아닌 최소한의 프로세스만을 움직여서 Hole 들을 모으는 방법이 필요한데 이것도 만만치 않다더라\n\nNon-contiguous Allocation §\n\n얘는 프로세스를 잘라 메모리에 적재하는 방식인데\n동일한 크기로 자르는 방식인 Paging 기법과\n코드의 의미 단위 (뭐 Code, Data, Stack 이랄지 함수별로 나누던지) 에 따라 가변크기로 자르는 방법인 Segmentation 기법\n이 둘을 합친 Paged segmentaion 기법이 있더라\n"},"os.fall.2022.cse.ewha.ac.kr/9.-Virtual-Memory":{"title":"9. Virtual Memory","links":[],"tags":[],"content":"Demand Paging §\n\n\n얘는 페이지를 모두 메모리에 올리는 것이 페이지가 필요한 시점에 메모리에 올리는 방법을 의미한다\n\n\n장점은\n\nIO 감소\n\n한번 올릴때 페이지 단위로 올리니까\n\n\nMemory 사용량 감소\n\n필요한 페이지만 올리니까 예외처리코드같은 자주 실행되지 않는 코드들이 메모리에 불필요하게 올라가지 않음\n\n\n빠른 응답시간\n\n여러개의 프로세스가 작동하는 경우에 하나의 프로세스 전체가 메모리에 올라가고 나머지는 아주 일부분만 올라간다면 모두 올라와있는 놈은 빠르지만 나머지는 IO 가 많아져 느림\n하지만 Demand Paging 을 사용하면 각 프로세스의 필요한 부분만 올라와있기 때문에 프로세스 전체가 메모리에 올라와있는 것보다는 느릴 수 있겠지만 전체적인 응답시간은 빨라진다\n\n\n더 많은 사용자 수용\n\n프로세스당 실시간으로 사용하는 메모리의 양이 적으므로\n\n\n\n\n\n그래서 프로세스가 메모리에 올라가게 되는 전체적인 모습을 보면 아래와 같다\n(사진 사라짐)\n\n제일 왼쪽은 가상 메모리 공간을 할당받고 프로세스가 페이지별로 나뉘어진 모습이다\n\nA ~ F 까지는 가상 메모리 공간에서 프로세스가 실제로 차지하는 페이지들이고\nG ~ H 는 프로세스가 차지하지 않는 빈 페이지임\n\n\n그리고 오른쪽의 두 그림처럼 메모리에 적재되었다고 한다면\n\n페이지 A, C, F 만 Demand Paging 에 의해 실제 메모리에 적재되었고\n나머지 페이지들은 디스크에 스왑되어있는 상황\n\n\n그때 Page Table 은 왼쪽 두번째와 같다\n\n실제 메모리에 적재되어있는 페이지는 프레임 번호가 적히고 Valid 로 표시된다\n그리고 적재되어있지 않는 페이지는 Invalid 로 표시된다\n가상 메모리 공간에서 프로세스가 차지하지 않는 빈 페이지도 Invalid 로 표시됨\n\n\n당연한 이야기지만 프로세스가 처음 생성되었을때에는 Page Table 이 전부 Invalid 로 표시되어 있고 프로세스가 실행됨에 따라 필요한 페이지가 차츰 올라가며 Valid 로 바뀌게 된다\n\n\n\nPage Fault §\n\n\n근데 Demand Paging 을 하려면 어떤 페이지가 필요해서 OS 에 올려달라고 요청할 수 있어야 되는데 이를 위한 것이 바로 Page Fault 이다\n\n\n간단히 말하면 MMU 가 주소를 바꿀때 해당 주소가 Invalid 한 페이지에 있다면 트랩을 걸어 OS 로 하여금 해당 페이지를 적재할 수 있도록 하는 것\n\n\nPage Fault 의 처리 과정은 다음과 같다\n(사진 사라짐)\n\nInvalid 페이지를 참조\n\nMMU 는 이때 유효한 주소인지, Protection Violation 등이 없는지 추가적으로 체크한다\n\n\n(MMU 에 의해) Page Fault Trap 이 걸려서 OS 로 CPU가 넘어감\n\n\n\n실제 메모리에서 비어있는 프레임 (Free Frame) 을 할당함 → 이미 모든 프레임이 하나 사용중이면 하나를 디스크로 스왑시켜서 빈 프레임을 만들어낸다\n\n디스크에서 해당 페이지를 가져오고\n빈 프레임에다가 페이지를 채움\n\n3, 4번 과정은 Disk IO 과정이기 때문에 당연히 해당 프로세스는 Block 되어 다른 프로세스로 CPU 가 넘어간다\n\n\nPage Table 에다가 Frame 번호 및 Valid/Invalid 를 업데이트함\nReady 상태로 있다가 CPU 를 받으면 멈췄던 Instruction 부터 다시 실행\n\n\n\nPage Fault Rate §\n(사진 사라짐)\n\nPage Fault Rate p 를 위와 같이 정의한다면\n\n즉, 0이면 Page Fault 가 절대 나지 않음\n1이면 모든 참조에서 Page Fault 가 발생\n\n\np 는 실제 시스템에서 0.01 정도로 아주 낮게 나온다 → Page Fault 가 앵간하면 일어나지 않는다는 의미\n\nPage Replacement §\n\n위에서 Page Fault 루틴 설명할 때 빈 프레임이 없으면 기존의 프레임에 있는 페이지를 swap out 시켜서 빈 프레임을 만들어낸다고 했는데 그것을 Page Replacement 라고 한다\n\n(사진 사라짐)\n\n위 그림이 Page Replacement 의 과정인데\n\n희생양을 정하고 Swap out 한다\n\n이때는 페이지에 변화가 없을 때에는 그냥 냅둬서 Overwrite 되게 할 수 있지만\n만일 페이지 내용에 변화가 있을 때에는 변화된 내용을 디스크에 반영해주는 IO 가 필요하다\n\n\nPage Table 에서 Swap out 한 페이지의 Validity 를 업데이트한다\n요청된 페이지를 Swap in 한다\nPage Table 에서 Swap in 한 페이지의 Validity 를 업데이트한다\n\n\n당연히 Page Replacement 를 할 때에는 Page Fault Rate 가 최소화되도록 프레임을 선택해야 되는데\n이것을 위한 알고리즘이 Replacement Algorithm 이다\n\nOptimal Algorithm (Belady’s Algorithm) §\n\n\n다시는 참조되지 않거나 가장 먼 미래에 참조될 페이지를 Replace 하자는 생각\n\n\n하지만 미래의 일은 알 수 없기 때문에 비현실적이다 → 이에 따라 Optimal Offline Algorithm 이라고도 불림\n\n\n다만, 이 알고리즘이 Page Fault 를 최소화한다는 것이 증명되어 있으므로 다른 알고리즘들의 성능에 대한 척도를 제공해주는 역할을 한다\n\n\n아래의 예제를 보면\n(사진 사라짐)\n\n위 시나리오에서 일단 첫 4번은 어쩔 수 없다 → 페이지가 없으니 어쩔 수 없이 Page Fault 가 발생\n5번째 Page Fault 에서는 4번 페이지가 가장 나중에 사용되므로 4번이 5번으로 Replace\n6번째 Page Fault 에서는 5번만 나중에 사용되므로 사용되지 않는 페이지 아무거나 Replace\n\n\n\nFIFO (First In First Out) Algorithm §\n\n\n선입선출이다\n\n\n얘는 FIFO (혹은 Belady’s) Anomaly 라는게 있는데 이게 뭐냐면\n\n일반적으로 Frame 수가 늘어나면 Page Fault 는 줄어드는 것이 일반적인데\nFIFO 방식을 사용하면 Frame 수가 늘어났을 때 Page Fault 가 늘어날 수도 있다는 것이다\n아래 예시 보면 됨\n\n(사진 사라짐)\n\n\nLRU, LFU Algorithm §\nLRU (Least Recently Used) Algorithm §\n\n\n가장 오래전에 참조된 것을 지우는 것\n\n\n최근에 참조된 것이 다시 참조될 가능성이 높다는 성질을 이용\n\n\nFIFO 와의 차이점은 FIFO 의 경우 가장 오래전에 입장한놈을 지운다면 LRU 는 가장 오래전에 마지막으로 참조된 것을 지운다\n(사진 사라짐)\n\n\nLFU (Least Frequently Used) Algorithm §\n\n가장 덜 빈번하게 참조된 것을 지우는 것\n빈번하게 참조된 것이 다시 참조될 가능성이 높다는 성질을 이용\n\nLRU vs LFU §\n(사진 사라짐)\n\nLRU 랑 LFU 의 장단점을 극단적으로 보여주기 위한 예시인데 누가 개같이 쫒겨날지는 직접 해보면 알 수 있음\n이걸 토대로 LRU 랑 LFU 를 비교해보면\nLRU 는 제일 나중에 참조된 것을 내쫒긴 하지만 그놈이 제일 많이 참조된 놈이어서 참조 빈도에 대한 고려는 안된다는 단점이 있고\nLFU 는 제일 적게 참도된 놈을 내쫒았는데 마지막 참조 시점의 고려가 되지 않는다는 단점이 있다\n\n위의 예시에서는 하필 그놈이 제일 최근에 들어온 놈이어서 연속 참조에 장애가 걸리는 문제가 발생한다\n\n\n\n구현 §\n(사진 사라짐)\n\nLRU: 얘는 Linked List 형태로 구현한다\n\n즉, 참조되면 그놈을 제일 아래로 내려 제일 높은 우선순위를 갖게 하고\n내쫒을때는 제일 위에 있는 제일 낮은 우선순위를 내쫒음\n따라서 시간복잡도는 O(1) 이 됨\n\n\nLFU: 얘는 Heap 을 이용하여 구현한다\n\n참조 시점이 아니라 빈도가 중요하므로 다른 놈들과의 비교를 해야되는데\n비교할때는 Linked List 를 이용해 일렬로 비교하며 따라가는 것 보다는 Heap 을 이용해 Leaf 까지 따라가며 비교횟수를 줄이는 것이 좋기 때문\n\n\n\n한계 §\n\n실제로는 LRU, LFU 알고리즘을 이용해 Page Replacement 를 할 수는 없다\n왜냐하면 MMU 가 하드웨어 유닛이기 때문에 Page Reference 는 OS 의 관여 없이 기계적으로 일어나기 때문\nOS 가 관여하는 부분은 Page Fault 가 발생했을 당시이므로 어떤 페이지가 언제 혹은 얼마나 참조되었는지는 OS 가 알 수 없다\n\nClock Algorithm §\n\n\n위에서 제시한 LRU, LFU 알고리즘의 한계를 극복하기 위해 등장한 알고리즘\n\n\n다음과 같이 작동한다\n(사진 사라짐)\n\n일단 시계에서 네모는 각 페이지를 의미한다\n그리고 숫자는 Reference Bit 으로, 최근에 해당 페이지가 참조되었음을 나타낸다\n\nReference Bit 은 MMU 에 의해 1로 바뀌고 OS 에 의해 0으로 바뀐다\n\n\nPage Fault 가 발생하면 OS 는 시계방향으로 Reference Bit 가 0인 페이지를 찾는다\n\nReference Bit 가 1이라면 OS 가 0으로 바꾸고 다음 페이지로 넘어간다\n\n\nReference Bit 이 0인 페이지를 찾으면 해당 페이지를 Swap out 한다\n\n\n\n이렇게 하면 다음과 같은 효과가 난다\n\nPage Fault 가 일어나지 않는 동안은 MMU 가 Reference Bit 을 관리하며 참조되었던 페이지들을 표시한다\nPage Fault 가 일어나면 OS 가 MMU 가 표시한 Reference Bit 을 이용해 참조되지 않았던 페이지를 찾아 swap out 한다\n이때 swap out 되는 페이지는 OS 에 의해 0으로 바뀐 뒤에 시침이 한바퀴를 돌아 다시 돌아올 때 까지 한번도 참조되지 않았던 것이 보장되므로 충분히 옛날에 마지막으로 참조되었던 것으로 생각할 수 있다\n\n따라서 이것은 LRU 와 비슷하다고 할 수 있다\n즉, LRU 의 근사 (approximation) 알고리즘\n공통점 → 마지막 참조 시점을 기준으로 페이지를 고름\n차이점 → 마지막 참조 시점이 가장 오래된 놈이라고 할 수는 없음\n\n\n\n\n\n이놈은 다음과 같은 이름으로도 불린다\n\nSecond Chance Algorithm: Reference Bit 이 1이면 한번 봐주고 다음 페이지로 넘어감\nNUR(Not Used Recently) 혹은 NRU(Not Recently Used): LRU 에서 Least 가 Not 으로 바뀜\n\n\n\nReference Bit 이외에도 Modified Bit 을 이용해 더욱 개선할 수도 있다\n\nModified Bit (Dirty Bit) 을 이용해 페이지가 변경되지 않았으면 IO 없이 swap out 하여 Overwrite 되게 함\n\n\n\nPage Frame Allocation §\n\n이것은 프로세스 하나에게 몇개의 Frame 을 할당할 것이냐인데\n이것이 중요한 이유는 다음과 같다\n\n프로세스는 실행코드 말고도 데이터와 협력해야되는 경우가 많으므로 여러 페이지에 동시에 참조할 일이 빈번하다\n또한 Loop 의 경우에는 해당 코드를 담은 페이지가 전부 올라와 있어야 Page Fault 가 안난다\n\n만약 Frame Allocation 이 2개인데 Loop 의 코드가 3 frame 을 필요로 한다면 1개의 페이지가 계속해서 Page Fault 가 날 것이기 때문\n\n\n\n\n다음과 같은 방법으로 할당할 수 있다\n\nEqual Allocation: 모두 똑같은 개수 할당\nProportional Allocation: 프로세스 크기에 따라 할당\nPriority Allocation: CPU 우선순위에 따라 할당\n\n\n이렇게 할당해 놓고 Replace 를 할때에는 해당 프로세스의 페이지 내에서만 Replace 되게 하는 방법을 Local Replacement 라고 한다\n하지만 프레임의 개수를 할당하지 않고 Replace Algorithm 에 따라 프로세스간 프레임을 경쟁하도록 하여 프레임 할당을 유동적으로 관리하는 것을 Global Replacement 라고 한다\n\n이렇게 하면 자연스레 프레임을 많이 필요로 하는 프로세스는 다른 프로세스의 페이지를 방출시켜 많이 차지하게 하고 해당 프로세스가 종료되면 자연스레 방출되어 다른 프로세스가 프레임을 차지할 수 있도록 할 수 있다\n\n\n\nThrashing §\n(사진 사라짐)\n\n일반적으로 메모리에 많은 프로세스가 올라오면 (= Degree of Multiprogramming 이 증가하면) CPU Utilization 은 올라간다\n하지만 어느 수준이 되면 프로세스 하나당 충분한 프레임이 확보되지 않아 Page Fault 가 너무 빈번하게 일어나 CPU Utilization 이 떨어지게 된다 → 이 시점을 Thrashing 이라고 한다\n\n이 구간에는 CPU Utilization 이 낮아 OS 가 더 많은 프로세스를 메모리에 올리려고 하고, 그러면 Page Fault 가 더 빈번하게 일어나는 악순환이 계속됨\n\n\n따라서 이것을 막기 위해서는 Degree of Multiprogramming 을 조절할 필요가 있다\n\nWorking Set Algorithm §\n\n\n페이지를 참조할때는 특정 시점에 빈번하게 참조하는 페이지가 한정되어있다는 Locality 에 착안해서\n\n\n빈번하게 참조하는 페이지들의 집합을 Working Set 이라고 부르고 WS 의 크기가 할당된 프레임의 개수보다 크면 그냥 해당 프로세스 전체를 Swap out 시켜버리는 알고리즘이다\n(사진 사라짐)\n\n\n저 WS 를 구하기 위해 Working Set Window 라는 것을 이용하는 데 이것은 페이지 참조 시퀀스에서 특정 시점의 최근 n 개의 참조 페이지를 의미한다\n\n위 그림의 예시로는 n 이 10이라고 할 수 있는 것\n이 Working Set Window 만큼의 페이지들을 집합으로 만들어 그의 개수를 기준으로 프로세스를 방출할지 말지 결정하는 알고리즘\n\n\n\nPFF (Page-Fault Frequency) Scheme §\n(사진 사라짐)\n\n얘는 Page Fault Frequency 를 추적해서 Page Fault Rate 가 일정 수준이 유지될 수 있도록 하는 것이다\n그래서 위 그림에서 보이는 것 처럼 상한 (Upper Bound) 와 하한 (Lower Bound) 를 정해놓고 상한보다 올라가면 프레임 할당을 더 증가시키고 하한보다 내려가면 프레임 할당을 줄여주는 방식\n\nPage Size §\n\nPage 사이즈가 너무 작다면\n\n장점\n\nInternal Fragmentation 의 감소\n필요한 정보만 메모리에 올라옴\n\n\n단점\n\n페이지 테이블 크기가 증가\nDisk Transfer 의 효율성 감소 (디스크에서 데이터를 찾는 것에서의 효율성)\n\n\n\n\n요즘 트랜드는 Page 사이즈를 크게 하는 것이랜다 (현재는 4Kb 정도)\n"},"os.spring.2021.cse.cnu.ac.kr/(충남대)-운영체제-강의록":{"title":"(충남대) 운영체제 강의록","links":["os.spring.2021.cse.cnu.ac.kr/1.-인터럽트,-타임쉐어링","os.spring.2021.cse.cnu.ac.kr/2.-프로세스","os.spring.2021.cse.cnu.ac.kr/3.-쓰레드","os.spring.2021.cse.cnu.ac.kr/4.-Concurrency","os.spring.2021.cse.cnu.ac.kr/5.-Semaphore","os.spring.2021.cse.cnu.ac.kr/6.-Deadlock-&-Starvation","os.spring.2021.cse.cnu.ac.kr/7.-메모리-관리","os.spring.2021.cse.cnu.ac.kr/8.-가상메모리","os.spring.2021.cse.cnu.ac.kr/9.-Segmentation","os.spring.2021.cse.cnu.ac.kr/10.-CPU-Scheduling","os.spring.2021.cse.cnu.ac.kr/11.-Multicore-Scheduling","os.spring.2021.cse.cnu.ac.kr/12.-IO-&-Disk-Scheduling","os.spring.2021.cse.cnu.ac.kr/13.-File-Management"],"tags":[],"content":"Table of Contents §\n\n1. 인터럽트, 타임쉐어링\n2. 프로세스\n3. 쓰레드\n4. Concurrency\n5. Semaphore\n6. Deadlock &amp; Starvation\n7. 메모리 관리\n8. 가상메모리\n9. Segmentation\n10. CPU Scheduling\n11. Multicore Scheduling\n12. IO &amp; Disk Scheduling\n13. File Management\n"},"os.spring.2021.cse.cnu.ac.kr/1.-인터럽트,-타임쉐어링":{"title":"1. 인터럽트, 타임쉐어링","links":[],"tags":[],"content":"DMA §\n\nDirect Memory Access : IO모듈을 따로 두어서(IO 전담 프로세서) 이 과정을 책임짐 - cpu가 IO작업을 하지 않는다\nIO : 입출력받는 모든 일 - 키보드 모니터 프린터 등 - IO모듈이 하는 일은 이 중에서도 필요한 데이터를 하드디스크에서 갖고오는 일을 한다\n이전에는 원하는 데이터가 메인메모리에 없으면 cpu가 하드디스크로 갖고왔음 - cpu가 직접 갖고오는 것을 Programmed IO라고 한다)\nSystem bus : 컴퓨터 내에서 데이터들이 아동하는 통로(전선)\nIO module안에는 buffer가 있어서 하드디스크로부터 가져온 데이터를 cpu가 가져가기 전까지 임시로 보관하게 된다\n\nInterrupt §\n\nIO Interrupt : IO모듈이 제대로 된 데이터를 갖고왔는지 cpu가 확인해야하기 때문에 IO모듈이 interrupt를 거는 것 - 이러한 IO방식을 Interrupt driven IO라고 한다\nInterrupt라는 것은 어떤 중요한 이벤트가 발생해 cpu가 지금 하던일을 멈추고 새로운 이벤트에 대응해야 된다고 cpu에 알려주는 것을 의미한다\n\nMemory hierachy §\n\nMemory hierarchy : 하드디스크 → 메인메모리 → 캐쉬 → 레지스터 계층구조를 의미함\n가격, 속도, 유지 등의 요소를 고려해 적절한 메모리 계층구조를 가지게 된다\n\nProcessor §\n\nProcess : 프로그램이 OS로 오면 실행가능한 프로그램을 process라고 부름\n이 process들을 실행하는게 processor\n\nCPU, GPU, DSP §\n\nCPU 는 명령어를 빠르게 처리하지만\nGPU 는 수학적 계산을 빠르게 처리하기 위해 나온 프로세서\nDSP(Digital Signal Processor) 로 음악이나 비디오 등의 시그널 처리를 담당한다\nCCP(Crypto Co-Processor) 로 암호처리를 담당한다\n\n프로세스의 처리 과정 §\n몇가지 레지스터들 용어정리 §\n\n기억안날까봐 다시 한번 설명해준다\nPC(Program Counter) : 다음으로 실행할 instruction이 들어있는 주소를 저장하는 레지스터\nIR(Instruction Register) : PC에 담긴 주소로 가서 가져온 instruction을 저장하는 레지스터\nAC(accumulator) : 임시저장소\n\nFetch §\n\nPC에서 주소를 읽어 메모리의 해당 주소로 간다\n거기 저장되어있던 instruction을 IR에 load한다\n\nExecute §\n\nIR에 load된 instruction을 실행하고 다시 Fetch를 반복한다\n\nInterrupt의 종류 §\n\nProgram : overflow, division by zero등의 상황이 일어났을 때\nTimer : 타임쉐어링 시스템에 의해 프로세스가 할당받은 시간이 만료되었을때\nIO : IO module이 데이터를 하드디스크로부터 갖고왔을 때\nHardware : memory parity failure등의 하드웨어적 이벤트가 일어났을 떄\n\nInterrupt가 발생했을 때 §\n\n기존 프로세스는 멈춰서 기다리고 interrupt handler가 interrupt를 해결하고 그 다음 줄로 넘어와 계속 코드를 실행하게 된다\nIDT : Interrupt Descriptor Table / IVT : Interrupt Vector Table : error, interrupt를 해결할 수 있는 코드의 위치(주소)를 정리한 표가 있는데 이제 interrupt handler는 이 표에 가서 지금 일어난 interrupt를 해결할 수 있는 코드가 어디에 있는지를 알아내 실행하게 된다\nSystem Call Table : 이것은 시스템 콜을 처리하는 코드의 위치(주소)를 정리한 표인데 이 표가 저장된 주소도 IDT의 마지막에 들어있다\n따라서 하나의 instruction을 execute다음에는 &lt;반드시&gt; interrupt가 일어나는지 검토하는 작업이 이루어진다\n\nMultiple interrupt §\n\n여러개의 interrupt가 일어났을 때 처리하는 방식은 두가지가 있다\nDisable/sequential : interrupt가 일어난 순서대로 처리하는 것 - 하나의 interrupt를 다 처리하고 나서 다음것이 실행됨 - interrupt를 처리하는 중간에 또다른 interrupt가 발생해도 처리하던 interrupt를 계속 처리한다\nNested : priority를 정해서 처리하는 것 - interrupt가 처리되는 와중에 새로운 interrupt가 발생했을 때 우선순위를 따져서 높은걸 먼저 처리하고 낮은걸 나중에 처리한다 - 낮은 interrupt가 발생하면 disable처럼 하던거 계속 하고 높은게 발생하면 중단하고 높은거 처리한 다음에 넘어와서 계속 처리 하는 구조이다\n\nOS §\n\nOS : 이러한 하드웨어들이 제대로 굴러가도록 관리하는 소프트웨어\n\nOS가 제공하는 서비스들 §\n\n프로그램 개발\n프로세스 실행 - process management - 프로세서와 연관\nIO기능 을 사용할 수 있게 함 - IO managemant\n파일들에 접근 할 수 있도록 해줌 - 리눅스의 경우 file discriptor를 통해서 파일들에 접근할 수 있게 해주는거 알쥬? - file management - 하드디스크와 연관\n시스템에 접근 / 다른 프로세스의 자원 등에 함부로 접근하지 못하게 하는 등의 protection - Memory protection이라고 한다 - memory management - 메인메모리와 연관\n에러에 대한 대응\n컴퓨터의 사용자가 여러명일 경우 누가 얼마나 썼는지를 계산 - 보통 클라우드에서 중요하다\n\nKernel §\n\nKernel은 OS의 핵심부분을 일컫는 말이다\nOS는 아주 사이즈가 크기 때문에 kernel이라는 핵심만 메모리에 상주하게 된다\n요즘은 컴퓨터의 성능이 놓기 때문에 커널의 사이즈를 점차 줄여나가는 microkernel이 추세이다\n\nProcess §\n\n프로그램이 실행되기 위해서는 메모리에 공간을 할당받아야 하고 또 그자리에 load되어야 하고 cpu time도 체크해야 되고 등등의 여러 데이터 구조와 여건이 갖춰져야 한다\n이런 여건들을 갖춰 os가 관리할 수 있는 실행 가능한 상태가 된 프로그램을 process라고 한다 - program in execution\n프로그램은 그냥 자료의 단위이고, 프로세스가 되어야 실행의 단위가 된다\n\n프로세스 실행의 종류 §\n\nBatch processing : 유사한 프로그램들을 한꺼번에 처리하는 것\nMulti programming(Concurrent Programming) : IO 등의 인터럽트가 일어나서 CPU가 기다리는동안 놀지 않고 다른 프로세스를 가동하는 것 - time sharing도 인터럽트를 발생시키지만 time sharing에 의한 인터럽트는 multi programming 이라고 하지 않는다 &lt;-&gt; 반대개념으로는 uniprogramming이 있다\nMulti processing(Symmetric Multi Processing - SMP) : 여러개의 코어를 갖는 CPU를 이용해 말 그대로 프로세스를 여러개 가동시키는것 - Multi programming과 헷갈리지 말아야 한다 - Multi programming의 경우에는 코어가 한개여도 가능하다 &lt;-&gt; 반대개념은 uniprocessing이다(싱글코어인 것)\nDistributed computing : 컴퓨터 여러개를 하나로 묶어 마치 하나의 컴퓨터처럼 움직이게 하는 개념\n\nTime sharing system §\n\nIO가 안일어나서 cpu가 쉬는경우가 안일어나면 하나의 프로그램이 cpu를 계속 사용하는 일이 일어나게 된다 - monopolize라고 한다\n이것을 방지하기 위해 각각의 프로세스에 시간을 할당하는 time sharing system이 나오게 된다\n\nUser mode vs Kernel mode §\n\nuser mode : 일반적인 사용자 모드. 일반적인 instruction들을 사용하고 접근이 제한된 메모리 공간에는 접근하지 못한다\nkernel mode : 관리자 모드 같은것. 시스템의 중요한 부분을 변경하는 privileged instructions들과 제한된 메모리 공간에 접근하는 것도 가능하다\nprivileged instructions나 제한된 메모리 공간에 무분별하게 접근해 시스템이 오작동하는 것을 막기 위해 os는 프로세스의 실행 모드가 유저인지 커널인지를 확인하게 된다\n\nUNIX 시스템 작동 순서 §\n\n\nUser → (command) → Command interpreter → (system call) → OS → (instructions) → Hardware\nsystem call은 OS와 밀접한 함수를 뜻하며 privileged instruction의 바로 상위 레벨 언어라고도 할 수 있다\n"},"os.spring.2021.cse.cnu.ac.kr/10.-CPU-Scheduling":{"title":"10. CPU Scheduling","links":[],"tags":[],"content":"Short, mid, long - term Schedule §\n\n\n일단 Ready Queue에 있다가 Dispatch가 되어서 CPU를 할당받는 작업이나 Timeout이 걸려 Ready Queue로 내려가는 것, IO등의 이벤트로 인해 Block되는 작업 은 가장 빈번하게 일어나기 때문에 이것에 관련된 정책을 Short-term Schedule 이라고 한다\n그리고 메모리에 자리가 없어서 Ready상태에 있던 놈이 swap-out되는 Ready, Suspend나 Block된 놈이 Swap-out되는 Blocked, Suspend의 경우에는 적당히 일어나기 때문에 이것에 관련된 정책을 Mid-term Schedule라고 한다\n또한 프로세스가 folk되어 new state에 있다가 자원을 모두 할당받으면 Ready state가 되는데 너무 많은 프로세스가 Ready queue에 있으면 시스템에 부담이 되기 때문에 new state에서 자원을 할당받는거를 기다리게 되는데 이러한 과정은 잘 일어나지 않기 때문에 이것에 관련된 정책을 Long-term Schedule이라고 한다\n\n\n\n따라서 new, exit과 관련된 작업은 Long-term Schedule, suspend와 관련된 작업은 Mid-term Schedule, Running, Ready, Blocked랑 관련된 작업은 Short-term Schedule이라고 할 수 있다\nMid-term Scheduling과 Long-term Scheduling은 메인메모리에 올라가는 프로세스의 갯수와 연관된다는 점에서 Multiprogramming Level을 조절해주는 역할을 하게 된다\n\nShort-term Scheduling §\n\nDispatcher, Short-term Scheduling, CPU-time Scheduling 다 비슷한 말이다\n자주 일어나기 때문에 이 과정이 빠르게 일어날 수 있도록 알고리즘을 짜야되고\n빠른것 뿐만 아니라 모든 프로세스에게 공평하게 자원이 돌아갈 수 있도록 알고리즘을을 짜야 된다\n\nCriteria §\n\nShort-term Scheduling의 알고리즘을 선택하는 기준(Criteria)\nTurnaround Time : 어떤 프로세스가 생성되고(new) 종료(exit)될때까지 걸린 시간\n\n프로세스가 생성된 후에는 여러번의 wait과 running을 거치기 때문에 Trunaround Time은 총 Service Time(Running Time)과 총 Waiting Time의 합이다\n일단 프로세스가 생성된 후에 일을 마치고 종료되는 시간이 짧으면 좋기 때문에 Turnaround Time이 짧으면 좋은데\n프로세서가 같다면 저 프로세스가 실행되는데 걸리는 시간은 동일하기 때문에 Service Time은 동일하다\n따라서 Waiting Time을 줄이는 것이 관건이며 이것들의 평균인 Average Waiting Time 혹은 Service Time까지 합쳐서 Average Turnaround Time이 낮은 Scheduling Algorithm을 선택하는 것이 효율적이다\n\n\nResponse Time : 얘는 프로세스의 실행 후 첫번째로 결과물이 나오는(뭐 printf로 뭔가가 출력되게 한다던지)데까지 걸리는 시간을 의미한다\n\n얘도 당연히 적을수록 좋지만 결과물을 출력하는 지점을 어디에 설정하느냐에 따라 값이 달라지기 떄문에 CPU Scheduling Algorithm을 선택하는 데에는 별로 중요한 척도가 되지 못한다\n하지만 사용자 편의성의 관점에서 보자면 매우 중요 - 일례로 여러 클라이언트가 접속하는 서버의 경우에는 첫번째로 받게되는 결과물이 완성된 html파일이기 때문에 이 response time이 이러한 경우에는 아주 중요한 척도가 된다\n\n\nDeadlines : 얘는 이제 반드시 이 시간 내로는 프로새스가 완전히 실행되어 종료되어야 한다라는 뜻을 가지고 있다 - 특히 아주 중요한 실시간 프로그램의 경우\nThroughput : 얘는 단위시간 내에 몇개의 프로세스가 종료되는지이다 - service time이 얼마나 걸리는지와 scheduling algorithm에 따라 많이 달라지더라 - 얘도 당연히 많이 끝내면 좋은거이기 때문에 클수록 좋은거다\nProcessor Utilization : CPU 이용률을 의미 - CPU를 많이 이용할수록 더 좋다\n\n알고리즘측면에서는 높으면 높을수록 좋기는 하지만 실제로는 100퍼센트까지 올라가면 시스템이 다운될수도 있기 때문에 대략 50-60퍼센트정도로 유지시킨다\n\n\nEnforcing Priority : 프로세스들에게 우선순위를 주어서 우선순위가 높은 프로세스를 먼저 CPU에게 할당하는 알고리즘\n\nPriority Queuing §\n\n\n커널 프로세스같은 중요한 프로세스는 fixed priority를 가질수도 있지만 유저 프로세스 대부분은 우선순위가 바뀌는 dynamic priority를 가지게 된다\nCPU time(timeout과 관련된 시간이 아니고 지금까지 총 할당받은 시간)이 많은 놈은 우선순위를 좀 낮추고 총 waiting time이 많은놈의 경우에는 우선순위를 높여서 빈부격차를 줄인다\n저 RQ가 프로세스 우선순위에 따른 큐 이고 상위계층의 큐가 다 비어야 그 다음의 큐에 들어있던 프로세스가 실행되게 된다\nPre-emptive라는 것은 낮은 우선순위를 가진프로세스가 실행되다가 높은 우선순위의 프로세스가 들어오면 낮은 우선순위의 프로세스를 중단시키고 높은 우선순위의 프로세스로 문맥을 교체시키는 것을 의미하고 Non Pre-emptive라는 것은 데드락에서 배운거처럼 반대로 높은 우선순위의 프로세스가 들어와도 현재 프로세스를 중단시키지 않는 것을 의미한다\n\nSelection Function(Algorithm) §\n\nw는 waiting time을 뜻하는 기호\ne는 execution time을 뜻하는 기호\ns는 service time 을 뜻하는 기호\n\n여기서 e과 s의 차이는 s는 프로세스가 종료되기까지 필요로 하는 CPU time 총 시간을 의미하고 e는 지금까지 얼마만큼의 CPU time을 할당받았냐를 의미\n따라서 e = s가 될때 프로세스가 종료되게 된다\nTurnaround time은 w + s가 되는 것\n\n\n\nAlgorithm §\n\n\n위처럼 프로세스 5개의 도착시간(Arrival Time)과 종료되기까지 필요로 하는 시간(Service Time)이 있다고 할 때\nFirst Come First Served(FCFS) 알고리즘\n\n\n\n얘는 무적권 먼저 도착한놈한테 먼저 CPU 를 할당해주는 것을 의미\n\n\n\n이때의 Turnaround time은 위와 같다\n이 표를 읽는 방법은 우선\nFinish time은 말 그래도 끝난 시간을 의미하고\nTurnaround time은 Finish time에서 Arrival time을 뺀 시작에서부터 종료되기까지 걸린 시간\n그리고 Tr / Ts 는 Turnaround time / Service time 이다 - 즉, 총 걸린 시간을 실제 작동한 시간으로 나눈 것을 의미\n\nTr / Ts 가 1이라는 것은 waiting time이 하나도 없었다는 것을 의미하고 1보다 크다는 것은 waiting time이 존재했다는 뜻으로도 생각할 수 있음\n그리고 이 값이 클수록 waiting time의 비율이 높은거이기도 하다\n\n\n위의 그래프를 Gantt chart라고 하고 저런 표들이나 이 차트를 주고 w, s, 등등을 구하는 문제 나온댄다\nFCFS의 경우에는 프로세스가 종료되기 전까지 CPU를 뺏지 않으므로 No Pre-emptive라고 할 수 있다\n하지만 만약 제수없게 실행시간이 엄청 긴 프로세스가 먼저 오면 w가 엄청 커지게 되는 단점이 있는데 이것을Convoy effect라고 한다\nRound Robin(RR)\n\n\n\n얘는 q 단위시간마다 프로세스를 교체시키는 알고리즘이다\ntime quantum(q) 는 얼마의 단위시간마다 프로세스를 교체할건지를 의미한다\n위의 차트는 q = 1인 상황으로 1 단위시간마다 프로세스가 교체되는 것을 알 수 있으며\n처음에 A프로세스의 경우에는 1 단위시간을 실행하고 난 다음에도 아무 프로세스도 들어오지 않았기 때문에 1단위시간을 더 실행하게 되는 것\n그리고 할당된 시간이 끝나고 누구에게 넘겨줄 것인가를 결정하는 것을 Tie Break Rule이라고 하는데 위의 그래프에서는 FCFS방식으로 넘겨줬기 때문에 먼저 들어온놈에게 프로세스가 넘어가는 것\n하지만 Tie Break Rule을 execution time이 적은놈이라고 정하면 또 차트가 달라질 수도 있다\nRound Robin의 경우에는 q를 너무 짧게 잡으면 context switch가 자주 일어나기 때문에 별로 좋지 않다 - 어쨋든 context switch가 일어난다는 것도 추가적인 시간을 잡아먹는 일이기 때문\n이렇듯 q를 너무 짧게 잡으면 context switch가 너무 자주 일어나게 되고 너무 길게 잡으면 FCFS와 다를바가 없기 때문에 보통 q 시간 내에 80퍼센트의 프로세스들이 종료될 수 있도록 q값을 설정해준다\nRound Robin은 같은시간동안 순서대로 프로세스들에게 CPU를 할당해주기 때문에 interactive program에서 자주 쓰인다\nRound Robin의 경우에는 정해진 시간이 지나면 CPU를 뻇으므로 Pre-emptive라고 할 수 있다\nShortest Process Next(SPN)\n\n\n\n얘는 프로세스가 종료되고 난 후에 가장 Service time이 적은 프로세스로 옮겨가는 알고리즘이다\n얘도 프로세스가 종료되기 전까지는 CPU를 뺏지 않으므로 Non Pre-emptive라고 할 수 있다\n이 알고리즘은 waiting time의 평균이 다른 알고리즘들보다 작다 - 프로세스가 필요로 하는 총 Service time을 알기 어렵다는 점에서 현실적으로는 구현하기 힘들고 어떤 알고리즘의 효율을 비교하는데 사용하는 이론적인 알고리즘이다\n즉, 어떤 알고리즘이 있을 때 waiting time이 SPN에 근접하면 좋은 알고리즘인거고 너무 차이가 많이 나면 안좋은 알고리즘인 셈\nShortest Remaining Time(SRT)\n\n\n\n얘는 SPN의 Pre-emptive 버전 이다\n작동방식은 새로운 프로세스가 들어왔을 때 지금 실행하고있는것의 남은시간(Remaining time)과 새로 들어온놈의 Service time을 비교해 짧은놈이 실행되게 하는 것\n위의 예시로 보자면 일단 2시에 B가 들어왔는데 A는 1시간만 있으면 종료되므로 그대로 A를 실행한거고\n그다음 B를 실행하다가 4시에 C가 들어왔는데 B는 종료되려면 5시간이 남았고 C는 4시간이면 종료되기 때문에 C로 프로세스를 교체한 것을 알 수 있다\n얘는 SPN보다도 더 waiting time이 짧으나 SPN과 마찬가지로 service time과 remaining time을 알 수 없기 때문에 이론적으로만 존재하는 알고리즘이다\n따라서 마찬가지로 어떤 알고리즘의 효율성을 비교할때 사용되는 기준점을 제시해주는 역할을 함\nHighest Response Ratio Next(HRRN) : 얘는 다음과 같은 수치를 이용해 다음 실행될 프로세스를 결정한다\n\n\n\n여기서 일단 aging이라는 용어가 나온다 - 오래 기다려서 folk된지 오래된 프로세스를 나이가 드는것에 빗대어 waiting time이 긴 프로세스일수록 age가 많다고 판단 - 이런 프로세스에게 우선권이 넘어가도록 한다\n그래서 위 수식을 보면 일단 waiting time이 길수록 저 ratio가 커지게 되고\n그리고 service time적을수록 ratio가 커지게 되어 - SPN과 SRT를 생각해보면 service time이 적은 프로세스를 먼저 실행시키는 것이 waiting time을 줄이는 방법이므로\n종합적으로 ratio가 크다는 말은 waiting time이 크거나 service time이 작다는 말이므로 ratio가 큰 프로세스를 선택하는 것\n하지만 이 역시도 service time을 알아야 하기 때문에 구현하기에는 어려움이 많은 알고리즘이다\nFeedback Scheduling : 얘는 이제 waiting time을 줄이려면 service time을 알아야 가능하다는 생각에서부터 출발한 알고리즘이다\n\n\n\n일단 이 알고리즘은 우선순위에 따라 여러개의 큐가 존재하는데\n예를 들어서 n이 2까지 있어서 3단계로 우선순위를 나눈다고 해보자\n이때 첫번째 큐(RQ0)의 경우 RR로 작동하고 q를 1로 두고\n두번째 큐(RQ1)도 RR로 작동하는 대신 q를 2로 두고\n세번째 큐(RQ2)는 FCFS로 작동한다고 해보자\n이때 프로세스가 생성되면 전부 RQ0로 집어넣은 다음\n프로세스를 실행시켜 RQ0에서 1 단위시간 내에 끝나면 그냥 끝나는거지만\n만약에 1 단위시간 내에 안끝내면 RQ1으로 내려보내고 RQ0이 비기 전까지는 RQ1을 실행하지 않게 된다\n그리고 RQ0이 비게 되면 그제서야 RQ1를 실행하게 되는데\nRQ1에서 2 단위시간 내로 프로세스가 종료되면 그냥 끝나는거지만 만약에 2 단위시간 내로 끝나지 않으면 이제 RQ2로 내려보내고\n마찬가지로 RQ1이 비기 전까지는 RQ2를 실행시키지 않는다\nRQ1까지 비게 되면 이제 RQ2를 실행시키는데 얘는 FCFS이기 때문에 들어온 순서대로 프로세스가 종료될때까지 실행되게 된다\n대신 새로운 프로세스가 실행되어 RQ0으로 들어오면 지금 하던일을 멈추고 RQ0으로 가서 실행시킴 - 따라서 Pre-emptive 하게 작동한다고 할 수 있다\n이런식으로 우선순위마다 큐를 여러개 두고 각 큐마다 다른 알고리즘을 적용시키되 각 큐들의 Quantum Time을 다르게 두어서 먼저 끝나는 프로세스를 먼저 실행시킬 수 있게 하는 것이다\nservice time을 실행시키는 당시에는 알 수 없기 때문에 시간제한을 두고 일단 실행시켜서 시간제한 내에 종료되면 service time이 짧은 놈을 먼저 실행시킨 꼴이므로 waiting time을 줄이는 효과를 가져오고\n그리고 제한시간 내에서 끝내지 못했으면 일단 service time이 제일 적은놈은 아니라는 것이 증명되므로 우선순위를 낮춰 나중에 실행되게 하는 꼴이고\n마지막 우선순위에 도달할때까지 종료되지 못했으면 service time이 아주 오래걸린다는 소리이므로 제일 나중에 FCFS같은 Non-preemptive한 알고리즘으로 실행시켜 나머지 과정을 마무리 짓는것\n즉, 시간제한을 여러개를 두어서 service time을 직접 실행시키면서 추론하는 방식으로 service time이 짧은 프로세스를 먼저 실행시키는 효과를 내어 waiting time을 줄이고하 하는 알고리즘이 Feedback Scheduling이다 - 상위 우선순위에서 끝마치지 못해 하위 우선순위로 내리는 것을 Feedback이라고 한다\n이 알고리즘이 요즘의 많은 OS에서 채택하고 있는 Scheduling 방식이다\nFair Share Scheduling(FSS) : 이게 현재 UNIX시스템에서 채택하고있는 Scheduling 방식이다\n\n\n\n일단 위의 수식을 이해할 필요가 있다\n일단 **CPUj(I)**는 현재의 CPU time을 나타낸다 - 그럼 **CPUj(I - 1)**은 바로 이전의 CPU time을 나타내것제\n그리고 Base랑 nice는 일단은 그냥 상수값으로 생각해래이\n그럼 위의 수식에 따라 현재의 CPU time은 이전의 CPU time의 절반이 되고\n그걸 또 Priority(위의 수식에서는 Pj(I))를 계산할때는 현재의 CPU time에서 절반을 나누므로 결과적으로는 이전의 CPU time에서 4를 나눈 값으로 계산하게 된다\n그리고 다음의 예시를 이해해보면\n\n\n\n일단 먼저 프로세스 A, B, C가 동일한 시간에 들어왔다고 해보자\n그리고 여기에서 Base랑 nice의 합은 60이라고 가정해보자\n일단 셋이 같이 들어왔고 CPU time도 0이므로 Priority는 60이 되어 셋 다 동일한 상태이다\n어차피 차이가 없으므로 A를 먼저 선택했을 경우\n보면 1 단위시간동안 CPU time동안 CPU time이 60씩 증가하게 된다 - 따라서 프로세스 A가 실행되는 0 ~ 1의 시간에는 CPU time이 60이 된다\n근데 다음 1 ~ 2의 기간에는 A의 경우 이전의 CPU time이 60이었으므로 4로 나눠 15가 되기 때문에 이것을 Base와 nice에 더해 Priority가 75가 된다 - 그리고 현재의 CPU time의 경우에는 절반을 나누기 때문에 1 ~ 2에서의 CPU time은 30이 되는 것\n그럼 A는 75이고 B와 C는 60이기 때문에 B와 C중 하나를 고르게 된다 - 여기서는 P가 낮을수록 우선순위가 높은거임\n만약 B를 선택했다면 0 ~ 1에서의 A와 마찬가지로 2 ~ 3에서의 B의 Priority는 75가 된다\n근데 A의 경우에는 이전의 CPU time이 30이었기 때문에 이것을 4로 나눠 계산한 Priority는 67.5로 재조정되고 현재의 CPU time은 15가 되는 것\nC는 아직 1 ~ 2에서는 실행되지 않았기 때문에 Priority가 60으로 그대로 유지된다\n그럼 2~3에서의 우선순위는 순서대로 67, 75, 60이 되기 때문에 가장 낮은 C가 선택되게 된다\n이제 그럼 3 ~ 4에서의 A를 보면 이전의 CPU time이 15였기 때문에 현재의 CPU time은 7.5가 되고 따라서 Priority는 63.75가 되는것이고\nB를 보면 2 ~ 3에서의 A처럼 67.5가 되며 C는 방금 실행되었기 때문에 75가 된다 - 따라서 A가 다시 선택되게 되는 것 - 이런식으로 돌아가게 된다\n따라서 종합해보면 프로세스가 1 time quantum만 실행되고 교체되기 때문에 RR의 성격을 가진다고할 수 있고 CPU를 할당받지 못한 동안에는 CPU time이 점차 감소되어 재조정되는 방식을 통해 aging도 반영되게 된다\nSPN도 반영된다는데 이거까지는 아직 잘 모르겠다\n"},"os.spring.2021.cse.cnu.ac.kr/11.-Multicore-Scheduling":{"title":"11. Multicore Scheduling","links":[],"tags":[],"content":"Multiprocessor System의 구조 §\nLoosley Coupled Multiprocessor §\n\n코어가 자신의 메인 메모리를 따로 갖고있는 코어들로 구성된 것\nDistributed혹은 Cluster라고도 불린다\n\nTightly Coupled Multiprocessor §\n\n모든 코어가 하나의 메인 메모리를 공유하는 구조\n대부분의 컴퓨터가 이와 같은 구조를 가진다\n이번 강의에서는 이 시스템을 가지고 Multiprocessor의 작동방식을 설명한다\n\nFunctionally Specialized Processors §\n\nmaster processor가 하나 있고 그것의 지배를 받는 IO전담 프로세서 등 slave processor가 존재하는 구조\n\nReady Queue의 구성 §\n\n\n일단 통합된 하나의 ready queue를 두고 여기에서 프로세스가 하나씩 빠져 프로세서로 들어가는 방식을 Dynamic이라고 한다\n\n왜 Dynamic이라고 하냐면 만약 하나의 프로세스가 실행되다가 timeout이 걸리든 block을 먹든 해서 빠져나왔다가 다시 Ready queue로 들어가면 기존에 실행되던 프로세서에 다시 할당되리라는 보장은 없기 때문에 하나의 프로세스가 여러개의 프로세서를 거쳐 실행된다는 뜻이다\n\n\n하지만 각 코어마다 ready queue를 두고 프로세스가 이 큐들로 분배되는 방식을 Static이라고 한다\n\n얘같은 경우에는 프로세스가 실행되다가 다시 내려와도 어차피 원래 실행되던 프로세서의 큐로 가기 때문에 이놈은 처음 할당받은 프로세서에서만 실행되다가 종료된다\n\n\n\n프로세스 선택 알고리즘 §\n\nUniprocessor일때는 FCFS를 선택했을 때 Convoy effect가 일어나서 average waiting time이 길어질 수가 있었는데\nMultiprocessor일때는 어차피 남는 CPU에 할당해주면 되기 때문에 Convoy effect에 대해 크게 신경쓰지 않는다\n따라서 FCFS가 알고리즘중에는 가장 공평하므로 FCFS도 많이 이용하게 되는 것\n\nThread Scheduling §\n\n쓰레드의 경우에 어떻게 할 것인가 - 쓰레드도 각각의 독립적인 개체로 보고 여러 프로세스에게 할당할 수도 있는데 이때 한 프로세스에서 파생된 쓰레드들 중 일부만 프로세서를 잡고 실행되게 되면 쓰레드들 간의 통신이 원활하지 않기 때문에 하나의 프로세스에서 파생된 쓰레드들을 한정된 프로세서들에게만 할당해주는 것도 가능하다?\nLoad Sharing : 쓰레드들을 Dynamic 시스템을 이용해 처리 - 하나의 Ready queue에 넣어서 처리함으로 정해진 프로세서에게만 처리되는 형식이 아닌 것\nGang Scheduling : 한개의 프로세스에서 파생된 쓰레드들에게 하나씩 프로세서를 할당하는 구조\n\n하지만 얘도 하나의 쓰레드가 하나의 프로세서에서만 돌아가지는 않는다\n말그대로 쓰레드들이 동시에 실행되기 때문에 게임같은 프로세스를 돌릴때 많이 사용되었다\n하지만 쓰레드의 갯수를 세야되고 하는 절차가 존재하기 때문에 옛날에 컴퓨터가 안좋았을 시절에는 많이 사용했지만 요즘은 컴퓨터가 좋아 리소스가 풍부하기 때문에 알고리즘을 단순화시키자는 생각으로 Load sharing을 더 사용한댄다\n\n\nDedicated Processor Assignment : Gang Scheduling과 비슷하지만 이제는 하나의 프로세서가 하나의 쓰레드를 전담하는 구조이다\nDynamic Scheduling : 얘는 프로세스의 쓰레드 갯수가 동적으로 바뀌는 상황에 대응하기 위해 만들어진 알고리즘이다\n\nReal-time Systems §\n\nReal-Time System은 실시간 시스템을 의미한다\nHard Real-Time : 얘는 앞에서 배운 Deadline이 존재하고 반드시 그걸 지켜야 되는 시스템 을 의미하고\nSoft Real-Time : 얘는 Deadline이 존재하지만 권장사항일 뿐 반드시 지켜야되는건 아닌 시스템을 의미한다\n\n얘는 의무사항은 아니어도 Deadline을 되도록이면 지켜야 하기 때문에 deadline이 걸린 프로세스는 메모리에 상주하고 우선순위를 높이게 된다\n\n\n\nReal-Time Scheduling §\n\n\n보면 맨 위에가 프로세스들이 언제 들어오고 얼마만큼의 시간을 필요로 하고 deadline이 언제까지인지를 나타내는 그림이고(편의를 위해 uniprocessor를 기준으로 한다)\n두번째는 A프로세스에게 우선권이 있을때의 그림, 세번째는 B프로세스에게 우선권이 있을때의 그림이다\n우선순위가 존재할때를 살펴보면 deadline을 지키지 못해 miss가 일어나는 것을 볼 수 있다 - deadline이 존재하는 경우에는 특정 프로세스에게 우선권을 주는 식으로 실행을 하면 miss가 자주 일어나므로 잘 사용하지 않는다\n네번째 그림인 Earliest Deadline Scheduling은 deadline이 가장 빠른것(=마감일이 얼마 안남은 것)을 먼저 실행시키는 알고리즘이다 - 이경우에는 miss가 안나는 것을 알 수 있다\n이 알고리즘은 프로세스가 하나밖에 없으면 그냥 그걸 실행시키고, 다른 프로세스가 들어오면 둘중에 deadline이 더 빠른놈을 선택하여 실행한다. 만약 deadline이 동일하다면 기존에 실행시키던 것을 계속 실행시키는 식으로 작동한다\n"},"os.spring.2021.cse.cnu.ac.kr/12.-IO-&-Disk-Scheduling":{"title":"12. IO & Disk Scheduling","links":[],"tags":[],"content":"IO Device §\n\nHuman Reachable : 키보드나 모니터, 마우스같은거\nMachine Reachable : USB, 센서같은거\nCommunication : 통신을 위한 장비\nIO장비는 하드웨어면으로나 소프트웨어 면으로나 장비마다 다양하기 때문에 이쪽을 개발하는 것은 전문성을 요구하는 쉽지 않은 일이다\n\nIO Techniques §\n구분 §\n\n\n보면\nProgrammed IO는 IO 처리를 구현한 프로그램이 있어서 프로세서가 직접 이 프로세스를 실행시키며 디스크에서 파일을 읽어오는 것을 의미한다\nInterrupt-Driven IO는 블락이 먹기 전까지 실행하다 IO가 필요해져서 블락을 먹으면 다른 프로세스를 실행하고 IO가 완료되면 인터럽트를 걸어서 다시 복귀하는 형태를 의미한다\nDirect Memory Access는 Interrupt Driven IO의 진화버전으로써 프로세서가 아닌 IO처리 담당 프로세서가 별도로 존재해서 걔가 IO를 처리하고 끝나면 인터럽트를 거는 일을 의미한다\nProgrammed IO와 나머지 둘의 가장 큰 차이점은 Busy Waiting이다 - Programmed IO는 프로세서가 직접 IO처리 프로세스를 실행시키며 IO처리를 해 기존의 프로세스가 기다리는 와중에도 프로세서를 사용하지만 Interrupt-Driven IO나 Direct Memory Access 는 IO처리를 프로세서가 직접 하지 않아 프로세서는 다른 프로세스를 돌릴 수 있게 한다\n\n발전과정 §\n\n\nProgrammed IO형태에서\nIO 전용의 IO module / Controller가 등장한다\n\nIO module / Controller는 한가지 형태의 IO를 전담하는 것이라고 생각하면 된다\n\n\n하지만 Interrupt 기능은 없어서 CPU가 수시로 IO가 종료되었는지 확인해줘야 되는 Busy Waiting이 여전히 존재했기 때문에 IO Interrupt가 추가된다 - 얘가 추가되고 나서는 Busy Waiting을 하지 않음\nIO module / Controller가 하드와 메모리를 직접적으로 제어하는 DMA가 추가됨\n\nDMA가 IO와 관련된 모든 일을 전담하는 것으로 생각하면 될거같다\nIO Module / Controller들을 DMA가 관리하게 되는 것\nCPU가 DMA에게 IO를 맡기기만 하면 얘가 알아서 다 처리하는 형태\n\n\nIO module / Controller가 별도의 프로세서로 분리됨 - IO만을 위한 특별한 Instruction을 실행시키며 IO를 처리한다\n\n4, 5번에서 하드와 메모리를 직접적으로 제어하는 프로세서를 별도로 분리한 것을 IO Channel이라고도 표현한다\n\n\n이전까지는 DMA도 메인메모리를 공유했지만 이제는 DMA전용의 메모리가 별도로 분리되어서 더 빠르게 작동할 수 있게 됐다\n\n\n\n옛날에는 데이터를 주고받는 Bus가 하나여서 여기에 DMA나 IO Module / Controller들이 전부 연결되어있었지만 - Single Bus, Detached DMA\nbus에는 DMA만 붙고 그 아래 IO Module / Controller들이 있는 형태로 바뀌었다가 - Single Bus, Integrated DMA\n이제는 System bus에는 DMA하나만 붙고 그 아래 IO Bus가 별도로 존재해 IO Module / Controller가 사용하는 Bus가 별도로 분리되게 된다\n\nIO 설계 §\n\nEfficiency : IO들은 프로세서나 메모리보다 처리속도가 더 늦기 때문에 이런 처리속도가 느린 IO 하드웨어들을 어떻게 효율적으로 관리하는가\nGenerality : IO의 인터페이스가 다 제각각이어서 그것을 이용하려는 프로그래머가 IO에 따라 다른 방법을 사용해야한다면 매우 불편 - IO의 사용법(인터페이스)을 통일시켜서 간편하게 사용할 수 있게끔 하는 것\n\n\n\n위 그림은 세 IO를 예시로 든건데\n보면 맨 아래 3개가 하드웨어로 구현된 IO 이다\n그리고 그 위에가 OS 레벨 이며 맨 위의 user process에서는 OS가 제공해주는 API들을 이용해 사용자가 프로그램을 짜게 되는 것\n우선 Logical Peripheral Device를 보면\n\nLogical IO에서 open, read, write, close등의 API등을 사용자에게 제공한다\n그리고 이런 API를 사용해 명령을 내리면 Logical IO에서 그것을 처리해 표준화된 인터페이스를 제공하는 Device IO로 전달하게 된다\nDevice IO가 이런 표준화된 인터페이스를 제공하기 때문에 우리는 HW레벨의 지식 없이 간편하게 HW를 제어할 수 있는 것이다\n\n\nCommunication Port에서도 동일하게 Communication Architecture을 이용해 사용자에게 API를 제공하고, 그것을 처리해 Device IO로 넘겨주게 된다\nFile System에서는\n\n일단 Directory Management는 우리가 문자열 형태로 전달한 파일의 경로를 File Descriptor로 바꾸는 역할을 한다\n\nFile Descriptor 별거 아니다 - 프로세스는 고유한 pid를 갖고있듯이 파일도 File Descriptor 라는 고유한 번호를 갖게 된다\n\n\n그리고 File System에서 파일에 대한 Open, Read, Write, Close 명령어를 제공해준다\n그리고 Physical Organization에서는 Virtual Address를 Physical Address로 변환하는 등의 일을 하게 된다\n\n\n\nBuffering §\nData IO size §\n\n일단 Device는 IO로 갖고오는 데이터의 크기에 따라 두가지로 나눌 수 있다\nBlock Oriented Device - 얘는 블럭(IO에서는 페이지를 블럭이라고 표현한다)단위로 IO를 처리하는 Device를 말한다\n\n보통 Machine Reachable Device가 블럭단위로 IO처리하므로 이놈이 여기에 들어간다\n\n\nStream Oriented Device - 예는 바이트나 워드 단위로 IO를 처리하는 Device를 의미한다\n\n보통 Human Reachable Device가 바이트나 워드 단위로 IO를 처리하므로 이놈이 여기에 들어간다\n\n\n따라서 Block Oriented Device가 블럭단위로 갖고오므로 Stream Oriented Device보다 갖고오는 양이 많다\n\nBuffer §\n\n\n일단 Buffer라는 것은 IO를 통해 가져온 데이터를 메인메모리의 OS파트에 잠깐 저장하기 위한 용도로의 공간을 의미한다.\n버퍼라는게 존재하지 않을 때 어떤일이 벌어지는지 보자\n유져 프로세스가 page fault가 일어나서 OS에게 특정 페이지를 요청했다고 해보자\n그럼 OS는 IO에게 해당 페이지를 가져오라고 시킨 뒤 다른 프로세스를 실행시키게 되는데\nIO가 끝나게 되면 버퍼가 없기 때문에 가져온 페이지가 메인메모리의 유저 프로세스 영역으로 들어가게 된다\n근데 만약에 유저 프로세스가 블락을 먹은 동안 메모리에 공간이 부족해져서 이놈이 Swap-out당하면 유저 프로세스가 메인메모리에 없기 때문에 IO는 가져온 데이터를 둘 곳이 없어지게 된다\n따라서 유저 프로세스는 IO가 완료되지 않았기 때문에 블락이 풀리지 않고 IO입장에서는 데이터를 갖고와도 둘곳이 없기 때문에 IO를 완료하지 못해 계속 블락을 먹은 상태로 있게 된다 - 이것을 Single Process Deadlock이라고 한다\n\n즉, 프로세스가 한개여도 버퍼가 없다면 데드락에 걸릴 수 있게 되는 것이다\n\n\n\n\n\n따라서 메모리의 OS파트에 버퍼라는 공간을 두어서 유저 프로세스가 Swap-out을 당하더라도 IO가 완료될 수 있도록 하는 것이다.\n그리고 이렇게 함으로써 Write에도 좀 더 이점을 가질 수 있다 - 유저 프로세스에서 Write가 일어났을 때 하드디스크를 바로바로 변경시키면 처리량이 많기 때문에 Write가 일어나면 일단 Buffer에 있는 페이지를 변경하고 나중에 하드에 한번에 업데이트 시킬 수 있게 한다\n또한 IO의 성능에 대해서도 이점이 있다 - Page Fault가 일어나면 하드디스크로 가기 전에 버퍼를 먼저 찾아서 여기에 이미 내가 원하는 페이지가 존재하는지 찾아보게 된다 - 만약에 있으면 하드에 갈 필요가 없으므로 훨씬 빠르게 Page Fault가 해결됨\n\n\n\n근데 버퍼를 여러개 갖게 되면 하나의 버퍼에 하드에서 가져온 페이지를 쓰는 것과 동시에 다른 프로세스가 다른 버퍼레 접근하여 데이터를 가져갈 수 있으므로\n요즘은 OS파트 안에 버퍼를 여러개 두고 여러개의 유저 프로세스가 버퍼들을 나눠서 사용하는 구조인 Circular Buffering 으로 운영된다\n\nDisk Performance §\n\n\n일단 디스크는 LP판처럼 생겼고 이와 유사하게 작동한다\n먼저 디스크의 한 표면(Surface)에는 여러개의 Track이 존재한다\n\n하나의 디스크는 앞면, 뒷면 두개의 Surface를 갖게 된다\n\n\n그리고 일정한 각도로 Surface를 잘라 만들어진 Track의 한 부분을 Sector 라고 한다\n또한 Sector는 여러개의 Block들로 구성되어 있고 어느 Sector든 같은 수의 Block으로 구성되어 있다\n\n그 각속도 기억나제? - 디스크 판은 같은 속도로 회전하기 때문에 한 섹터에서 같은 양의 블럭을 가져오기 위해서는 바깥쪽의 블럭은 좀 더 듬성듬성하게 위치하게 된다\n\n\n그리고 Disk Arm이 있어서 이놈이 Surface를 읽으며 데이터를 읽게 되는 것\n따라서 디스크에서 특정 블럭을 찾는 과정은 다음과 같은 세가지의 단계를 거치게 된다\n\n일단 Disk Arm이 특정 Track으로 움직이는 작업을 한다 - 이것을 Seek이라고 한다\n그리고 Track으로 간 뒤에는 디스크가 회전하며 해당 Sector를 찾는다 - 이것을 Rotational Delay라고 한다\n마지막으로 디스크에서 비트들을 읽어 전송하는 Data Transfer과정이 있다\n\n\n여기에 걸리는 시간을 보면\n\nData Transfer는 그냥 읽어서 전송하는 것이기 때문에 시간을 별로 잡아먹지 않는다\n하지만 Seek의 경우에는 Disk Arm이 물리적으로 움직여야 되므로 가장 오래 걸리게 되고\nRotational Delay도 디스크를 회전시켜야 되기 때문에 적지 않은 시간이 걸린다\n즉, Seek &gt; Rotational Delay &gt; Data Transfer 의 순서대로 시간이 소요된다\n\n\n특정 주소를 이용해 디스크의 위치를 알아내는 과정은 다음과 같다\n\n일단 Logical Address를 이용해 Page# 을 알아낸다\n그리고 그 Page# 를 Block# 로 바꾸게 된다\n그리고 Block# 을 이용해 해당 Block이 어느 Track에 있는지 알아낸다\n\n\n이 과정이 정확히 어떻게 이루어지는지는 안알랴줌\n\n\n근데 이제 Seek이 제일 오래 걸리기 때문에 이 시간을 줄여야 되고 따라서 일련의 Track# 들이 주어졌을 때 Disk Arm을 어떻게 움직여서 어떤 순서로 Track을 읽어야 할지가 Disk Scheduling이다\n\nDisk Scheduling §\n\n\n\nFIFO : 말그대로 들어온 순서대로 처리하는 것\n\nTrack# 이 Arm이 효율적으로 움직일 수 있는 동선대로 들어오는게 아니기 때문에 가장 최악의 시간이 걸린다\n\n\nSSTF(Shortest Serve Time First) : 얘는 지금 현재의 위치에서 가장 가까이 있는 놈을 처리한다\n\n보면 가장 효율적으로 움직이기 때문에 Seek가 제일 적게 걸리는 것을 알 수 있다\n하지만 매번 Queue를 전부 확인해서 나랑 가장 가까운 놈을 찾아야 하기 때문에 실제로 사용하기에는 무리가 있다\n\n\nSCAN : 얘는 엘리베이터마냥 한방향으로 가면서 그 방향에 있는애들 다 처리하고, 끝나면 다시 방향을 틀어 그 방향에 있는애들 다 처리하는 방식이다\nC-SCAN : SCAN은 양방향으로 움직이며 해당 방향에 있는 애들을 다 처리하는 반면, 얘는 한방향으로만 움직인다 - 한방향으로 움직이며 애들을 다 처리하고, 처리가 끝나면 다시 0번으로 복귀해 한방향으로 움직이게 되는 것\n\n즉, 0번으로 복귀할때에는 처리를 안한다\n이것은 하드웨어적 관점에서 봤을 때 한뱡향으로만 움직이는게 더 좋을수도 있기 때문에 이런 알고리즘을 채택하는 것\n\n\n\n\n\nN-Step SCAN : 이전의 SCAN에서는 큐를 하나만 두고 이 큐 안에 있는 애들을 처리하는 방식이었는데\n\n근데 SCAN방식은 요청순서와는 전혀 무관하게 작동하므로 약간 형평성의 문제가 있을 수 있다\n따라서 이러한 요청순서를 어느정도 반영하여 SCAN을 돌리는 것이 N-Step SCAN이다\n얘는 일단 크기가 N인 큐를 여러개 갖고 여기에 들어온 순서대로 넣는다 - 큐 하나가 다 차면 그다음 큐로 가서 채우는 방식으로\n그리고 하나의 큐 안에서는 SCAN방식으로 작동하게 함으로 일찍 들어온놈이 재수없게 나중에 처리되는 일을 줄인다\n따라서 N = 1이면 그냥 FIFO와 다를바가 없고 N이 엄청 크다면 SCAN과 다를바가 없는 방식이 된다\n\n\n\n\n\nFSCAN은 큐를 단 두개만 갖는 N-Step이라고 할 수 있다\n즉, 큐를 두개 가지고 하나를 채운 뒤 SCAN으로 처리하고, 그동안 다른 하나를 채워 SCAN처리하고 앞선 큐가 다 처리되어 비워졌으므로 다시 여기에 채우는 식으로 작동한다\n\nRAID §\n\nRAID(Redundant Array of Independent Disk) 라는 것은 별도의 디스크를 두어 디스크의 속도를 빠르게 함과 동시에 디스크가 손상되는 것을 막는(Fault Tolerant) 7가지 기법을 의미한다\n\nLevel 0 §\n\n\n일단 Strip이라는 것은 Session이랑 같은말이다 - 일련의 블럭들\n여러개의 블럭으로 구성된 파일을 하나의 디스크에 넣으면 하나의 IO에 의해 처리되므로 블럭들을 Serial하게 처리할 수 밖에 없다\n따라서 파일의 여러 블락들을 여러 디스크에 나눠 담아 여러개의 IO에 의해 처리되게 함으로 Parallel하게 처리되게 한다\nLevel 0에서는 그냥 이렇게 나눠담는 방법만 사용하여 속도에만 집중한 방법이다\nError에 대한 대비책은 고려하지 않으므로(Non-redundant) 진정한 의미의 RAID와는 좀 거리가 있다\n\nLevel 1 §\n\n\n얘는 이제 Level 0과 동일하게 하되, 동일한 Level 0구성을 두개를 놓아 하나에서 문제가 생겼을 때 다른 하나로 바로 이동해 처리하는 구조이다\n마치 like 백업을 두는 구조 - 이중화(Mirrored)\n요즘은 이 방법을 많이 사용하지만 Disk가 많이 필요하다는 단점이 존재한다\n\nLevel 2 §\n\n\n얘는 똑같은거 두개를 놓는게 아니라 Hamming Code라는 Error Correction Code를 별도의 디스크에 저장해 디스크의 갯수를 좀 줄이는 방법이다\n\nLevel 3 §\n\n\n얘는 Hamming Code 가 아닌 비트 단위(Bit-Interleaved)의 Parity bit을 이용해 Error Correction에서는 한계가 있지만 디스크의 갯수를 더욱더 줄이는 방법\nParity Bit은 Single Bit Error에 대해서는 Correction이 가능하지만 Double Bit Error에 대해서는 Detection만 가능하다는 점에 있어서 한계가 있다\n\nLevel 4 §\n\n\n얘는 비트 단위가 아닌 블럭 단위(Block-Level)로 Parity Bit을 구성해 Parity Bit를 더 줄이고 Error Detection연산도 줄이는 방법이다\n\nLevel 5 §\n\n\nLevel 3이나 4같은 경우에는 Parity Bit이 디스크 하나에 몰려있기 때문에 해당 디스크를 너무 많이 참조하고 Write가 발생할때마다 해당 디스크에 가서 Parity Bit를 다시 계산해줘야 하므로 Bottleneck현상(트래픽이 몰리는 것)이 일어날 수 있다 - 몰린다는 뜻\n따라서 Parity Bit을 분산하여 배치해 이러한 문제를 막는 기법이 Level 5 이다 - Distributed Parity\n\nLevel 6 §\n\n\n얘는 Parity Bit을 두개를 계산하여 저장(Dual Redundancy)하여 더 Error Correction의 정확성을 높이는 방법이다\n"},"os.spring.2021.cse.cnu.ac.kr/13.-File-Management":{"title":"13. File Management","links":[],"tags":[],"content":"Files §\n\nFile : 사용자가 만든 비트들의 모음\n\n성질 §\n\nLong-term Existence : 오랫동안 보관되어야 함\nShareable between Processes : 프로세스들이 공유할 수 있어야 함\nStructure : 확장자 얘기하는듯 - 여러 구조의 파일들을 잘 관리할 수 있어야 함\n\n구성 요소 §\n\nName : 파일의 이름\n\n유닉스 시스템에서는 inode# 라는 정수형태로 파일의 이름을 저장한다\n\n\nType : 확장자\nLocation : 위치 - Block# 로 디스크에서의 위치가 저장된다\nSize : 파일의 크기\nProtection : 파일의 Log\n\nCreation : 생성\nLast Modification : 마지막 변경\nLast Use : 마지막 사용\n위 세가지에 대해 Time, Date, *UID(User ID)*를 로그로 저장한다\n\n\n\nOperation §\n\nCreate : 파일의 생성\nDelete : 파일의 삭제\nOpen : 파일 열기\nClose : 파일 닫기\nRead : 파일 읽기\nWrite : 파일 쓰기\nC언어에서는 open system call 이 create와 open 을 모두 책임진다\n사용자가 파일 하나를 open하면 파일의 이름을 inode로 변환하고 그것을 이용해 Block# 를 알아낸 다음 메인 메모리로 갖고 올라와 read 혹은 write의 연산을 하고 끝나면 close를 통해 파일이 닫히는 구조이다\n\nStructure - Database와 File System 의 차이점 §\n\nOS의 File System에서는 위에서 명시한 파일을 생성하고 삭제하고 열고쓰는 등의 Rough한 연산들만 지원한다\n반면에 Database에서는 File의 내용, 즉, File의 Field(데이터베이스에서 Column을 말하는듯)와 Record(데이터베이스에서의 Row를 말하는듯)등의 File의 세부적인 내용을 관리하는 역할을 한다\n\nUNIX File System §\n\n\n일단 디스크의 구조가 저렇게 n개의 블락으로 구성되어있다고 할 때\n첫번째 블록을 Boot Block이라고 한다 - 얘는 처음 부팅할때 메인메모리에 들어가서 OS초기화하고 부팅작업을 하는데에 사용된다\n그리고 두번째 블록을 Super Block이라고 한다 - 얘는 부팅 이후 메인메모리로 들어가서 전체적인 File System에 대한 정보를 OS에 제공해준다\n그 이후 위의 예시에서 2~m-1까지를 inode list라고 한다\n\ninode list에는 inode들이 저장되고 블록보다는 사이즈가 작기 때문에 한 블록에 여러개의 inode가 저장되게 된다\n따라서 하나의 시스템 안에 저장될 수 있는 파일의 갯수는 저 m에 달려있는 것이다\n\n\n그 다음 m부터 n-1까지는 data block이라고 한다\n\ndata block 은 파일의 실질적인 내용이 블럭단위로 잘려서 저장되게 된다\n\n\ninode는 파일 하나에 대한 정보를 저장하게 된다 - 프로세스에 PCB가 있었듯이 파일에는 inode가 존재하는 셈이다\n\ninode에는 다양한 정보들이 저장되는데 일단\n위에서 말한 파일의 구성 요소인 name, type, size, location, protection과 파일의 주인인 owner가 들어간다\n그리고 index table이 들어가게 되는데 이놈이 하나의 파일에 대한 내용을 블럭단위로 쪼개서 data block에 저장하게 되므로 그 블럭들이 data block의 어디에 존재하는지를 나타내는 테이블이다\n위의 예시에서는 327, 15, 216이라고 돼있으므로 파일의 첫번째 블럭은 data block의 327에 가면 있다는 거고 두번째 블럭은 15, 마지막 블럭은 216에 가면 있다는 소리이다\n따라서 파일 하나가 가질 수 있는 최대 크기는 index table에 달려있게 된다\n\n\n그리고 한 파일이 열리면 그 파일에 대한 inode가 메인메모리로 올라가고, index table을 이용해 data block들도 하나씩 차례로 올라가게 된다\n\nIndex table §\n\nindex table의 구조를 조금 더 자세히 살펴보면 다음과 같다\n\n\n\n일단 index table의 일정부분은 바로 파일의 내용이 저장된 data block의 블럭으로 연결된다 - 여기를 direct block이라고 함\n위의 예시에서는 10까지는 따라가보면 바로 파일의 내용이 나오게 된다는 소리이다\n그리고 그 다음부터는 계층구조를 가지게 된다\n이게 뭔말이냐면, index table에 적혀있는 block# 으로 가보면 해당 블럭에 들어있는 내용은 파일의 내용이 아니라 또다른 index table이 존재하는 것이다\n즉, data block에 저장되어있는 블럭은 파일의 내용을 저장하는 블럭일 뿐만 아니라 index table일 수도 있다는 소리이다\n따라서 인덱스 테이블에서 다시 또다른 인텍스 테이블로 움직이고, 거기서 파일의 내용이 저장된 블럭으로 이동하는 계층구조를 가진다\n최상위 index table은 이렇게 일정구간은 바로 파일 내용 블럭으로 가지만 나머지는 차수가 점차 늘어나는 계층구조를 갖도록 되어 있다 - 이부분을 indirect block이라고 한다\n즉, 위의 예시에서는 11번째 칸에는 또다른 index table의 위치가 저장되어있고, 그 index table에는 파일 내용 블럭의 위치가 저장된 1중 계층구조였다면,\n12번째 칸에는 2중 계층구조, 13번째 칸에는 3중 계층구조로 되어있는 것이다\n이때 data block에 저장된 index table의 크기가 256이라면, 하나의 파일은 10 + 256 + 256^2 + 256^3 개의 블럭에 나뉘어져 저장되는 셈인거다\n보통 블럭 10개를 direct block으로 갖고 3개를 indirect block 로 1-Level, 2-Level, 3-Level 을 갖는 식으로 inode의 index table이 구성된댄다\n\nDirectory §\n\n일단 유닉스 시스템에서는 directory도 하나의 file로 취급한다\n\n\n\n일단 현재 디렉토리(current directory)가 inode 300번이라고 해보자\n그럼 거기의 index table을 통해 data block으로 간 결과가 그 옆의 column두개짜리 테이블이다\n디렉토리이기 때문에 파일의 내용이 저렇게 2 column table로 나타나게 되고\n이 2 column table에는 위의 예시에서는 오른쪽에는 해당 디렉토리에 들어있는 파일의 이름, 그리고 왼쪽에는 그 파일의 index# 가 저장된다\n그리고 만약 내가 A라는 디렉토리로 가고 싶으면 A 옆의 inode로 들어가게 된다\nA의 inode가 766이라고 했을 때 해당 inode list의 원소로 가면 동일하게 A의 정보와 A의 내용을 볼 수 있다(index table을 이용해서)\nA의 내용을 보면 A 또한 디렉토리이기 때문에 2 column table을 볼 수 있고, A에는 f1이 들어있기 때문에 f1과 f1의 inode# 가 2 column table에 저장되게 된다\n마찬가지로 f1의 inode# 인 111로 가면 거기에서 마찬가지로 index table을 이용해 f1의 내용을 볼 수 있는 것이다\n따라서 핵심은 유닉스에서는 디렉토리도 file로 관리되어 inode가 존재하고, 디렉토리의 inode에 저장된 index table을 이용해 내용 블럭으로 가면 거기에는 해당 디렉토리의 하위 디렉토리 / 파일에 대한 ( 이름, inode# ) 들이 저장되어 있는 것이다 - 따라서 해당 inode# 을 쫒아가면 하위 디렉토리 / 폴더로 접근하게 되는 구조이다\n\nFile Directory Structure §\n\nSingle Level Directory : 한명의 유저와 하나의 current directory만을 지원해 모든 파일들이 다 같은 곳에 unique한 이름들을 가지며 존재하는 것\n\n\n\nTwo Level Directory : 이제는 여러명의 유저와 하나의 current directory만을 지원해 파일들이 하나의 유저한테 속하여 존재하는 구조 - 한 유저 안에서는 unique한 이름을 가져야 되지만 유저가 다르다면 이름이 중복되어도 된다\n\n\n\nTree Structured Directory : 일반적으로 우리가 생각하는 디렉토리의 구조 여러명의 유저가 있고 한 유저 안에서도 여러개의 디렉토리, 디렉토리 안의 디렉토리를 생성해 트리구조로 디렉토리들이 형성되는 것\n\n\n\nAcyclic Graph Directory : 얘도 동일하게 트리구조를 갖지만 트리구조에서는 할 수 없는 공유의 개념이 가능한 구조이다 - 파일 하나를 여러명의 유저가 공유할 수 있는 구조\n\n\nFile Sharing System §\n\n\nHard Link : 공유파일에 대해 하나의 inode와 data block을 두 디렉토리 / 유저가 공유하는 형태이다\n\ninode와 data block을 하나씩 사용하기 때문에 resource를 적게 사용한다는 장점이 있다\n\n\nSymbolic Link : 얘는 두 디렉토리 / 유저가 각각 하나씩 공유파일에 대한 inode와 data block을 갖고있고 둘 중 하나의 data block에 나머지 하나의 inode의 경로가 적혀있는 형태이다\n\n얘는 inode와 data block이 더 필요하므로 resource를 더 많이 먹는다는 단점은 있지만, network를 사용해서 파일을 공유한다거나 하는 등의 더 강력한 파일 공유를 지원할 수 있다 - 그냥 파일의 경로만 data block에 적어주면 되므로\n\n\n\nFile Allocation §\n\ninode에서 쓰는 index table방식 말고 다른 방식의 data block을 찾아가는 방식들\n\nContiguous File Allocation §\n\n\nContiguous File Allocation : 얘는 data block을 연속적으로 디스크에 배치한 뒤, 시작블럭과 갯수를 File Allocation Table에 저장하는 방식이다\n이놈의 단점은 일단\n\n마지막 data block 뒤에 다른 파일의 data block이 들어있으면 그자리를 사용하지 못하므로 파일의 크기가 커졌을 때 대처할 수 없다는 것과\n파일이 삭제되어 data block들을 삭제했을 때에 External Fragmentation이 일어난다는 것이다\n옛날 windows xp가 이런 방식으로 작동해 external fragmentation 들을 모으는 조각 모음(compaction) 이 있었던 것이다\n\n\n\nChained Allocation §\n\n\nChained Allocation은 Linked List마냥 다음 data block의 위치를 data block의 마지막에다 저장해서 찾아가도록 하는 구조이다\n단점은 당연히\n\npointer를 잃어버리면 파일이 날라가는 문제가 발생한다는 것과\n파일의 특정 지점을 읽으려면 그곳까지 datablock을 차례로 들러야 하기 때문에 오래걸린다는 것이다\n이것을 해결하기 위해 FAT(File Allocation Table) 라는 것을 이용한다.\n\n\n\n\n\n얘는 여기저기 흩어져있는 포인터를 하나의 테이블에 모은 것으로, ( Block# , next Block# )을 저장하는 테이블이다\n포인터를 잃어버리지 않는다는 것과 이것이 특정 위치로 갈때 블락들을 찾는게 아닌 이 테이블만 읽으면 되니까 훨씬 더 빠르다는 장점이 있지만\n디스크의 사이즈가 커지면 FAT도 너무 커진다는 단점도 존재한다\n\nIndex Allocation with Variable-Length Portions §\n\n\nIndex Allocation with Variable-Length Portion은 index table개념과 contiguous allocation 개념을 합친거다\n즉, index table을 사용하되 연속된 블럭을 하나의 행에 저장하는 방법 - (start block, lengh)를 저장한다\n\nFree Block Management §\n\n비어있는 블럭을 관리하는 방법\n\nBit table §\n\n\nBit Table은 모든 Block# 에 하나씩 비트를 할당한 테이블로 이 비트를 이용해 해당 블럭이 비었는지 아닌지를 표시하는 방법이다\n\nChained Free Portions §\n\n\nChained Free Portions는 Free block들을 Linked List처럼 이어놓은 형태이다\n\nIndexing §\n\n\nIndexing은 table 하나를 만들어서 거기에 free block의 block# 를 다 저장하는 방법이다\n얘는 크기가 디스크의 블락의 갯수랑 같을 필요는 없다\n\nfree block의 갯수가 table의 갯수보다 클때는 일단 table을 다 채워놓고서 table에 들어있는 free block들이 다 사용되고 나면 다시 하드를 조사해 free block들을 채우면 되기 때문\n즉, 디스크의 모든 free block을 아는것이 중요한게 아니기 때문에 몇개를 채워놓고 다쓰면 다시 채우고 하는 방식으로 작동하게 된다\n\n\n"},"os.spring.2021.cse.cnu.ac.kr/2.-프로세스":{"title":"2. 프로세스","links":[],"tags":[],"content":"프로그램 실행에서의 OS의 역할 §\n\n자원들(메모리 등)을 여러 프로세스들에게 적절하게 분배하고 관리함\n프로세스가 계속 변경되며 실행되어 동시에 실행되는것처럼 보이게 한다\n이렇게 프로세스와 IO디바이스들을 관리하는것이 OS가 하는 일이다\n\n프로세스 §\n\n실행의 단위, OS의 관리의 단위, 실행됐지만 아직 죽지는 않은 것\n프로그램 코드 와 그 코드와 연결된 여러개의 데이터로 구성된다\n코드(text) : 내가 짠 프로그램 소스파일\n코드에 연동되는 데이터는 구체적으로 global 변수는 data에, local변수와 함수는 stack에, 동적할당을 위한 공간은 heap에(단 heap은 data와 합쳐 그냥 data로 하나로 퉁쳐서 부르기도 한다), 그리고 나머지 필요한 자료들은 PCB에 저장된다\nOS는 프로세스 단위로 메모리를 할당하고 관리한다\n\nPCB에 저장되는 정보들 §\n\nPCB = Process Control Block : 프로세스의 정보들을 담은 구역(자료구조). 프로그램이 프로세스가 되기 위해서는 이 공간을 반드시 할당받아야 한다\nidentifier : 유닉스에서 PID같은놈. 프로세스들의 고유 번호이다\nstate : 프로세스의 현재 상태. 현재 실행중인건지, 기다리는 것인지 등등의 상태들이 저당된다\npriority : 프로세스들 간의 우선순위. 시스템 프로세스 같은 중요한 것들이 먼저 구동될 있도록 우선순위가 매겨져있다. 하지만 하나의 프로세스가 cpu를 monopolize하는것을 막기 위해 우선순위는 계속 바뀌게 된다\n그리고 cpu로 들어갈때 레지스터에 쓸 값들 - program counter(다름 실행할 명령어의 주소), memory pointer(이 프로세스가 저장되어있는 메모리의 주소) 등등의 정보들이 저장되게 된다\n\nSystem, Kernel, User Process §\n\nOS도 하나의 프로그램이므로 OS의 여러 기능들도 프로세스화되어 구동되게 된다\n이 OS의 프로세스를 system process라고 하며 그 중에서도 중요한 애들인 커널이 프로세스화 된 것이 **kernel process(daemon)**이다. Kernel process같은 중요한 기능들은 항상 메모리에 상주한다 &lt;-&gt; 반대로 우리가 만든 프로그램들이 프로세스화되면 user process라고 하는 것\n\nDispatch, Context switch §\n\nDispatch : ready상태인 프로세스들 중 가장 우선순위가 높은놈을 running상태로 바꿔 cpu를 할당하는 일을 말함\nContext switch : 프로세스가 전환 후 새로운 프로세스가 실행되는것을 의미함\nDispatcher : 새로운 프로세스를 Dispatch하여 Context switch하는 일을 전담하는 kernel process\n여기서 중요한점은 새로운 프로세스가 Dispatch된 이후 새 프로세스가 실행되는것을 보고 Context switch가 일어났다라고 말한다 - 새로운 프로세스로 교체하는 “과정”을 Context switch라고 하는게 아니다 이말이야 - 따라서 Dispatch이후 Context Switch가 일어나는게 맞는거다\n\nProcess 실행과정 - 2 state process model §\n\n\n프로세스가 생성되면(Enter / Creation) 먼저 **Not Running(Ready)**상태가 된다 - Dispatch를 기다리는 상태\n이제 이 프로세스가 Dispatch되면 Running상태가 된다 - 실행되는 상태\n그리고 또 이놈이 실행되다가 타임아웃 등의 인터럽트를 받으면 다시 Not Running의 상태로 간다 - pause된다\n또 Dispatch되면 Running상태로 가고 이 과정을 반복하가 종료 (Exit / Termination)된다\n따라서 프로그램이 fork()되어 프로세스로 creation이 됐다가 exit()되어 다시 프로그램의 상태로 termination될때까지 수많은 pause와 dispatch를 거친다\n하지만 system process들은 잘 terminate되지 않는다 - 중요하므로\n우리가 코딩할때도. system call을 이용해 creation, dispatch, pause, terminate를 직접적으로 명령할 수도 있다 - fork(), exec(), wait(), exit()\nNot Running중인 프로세스들은 queue로 관리된다→ dispatch되면 queue에서 빠지고 pause되면 다시 queue로 들어간다\n\nsys call : fork()함수 §\n\n프로세스가 실행되다가 fork()가 실행되면 새로 프로세스가 하나 더 만들어지는데 이때 fork()를 호출한놈이 parent이고 만들어진 놈이 child이다\nfork()를 호출하면 parent와 동일한 놈이 하나더 child로 만들어지게 된다\n나머지는 전부 같으나 다른점이 몇가지 있다\n\nPID(identifier) 가 다르다 - 부모자식은 구별할 수 있어야 하므로\nfork()함수의 리턴값은 부모의 경우 자식의 PID, 자식의 경우 0을 리턴한다\n\n\nchild프로세스가 끝나기 전에 parent가 끝나면 좀 골치아파진다 - 원칙적으로 child가 끝나야 parent를 끝낸다 - cascade termination이라고 한다\n하지만 부득이하게 parent가 끝나면 parent의 parent가 child의 parent로 바뀌게 된다\n\nTermination condition §\n\nNormal completion : 정상종료\ntimeout과는 별개로 cpu를 차지하는 총 시간도 중요하다 - 무한루프에 빠졌을 가능성이 있으므로 - cpu를 차지하는 총 시간이 너무 긴 경우에도 강제로 termination하게 된다 - timeout과는 별개의 개념이다 - timeout의 경우에는 cpu를 연속적으로 사용하는 시간을 말하고 이때에는 이 cpu를 잡고있는 총 시간을 말하는거 -무한루프가 아닌 원래 시간을 많이 잡아먹는 일이면 작업관리자에 승인을 요청하는 작업을 해줘야 된다\nMemory unavailable : 더이상 가용 가능한 메모리가 없을 경우\n\nProcess 실행과정 - 5 state process model §\n\n\nNew : 새로 들어와서 프로세스로 바꾸는 과정 - 여러 resource들을 할당받는 상태 - 프로세스화가 끝나면 admit되어 다음 단계로 간다\nReady : 프로세스화가 끝난 상태 - dispatch되어 running되기만 기다리는 상태이다\nRunning : dispatch후 실행중인 상태 - 실행이 끝나면 release되어 다음 단계로 간다\n\n다만 timeout이 발생하면 다시 ready로 가게 된다 - timeout의 경우에는 어떤 이벤트가 일어나 지금 당장 실행할 수 없는 상태가 아니므로\nready 상태에 있는 놈들은 queue에서 기다리게 된다\n\n\nBlocked : 키보드 입력이라거나 그러한 이벤트로 인해 잠깐 멈춘 상태 - event wait\n\n얘네는 지금 바로 다시 실행할 수 있는 상태가 아니기 때문에 ready로는 가지 못하게 되는거다 - 따라서 이벤트가 처리되어(event occurs) 다시 running 가능해지면 running되는게 아니라 ready 단게로 가게 된다\nevent queue라는 것이 존재해서 event가 처리될때까지 queue에 머문다 - 그리고 event가 끝나면 ready queue로 옮겨져 또 기다리게 된다\n\n\nExit : 프로세스가 종료되어 new에서의 역순으로 처리되는 과정 - resource를 전부 반납하게 된다\n\nProcess Swapping - 7 state process model §\n\n\n중요한 이벤트가 발생해서 당장 실행해야 되는데 메모리에 공간이 없으면 덜 중요한 애들이 메모리를 양보하고 하드디스크로 내려간다 - swap-out\n이벤트가 종료되어 얘네들이 다시 메모리로 올라오는 것을 swap-in 이라고 한다\n이렇게 프로세스가 잠깐 하드로 내려가게 되는 것을 suspend라고 한다\n이런 suspend를 관리하기 위해 suspend state가 존재한다 - ready상태에서 swap-out를 먹으면 ready / suspend로 가고 blocked 상태에서 swap-out를 먹으면 blocked / suspend로 간다\n그리고 얘네들이 다시 swap-in을 먹으면. 원래의 상태로 돌아오게 된다 - 무조건 ready로 올라오는게 아니다!!\n당연하게도 일단 메모리에 있어야(ready 혹은 blocked여야) running 상태로 갈 수 있다 - suspend에서 바로 running으로 가지는 못한다\n하지만 running에서 suspend를 먹어서 내려갈 수는 있다\n또한 지금 메모리가 부족한 경우에는 프로세스가 만들어지자마자 ready / suspend로 갈 수도 있다\n\nFigure 3.11 §\n\n\nprocesses에 process table의 시작주소가 들어있고 그 테이블에 process들의 주소들이 들어있다\n여기서 process table이 PCB table이다 - 실제로는 프로세스를 구성하는 PCB, 데이터 등등이 어느 한곳에 같이 모여있는게 아니다 이말이야 - 그림에서의 process image에는 PCB는 안들어있고 그 나머지인 text, data, heap등이 저장되어 있는 구조이다\nprocess table은 pointer를 이용해서 가변길이로 할 수도 있지만 중간에 포인터를 잃어버리면 나가리기 때문에 불변길이로 선언하는 경우가 많다 - 다만 n이 시스템에 존재할 수 있는 process들의 총 갯수이기 때문에 n을 적당한 크기로 정하는 것이 중요하다 - n이 너무 크면 메모리를 너무 많이 먹고 n이 너무 작으면 process가 생성되기 힘들다 - 이 table의 일부가 비어있어야 process가 생성될 수 있기 때문\n뭐 나머지 memory table, io table 등등도 다 비슷하다\n그리고 이 table들의 주소를 담고 있는 structure가 존재하는 형태이다\nprocess table은 메모리에 상주하게 되는데 보통 이 n값이 굉장히 크기 때문에 메모리의 많은 부분을 차지하게 된다 - 그래서 PCB의 중요한 부분만 남기고 나머지 PCB중 덜 중요한 정보들은 하드디스크로 넘기게 되는데 이 부분이 u-area이다 - 다만 running 상태가 되면 이 u-area는 메모리로 다시 올라오게 된다 - state에 따라 어디 있을지 결정되는 것\n\nProcess creation 과정 §\n\ncreation : Id 만들기 → process를 위한 공간 할당 → PCB 생성 → 필요한 포인터들 연결 → 다른 자료구조들 생성\nterminate : 이것의 역순이다\n\nReady, Blocked Queue의 구현 §\n\n\n보면 큐라고 해서 이 프로세스들이 물리적으로 막 움직이는게 아니다 - 이렇게 linked-list형태로 구성되게 된다\n루트 노드에는 첫번째 프로세스의 PCB.state의 주소가 담기고 이 PCB.state에는 다음 프로세스의 PCB.state의 주소가 담기는 식으로 다음 프로세스를 계속 가리키는 식으로 큐가 구현되어있더라 이말이야\n\nInterrupt vs trap §\n\nInterrupt : 프로세스의 외부에서 이벤트가 발생해서 멈추는 것\n\ninterrupt가 발생하면 실행 모드가 user → kernel mode로 바뀐다\nuser의 process가 멈추고 kernel의 interrupt handler가 실행되게 된다 - 다음 실행할 instruction의 주소가 interrupt handler의 첫주소로 설정되는 것\ninterrupt가 끝나면 다시 원래의 instruction 주소로 돌아오며 실행모드도 user mode 로 바뀌게 된다\n\n\nTrap : 프로세스의 내부에서 이벤트가 일어나 멈추는 것\n\nContext switching이 일어나기까지의 과정 §\n\n중단된 시점의 레지스터 값을 전부 진행중인 프로세스의 메모리로 옮긴다(stop &amp; save)\nstate를 바꾼다(running → ready나 다른 상태들)\nqueue에 추가한다\n다음 process를 선택한다(select)\n그 process의 state를 변경한다(ready → running)\nprocess의 메모리에서 레지스터 값들을 다 가져오는 등 새 프로세스의 중단지점으로 다 restore한다(restore)\n바뀐 process를 진행한다\n"},"os.spring.2021.cse.cnu.ac.kr/3.-쓰레드":{"title":"3. 쓰레드","links":[],"tags":[],"content":"쓰레드가 필요한 이유 §\n\nfork()를 하면 프로세스가 pid만 다르고 그대로 복제되는데 그러면 이 resource들을 공유하면 어떨까 하는 생각에서 나옴\n왜냐하면 fork를 통해 매번 복사를 해 메모리에 할당되면 메모리도 많이 잡아먹고 복사하는데 시간이 걸리므로 오래 걸린다 이말이야\n그래서 resource는 공유하고 dispatch만 다르게 해 시간과 메모리를 절약하자는 생각이다\ntext와 data는 공유하면서 스택만 여러개로 복제되는 구조 - 이 하나하나의 스택들을 Thread라고 한다\n그래서 이제는 실행의 단위가 프로세스가 아니라 프로세스 내의 Thread가 된다\n그리고 이 thread들의 정보를 저장하는 놈이 TCB이다 - PCB와 별개로 쓰레드들마다 자신의 정보를 담고 있는 TCB가 생기게 된다\n그래서 이제는 fork를 할때 프로세스 전체에 대한 공간을 확보하는게 아니고 스택이랑 TCB로 이루어진 thread만 확보하면 된다\n이 때문에 thread를 light-weight process라고 부른다\ndispatch의 단위는 thread가 되고 resource의 단위(resource ownership이라 한다)는 process가 되는 것이다\n하지만 process는 여전히 protection의 단위가 된다 - 어차피 thread는 데이터를 공유하므로 protection할 필요가 없더라\n그래서 이제는 execution state도 thread단위로 일어나게 되고 context change가 일어나는 것도 thread단위로 일어나게 되며 실행되다가 cpu에서 물러날때 문맥저장도 쓰레드 단위로하게 된다\n쓰레드의 장접은 다음과 같다\n\n가볍기 때문에 fork, terminate, context-change가 빠르다 - context-change가 빠르기 때문에 concurrent processing에서도 이점이 있다\n그리고 같은 프로세스여도 여러 thread를 가질 수 있기 때문에 하나의 프로세스가 실행되다 block을 먹어 기다려야 되는 상황에서도 process change없이 thread change를 통해 하나의 프로세스를 계속 이어나갈 수 있다\n또한 정보를 공유하기 때문에 IPC에서도 이점이 있다\n\n\n\n예시 - 웹 서버에서의 쓰레드 §\n\n서버에서는 클라이언트의 리퀘스트가 들어오면 이 이것을 처리하는 프로세스로 처리하는게 아니라 자식 프로세스를 fork해서 처리하게 한다\n이렇게 하는 이유는 자기가 직접 처리해버리면 이것을 처리하는 동안에는 다른 클라이언트의 리퀘스트를 받지 못하기 때문\n근데 쓰레드 없이 fork하는 것은 프로세스 전체를 다 복사해야 하므로 오래걸린다 - 이것을 thread로 처리하면 작업속도를 많이 올릴 수 있게 된다\n\n예시 - 함수 병행 처리 §\n\n함수를 호출하는거를 RPC(Remote Procedure Call) 이라고 하는데 이렇게 RPC를 하게 되면 그 callee가 처리되고 처리되는동안 caller는 놀게 된다\n근데 이제 쓰레드를 이용하면 하나의 함수를 call해서 처리하는 동안 다른 함수를 다른 쓰레드로 실행시키면 이 둘이 context switch되며 평행하게 실행되게 된다\n\nThread의 상태 §\n\nSpawn : fork에 대응\nBlock : 프로세스에서의 Block과 같다\nUnblock : ready에 대응\nFinish : terminate에 대응\n\nUser-level thread(ULT), Kernel-level thread(KLT) §\n\nUser-level thread(ULT) : 쓰레드의 생성이 user mode에서 일어나는 것 - 리눅스 POSIX표준의 p_thread가 여기에 해당한다\nKernel-level thread(KLT) : 쓰레드의 생성이 kernel mode에서 일어나는 것 - 윈도우계열 쓰레드들이 여기에 해당한다\nULT 는 실행되다가 block을 먹으면 ULT의 경우에는 user mode에서 라이브러리의 도움을 받아 생성된 것 이므로 kernel에서 보기에는 그냥 하나의 프로세스처럼 보인다 - 때문에 그냥 process를 block시켜버린다\n하지만 KLT는 block을 먹어도 kernel-level에서 실행되기 때문에 이놈이 thread인것을 알고 thread 하나만 block을 먹인다\n따라서 ULT는 block을 먹으면 그 process내에 있는 thread전부가 block을 먹게 되고, KLT는 block을 먹어도 그 thread하나만 block을 먹게 된다*\n이렇게 KLT의 경우 process전체가 block을 먹으면 thread가 가지는 concurrent의 이점을 가질 수 없기 때문에 상대적으로 느리다 - multi-thread로 짜나 uni-thread로 짜나 별반 차이가 없으니까 IO request가 많은 등의 블락을 많이 먹을거같으면 process가 dispatch의 단위가 되도록 프로그래밍 하는 것이 나을 때도 있다\n하지만 대신 ULT의 경우 kernel과 무관하게 실행될 수 있으므로 os에 자유롭게 구동된다 - multi-platform하게 구동될 수 있다\nKLT는 kernel mode로 들어가서 구동해야 하므로 실행시간이 느리다는 단점이 있다 - 하지만 ULT와는 다르게 쓰레드 하나만 블락을 먹는다는 multi-thread의 장점때문에 결과적으로는 더 빠르게 구동된다\n"},"os.spring.2021.cse.cnu.ac.kr/4.-Concurrency":{"title":"4. Concurrency","links":[],"tags":[],"content":"Synchronize 문제의 발생 §\n\n프로세스가 concurrence하게 실행될 경우 발생하게 되는 문제이다 - concurrency 문제라고도 부른다\n프로세스 여러개가 공유하는 변수의 경우 이 프로세스들의 실행 순서에 따라 결과가 다르게 나올 수 있는 것을 의미한다\n이러한 문제의 경우 os딴에서는 절대 이 문제를 캐치해 낼 수 없다 → 프로그래머는 이러한 문제가 생길 수 있다는 것을 반드시 고려하고 대처할 수 있어야 한다\n\nmulti-thread로 프로그래밍을 하는 경우\nmultiprogramming, multiprocessing도중 공유변수를 사용하는 경우\nOS자체도 공유변수를 많이 사용하기 때문에 OS를 개발하는 경우\n\n\n이 경우에 프로세스들 간에 동기화가 되어 있지 않으면 문제가 생길 수 있다\n\n동기화 문제를 해결하기 위해서 §\n\n이것을 해결해주는 system call 이 존재한다\n이렇게 공유공간 존재하는 경우를 이 공간를 특별히 관리해야된다는 의미에서 critical section이라고 한다\n이때 mutual exclusion - 상호배제이 중요하다 - 누군가 이 변수를 사용하고 있으면 사용하면 안되고 사용하는 프로세스가 없어야 사용 가능한 것\n어떤 프로세스가 사용하고 있다는 것은 entry code와 exit code 를 통해 알아냄 - mutex나 semaphore등이 여기에 해당한다고 볼 수 있다\n변수가 사용중이면 entry code를 통해 이미 사용중이라는 것이라는 것을 알 수 있고 그럼 이 변수를 사용하는 다른 프로세스는 이 변수를 사용하지 못하고 wait상태에 들어가게 된다 - 이러한 과정을 synchronize한다고 한다\n그리고 기존에 이 변수를 사용하던 프로세스가 변수 사용을 끝내면 exit code가 실행되고 그럼 이 변수는 critical section을 빠져 나오게 된다 → 그러면 다른 프로세스가 접근해서 entry code를 확인했을 때 이 변수는 critical section에 들어있지 않다는 것을 알 수 있고 그럼 다른 프로세스에서 이 변수를 사용할 수 있게 된다\n또한 progress라는 것도 만족해야 한다 → entry / exit code를 잘못 짜면 critical section에 아무도 없는데 있는것으로 착각하고 waiting상태로 들어갈 수도 있다는 것\n\n이 progress에는 deadlock라는 케이스가 있다\n\n\nBounded waiting이라는 것도 만족해야 한다 → 변수가 critical section에 빠져서 다른 프로세스가 waiting에 들어가면 이 기다리는 시간은 무기한 기다림이 아니라 정해진 시간동안만 기다리게 된다는 것\n만약에 이런 bounded waiting 이라는게 없으면 starvation - 기아상태상태에 빠질 수도 있다 → 프로세스가 cpu할당을 오랫동안 받지 못하는것을 굶주리는 데에 비유한 것\n이렇게 mutual exclusion, progress, bounded waiting을 만족시킬 수 있는 entry code와 exit code를 짜야 concurrency의 문제가 발생하지 않는다\n\nRace Condition §\n\n여러개의 프로세스가 공유변수에 접근하고\n이 프로세스 들 간의 순서에 따라 결과가 달라진다면\n이때 프로세스들이 공규공간을 경쟁적으로 사용하려고 한다는 의미에서 Race Condition이라고 한다\n이렇게 race condition이 일어나는 구간을 critical section이라고 하는거고 변수가 이 구간에 포함되게 되면 뭐 mutual exclusion에 의해서 다른 프로세스가 기다리게 되고 뭐 이런거다\n\nOS가 해야 되는 것 §\n\n여러개의 프로세스들을 추적하고 있어야 한다 - 이놈이 critical section에 들어갔는지, 아니면 빠져나왔는지, 그리고 또 누가 critical section에 들어갈 수 있는지를 파악하고 있어야 한다\n프로세스들한테 자원을 할당하고 해제해야함\n공유변수 이외의 것은 다른 프로세스가 침범하지 못하게 보호해야 함\n프로세서의 속도에 따라서도 동기화 문제가 발생할 수도 있고 아닐 수도 있는데 프로세서의 속도(CPU의 처리속도)와 무관하게 동기화 문제가 발생하지 않도록해야 함\n\nMutual Exclusion 의 원칙 §\n\n모든 프로세스가 따라야 한다\n프로세스들간의 순서를 지정해 주는 거지 프로세스들 간에 간섭이 일어나게 해서는 안된다\ndeadlock이나 starvation이 일어나게 해서는 안된다 - progress, bounded waiting하게 실행되어야 한다\n프로세서의 속도나 실행되는 프로세스의 숫자와 무관해야 한다\n\n하드웨어적으로 해결법 §\nInterrupt disabling §\n\n인터럽트가 없다면 실행되는 중간에 다른 프로세스가 끼어드는 일이 없기 때문에 상호배제가 가능하다\n하지만 이렇게 되면 multiprogram이 아닌 uniprogram이 되어서 context change에 대한 이점을 얻지 못하게 된다\n\nAtomic operation §\n\n동기화의 문제가 발생할 수 있는 부분을 atomic operation으로 만들어보자는 것\natomic operation이라는 것은 해당 부분을 하드웨어적으로 구현해놓아 이 함수를 하나의 instruction으로 만들겠다는 것\n당연히 하나의 instruction을 실행할 때는 inturrupt가 걸리지 않으므로 동기화의 문제도 발생하지 않는다\n이렇게 atomic opration을 적극 활용하면 동기화의 문제를 막을 수 있다\n이놈을 잘 살펴볼 것 - compare_and_swap과 exchange라는 atomic operation을 이용해 mutual exclusion하게 코드를 짠 예시이다\n\n\n하지만 위의 코드는 문제가 있다\n\n다른 프로세스가 기다리는 동안 while(keyi != 0)이라는 조건을 계속 체크해야 되므로 기다리는 와중에도 cpu를 차지하게 된다 → busy waiting이라고 한다\n그리고 다음 실행 순서가 랜덤이다 → 이렇게 되면 운없는 어떤 프로세스는 starvation에 빠질 수도 있게 된다\n그리고 deadlock도 막지 못한댄다\n\nSemaphore §\n\n동기화의 문제점을 해결하기 위한 하나의 방법 - 제일 널리 사용된단다\n위의 코드와는 다르게 기다리는 중에는 cpu를 먹지 않아 busy waiting하지 않는다\n그리고 다음 실행 순서가 랜덤하지 않고 대기 큐에 들어가 FIFO하게 빠져나온다 - 그래서 starvation의 문제를 막을 수 있음\n\nMonitor §\n\n동기화의 문제를 해결하기 위해 프로그래밍 언어 차원에서 자동으로 해주는 것들도 있는데 얘네들을 monitor라고 한다\n"},"os.spring.2021.cse.cnu.ac.kr/5.-Semaphore":{"title":"5. Semaphore","links":[],"tags":[],"content":"Semaphore란? §\n\n자료형이다\n0이상의 정수로 초기화되는 것, 1을 빼는 것(sem_wait), 1을 더하는 것(sem_signal, sem_post) 세개의 연산만 가능하다\nsem_wait가 값을 1 뺀다는 것은 프로세스 하나가 critical section에 들어가서 공유변수에 접근할 수 있는 프로세스의 갯수가 하나 줄어들었다는 의미를 가진다\n반대로 sem_signal가 값을 1 추가시킨다는 것은 프로세스 하나가 critical section에서 나와서 공유변수에 접근할 수 있는 프로세스 하나가 더 늘었다는 의미를 가진다\ncritical section을 넓게 잡으면 굳이 concurrency문제가 발생하지 않는데도 다른 프로세스들이 블락을 먹으므로 최대한 좁게 잡아서 context change가 원활하게 이루어지게 하는 것이 중요하다\n세마포 변수가 0일 경우에 다른 프로세스가 sem_wait()함수를 실행시키게 되면 이 프로세스에서의 세마포 변수는 음의 값을 갖고 이 경우에 이 프로세스는 waiting queue에 들어가게 된다\n따라서 세마포 변수가 음의 값을 가질 때 이것의 절대값은 큐에서 대기하는 프로세스의 갯수를 의미하게 된다\n그리고 sem_signal()함수가 호출되면 세마포 변수를 하나 증가시키고 큐에서 한놈을 wait에서 깨운다 - 즉, critical section에 들어있던 프로세스가 하나 사라져 가장 처음에 큐에 들어온(FIFO)프로세스를 깨워 critical section에 넣게 되는 것이다\n공유변수에 접근하는 것을 제한하는 용도로의 세마포는 당연히 0과 1의 값만 가져야 되므로 binary semaphore를 사용한다\n근데 좀 더 사용처를 넓혀서 예를 들면 10명 이하의 유저가 게임에 접속하는 것만을 허용한다 뭐 이런 경우에는 세마포 변수의 초깃값을 10으로 잡아서 활용하는것도 가능하다\n그리고 초깃값을 0으로 잡아주면 실행순서를 조절하는 것도 가능하다 - 초깃값이 0이면 이 세마포를 sem_signal()해주는 프로세스가 반드시 선행되어야 해당 세마포를 sem_wait()해주는 프로세스가 동작할 수 있는것 - 하나의 세마포가 반드시 하나의 프로세스에서 semWait, semSignal돼야되는건 아니다\nsem_signal시에 깨우는 순서를 FIFO로 하는 경우를 strong semaphore이라고 하고 깨우는 순서를 랜덤하게 하는 경우를 weak semaphore라고 한다\n여기서 주의할 점은 critical section을 공유하는 애들 중 여기에 들어가는 프로세스의 갯수가 제한되어 있는 거지 normal execution의 경우에는 critical section과 parallel하게 작동할 수 있다\n\nProducer &amp; Consumer(Bounded Buffer) §\n\n세마포를 이용해 해결할 수 있는 대표적인 예시\n봐봐라\n\n제한된 갯수의 버퍼가 있고\n제한된 갯수의 producer 프로세스, 하나의 consumer 프로세스가 존재한다\n그리고 버퍼공간 통틀어 한번에 하나의 프로세스만 접근할 수 있다\n빈 버퍼에만 producer가 접근할 수 있다\n비지 않은 버퍼에만 consumer가 접근할 수 있다 - consumer는 destructive read작업(읽으면 자동으로 지워지는)을 수행한다\n\n\n다음은 이 문제의 해결법이다\n\n\n\n근데 봐봐라\n만약에 semWait 두개의 순서가 바뀌면 어떤일이 일어나느냐\nproducer의 경우에는 만약 버퍼가 다 차있는 상태라면 semWait(s)를 통해 s를 0으로 만들었는데 마침 semWait(e)를 했더니 e가 -1이 되게 된다\n그러면 얘가 이상태로 자게 되는데 그럼 입이 돌아간다\n왜냐면 얘가 s를 하나 먹고 자므로 e를 올려줄 수 있는 consumer도 접근을 못하게 돼 둘 다 자게 되는 것이다\n이러한 경우를 deadlock이라고 한다\nconsumer의 경우에도 semWait의 순서를 바꾸면 둘 다 입돌아가게 된다\n이렇듯 semWait의 경우에는 순서가 아주 중요하다 - 약간 보니까 실행순서나 참여 프로세스 갯수 제한이 아닌 상호배제의 용도로의 semaphore는 다른 용도로의 semaphore보다 늦게 - 딱 그 공유공간에 접근하기 바로 직전에만 - lock을 걸어줘야 되는듯\n하지만 semSignal의 경우에는 잠에서 깨워주는 역할을 하므로 순서가 바뀌어도 된다\n\nMassage Passing §\n\n얘는 그냥 프로세스들 간에 메세지를 주고받으며 동기화를 하는 방법이랜다\n"},"os.spring.2021.cse.cnu.ac.kr/6.-Deadlock-&-Starvation":{"title":"6. Deadlock & Starvation","links":[],"tags":[],"content":"Deadlock §\n\n일련의 프로세스가 영원히 블락먹는 상태를 의미한다\n어떤 프로세스의 블락상태가 풀리는것이 다른 프로세스의 실행에 달려있는데 이 다른 프로세스조차 블락을 먹어 둘다 영원히 블락을 먹게 되는 경우 이다\n예를 들면 이런 상황이다 - 프로세스 P가 D → T의 순서로 리소스를 먹고 Q는 T → D의 순서로 리소스를 먹을때 만약에 P가 D를 먹고 Q로 context change가 일어나 얘가 T를 먹으면 P도 자원을 먹지 못해 블락먹고 Q도 자원을 먹지 못해 블락을 먹으므로 둘 다 블락을 먹게 된다 - 이러한 경우에는 무조건 deadlock을 먹는건 아니므로 deadlock possible이라고 표현한다 - 즉, 무조건 deadlock이 발생하는건 아니지만 아다리가 맞으면 deadlock이 발생하게 되는 경우를 말한다\n이러한 경우에 첫번째로는 먹는 순서를 일치시킴으로 해결할 수 있다 - Q도 D → T의 순으로 자원을 먹으면 P가 D를 먹고 context change가 일어나도 Q는 D를 먹지 못하므로 T도 먹을 수 없어 Q는 블락을 먹어도 P는 블락을 안먹어 P가 자원을 뱉은 후 Q가 실행될 수 있게 되는 것이다\n\nConsumable 리소스의 deadlock §\nReusable, Consumable §\n\nreusable : 프로세스 하나가 먹고 뱉으면 다른 프로세스도 사용할 수 있는 자원 - 대표적으로 cpu가 여기에 해당한다\nconsumable : 하나의 프로세스가 먹고 나면 뱉어도 없어지기 때문에 다른 프로세스가 이용할 수 없는 자원 - interrupt처럼 처리하고 나면 없어지는 자원을 얘기한다\n\nDeadlock of Consumable resources §\n\n메세지 송수신에서의 deadlock\n\n\n\n보면 서로 메세지를 받아서 자신의 메세지를 보내는 과정을 거치는데 순서가 동일하다면 둘 다 메세지를 받아야 전송을 하므로 둘 다 블락을 먹게 된다 - 송신을 해야 반대편이 블락을 안먹는데 송신을 하려면 수신을 해야되고 그건 상대방도 동일하므로\n\nDeadlock of reusable resources §\n\n메모리 공간 할당에서의 deadlock\n\n\n\n예를들어서 메모리 총 공간이 200일때 프로세스 P는 80 → 60의 순서로 메모리 할당을 요청하고 프로세스 Q는 70 → 80의 순서로 메모리 할당을 요청할때 만약 P가 80을 먹고 context change가 일어나서 Q가 70을 먹으면 남은 공간은 50이므로 둘 다 원하는 메모리를 전부 먹지 못해 블락을 먹게 된다\n이렇듯 deadlock은 context change가 일어나지 않으면 일어나지 않지만 재수없게 context change가 일어나게 되면 일어나게 되는 경우가 많다\n프로세스 둘 중 하나의 자원을 뺏던가 아예 kill해버리는 방법으로 자원을 뱉게 하면 해결될 수 있다\n\n그림으로 deadlock 이해하기 - Resource Allocation Graph §\n\n\n동그라미가 프로세스, 네모가 자원, 네모 안의 검은 점이 이용할 수 있는 자원이다\n그리고 동그라미로부터 뻗어나오는 화살표가 자원 요청이고, 점으로부터 뻗어나오는 화살표는 자원 할당을 나타낸 것 이다\n왼쪽의 경우를 보면 P1이 Ra의 자원을 요청하나 이미 P2가 먹은 상태이다. 반면에 P2는 Rb의 자원을 요청하나 얘는 이미 P1이 먹은 상태이다. 따라서 계속 waiting하므로 deadlock이 걸리게 되는 것이다 - 이런식으로 리소스를 일부 먹고 기다리는걸 hold &amp; wait라고 한다\n반면에 오른쪽의 경우 P1은 Ra의 자원을 요청하는데 이용가능한 자원이 있으므로 문제없이 먹을 수 있다. 그리고 P2의 경우에도 Rb의 자원을 요청할때 이용가능한 자원이 있으므로 먹을 수 있다. 따라서 이 경우에는 deadlock이 걸리지 않게 된다\n\nDeadlock의 필요조건 §\n\nMutual Exclusion : 자원이 상호 배타적으로 접근해야만 정상적으로 작동할 때어떤 자원이 mutual exclusion하지 않으면 그냥 다 먹을 수 있으므로 deadlock이 걸리지 않는다\nHold &amp; wait : 프로세스가 자원을 하나 먹고 다른 자원을 먹으려고 기다릴 때 - 어떤 프로세스가 먹고 기다리는게 아닌 먹고 다시 뱉으면 다른 프로세스가 와서 사용할 수 있으므로 deadlock이 걸리지 않는다\nCircular wait : 자원의 요청, 할당관계 그래프가 화살표를 따라가봤더니 원형으로 그어질 때 - 원형으로 그어지지 않고 프로세스가 전혀 다른 리소스를 요청하는 그런 경우에는 한 프로세스가 블락을 먹어도 그걸 풀어줄 다른 프로세스가 다른 자원을 이용해 블락을 먹지 않게 되므로 블락먹은 프로세스도 풀리게 된다\nNo pre-emption : 프로세스들이 우선순위가 동일해 우선순위에 의한 작동순서를 정할 수 없고 프로세스의 자원을 뺏어오는것도 불가능할때 - 프로세스 두개가 deadlock을 먹었는데 하나의 우선순위가 높아 나머지 하나를 죽여버리면 deadlock이 풀리기 된다\n이 넷중에 하나만 만족하지 않아도 deadlock이 걸리지 않는다 - 즉, 이중에. 일부만 만족하는 것이 무조건적으로 deadlock을 야기하는건 아니다 - Circular wait의 상태여도 deadlock이 무조건 걸리는건 아니다 이말이야 - 원이 있어도 Mutual exclusion하지 않다던지 하는 연유로 프로세스 종료 시나리오가 완성된다면 deadlock이 아닌 것이다\n반면에 circular wait이면 반드시 deadlock이 되는 상황이 있다 - 연관되어 있는 모든 자원이 mutual exclusion, 즉, 한번에 한놈만 접근할 수 있을 때에는 circular wait이 일어나면 반드시 deadlock이 걸리게 된다\n\nDeadlock의 해결 §\n정보가 있는 경우 §\n\n여기서의 정보라는 것은 프로세스가 미래에 어떤 자원을 요청할지에 대한 정보나 자원이 mutual exclusion하다 등의 정보를 말한다. 나중에 프로세스가 어떤 자원을 요청할지를 미리 안다면 지금 내가 누구한테 자원을 줬을때 이것이 결국에는 deadlock을 야기할지 안할지를 알 수 있기 때문\nAvoidance : 자원의 요청과 할당관계에서 위와 같은 정보가 OS에 전달된다면 OS는 이 상황을 피하도록 대비를 할 수 있다 - 미래를 알고 피하는 것 - 그래서 OS는 deadlock posible 한 상황이면 리소스를 아예 할당해주지 않는다\n\n정보가 없는 경우 §\n\nPrevention : 이러한 정보가 없어도 저 4개의 필요조건중 하나라도 피할 수 있도록 잘 조정하는 것을 의미한다 - 미래는 모르지만 미리미리 방지하는 것\nDetection &amp; Recovery : 프로세스가 deadlock에 걸렸는지 아닌지를 계속 확인하고 걸렸으면 여기에서 빠져나오도록 일부를 kill한다던가 하는 등의 복구작업을 하는 것을 의미한다 - 여기서 deadlock을 탐지하는 방법은 프로세스들을 계속 관찰하면서 이 프로세스가 종료될 수 있는 시나리오가 있느냐를 확인하는 것이다 - 따라서 deadlock인것처럼 보여도 연관된 프로세스가 순차적으로 종료될 수 있는 그런 시나리오가 존재한다면 이것은 deadlock이 아닌 것이다\n\nPrevention strategy §\n\n아까도 말했지만 4가지 조건들을 회피해 deadlock이 걸리지 않게 하는 것\n간접(Indirect) 적인 방법 - Circular wait외의 나머지(Mutual exclusion, Hold&amp;Wait, No pre-emption) 이 세가지중 하나라도 발생하지 않도록 조치하는것\n직접(Direct) 적인 방법 - Circular wait가 일어나지 않게 조치하는 것\n\nMutual exclusion의 경우에는 리소스를 상호배타적으로 할당하지 않는 것이다\n\n하지만 리소스의 특성상 이놈이 상호배타적으로 할당해야만 하는놈인지 아니면 상호배타적으로 안해도 되는지 를OS가 알기가 힘드므로 쉽지 않다\n\n\nHold&amp;wait은 방지가 가능하다 - 프로세스가 시작하면 여기에 필요한 자원들을 중간에 끊지 않고 한번에 다 할당시킨다(serial하게)\n\n하지만 여기에는 몇가지 단점이 있다\n프로세스가 시작하면 거기에 필요한 자원들을 모두 할당하므로 이놈이 사용하지 않을 때 에도 먹고 있게 되어 비효율적이 될 수도 있다\n또한 어떤 리소스가 필요한지 실행시점에 다 알 수 없는 경우도 있다\n따라서 OS는 별로 선호하지 않는 방식이다\n\n\nNo pre-emption : 우선순위가 같은 경우에 OS가 프로세스 하나의 편을 일방적으로 들어서 나머지 프로세스의 리소스를 다 뺏어버리는 방법\n\n하지만 리소스를 뺏어버리면 그 프로세스는 그만큼 딜레이되는 것이므로 형평성의 문제가 있어 OS입장에서는 간편하지만 문제가 생길 수도 있다\n\n\nCircular wait : 리소스 할당에 원칙을 매기는 것으로 해결할 수 있다\n\n예를들면 오름차순으로 먹고 요청하는 것은 가능하지만 내림차순은 안된다고 했을 때 circular wait가 일어나려면 반드시 한번은 내림차순으로 가야되므로 이놈에게 리소스를 할당해주지 않으면 된다\n구체적인 예를 들어보면 프로세스 P가 R1먹고 R2요청하는 것은 오름차순이므로 허용, 다른 프로세스 Q가 R2먹고 R1 요청하는 것은 내림차순이니까 안된다고 했을 때 Circular wait이 성립하지 않으므로 deadlock이 발생하지 않는다\n\n\n\n\nprevention strategy는 아주 보수적인 해결방법이다 - avoidance와 다르게 미래를 잘 알지 못하는 상황에서 deadlock이 걸릴지 안걸릴지를 판단해야되므로 보수적으로 할 수밖에 없다\n\nAvoidance Strategy §\nDeadlock이 걸리지 않는 경우 §\n\n\nClaim matrix : 프로세스가 종료되는데 필요한 리소스들의 갯수\nAllocation matrix : 현제 프로세스들에게 할당된 리소스의 갯수\nC - A : 프로세스가 종료되기 위해 더 필요한 리소스의 갯수\nResource vector : 리소스를 동시에 할당받을 수 있는 프로세스의 통 갯수 - 아까의 allocation graph에서 검은 점의 갯수라고 보면 된다\nAvailable vector : 현재 프로세스들이 할당받은 다음 더 할당받을 수 있는 프로세스의 갯수 - 잔여분\nClaim matrix와 Resource vector를 아까말한 정보라고 하는 것이다 - 프로세스가 얼마나 자원을 필요로 할 지, 자원을 얼마까지 할당해줄 수가 있는지에 대한 정보가 존재하기 때문에 OS가 Avoidance strategy를 사용할 수 있는 것\n여기서 보면 P2가 R3를 하나 필요로 하는데 R3도 한개가 남으므로 줄 수 있다. 따라서 얘가 종료되고 남은 리소스를 전부 반환하면 Available vector는 623이 될 것이다. 이제 얘네들을 가지고 P1, P3, P4를 하나씩 끝내보면 모두 종료되는 시나리오가 존재하므로 이 경우에는 deadlock이 걸리지 않을 수 있다\n\nDeadlock이 걸리는 경우 §\n\n\n윗쪽의 상태를 보면 아직 종료 시나리오가 존재한다 - P2에게 102를 할당해주면 P2가 종료되며 순차적으로 종료될 수 있기 때문 - 이렇게 종료 시나리오가 존재하는 상태를 safe state라고 한다\n하지만 P1에게 101을 할당해주면 아래와 같이 종료 시나리오가 나오지 않게 된다\n왜냐면 아래쪽을 보면 모든 프로세스가 R1을 필요로 하는데 R1의 잔고가 하나도 남아있지 않은 상황이다. 따라서 프로세스 종료 시나리오가 나오지 않기 때문에 이 경우 추후에 deadlock이 발생하게 된다\n하지만 아직은 deadlock이 아니다 : 아직 P1이후로는 아무도 리소스를 요청하지 않았기 때문에 deadlock이라고는 할 수 없는것 - 즉, 아직 할당해줄 수 있는 자원이 남았기 때문에 이 범위 안에서 리소스를 요청하게 되면 그것을 수락할 수 있기 때문이다\n그래도 worst case를 가정했을 때 - 만약 저 프로세스들 중 어느 누구라도 R1을 요청하는 상황 - deadlock이 걸리게 되고 따라서 종료시나리오가 나오지 않는 것이라고 판단하는 것이다 - 이렇게 deadlock은 아니지만 종료 시나리오가 나오지 않는 그러한 상태를 unsafe state라고 한다\n따라서 OS는 P1한테 101을 주면 unsafe state이 걸린다는것을 알 수 있으므로 P1이 101을 요청해왔을때 이것을 거절하는 식으로 deadlock을 avoid할 수 있다\n이렇게 요청이 들어왔을때 unsafe state로 바뀌는지를 계산해 할당여부를 결정하는 식으로 avoid하게 된다\n이렇게 할당할때 조심스럽게 다 계한하고 위험요소가 없을 때 할당하는 것(worst case를 판단해서 할당여부를 결정하는 것)을 banker’s algorithm이라고 한다\n하지만 프로세스가 얼마만큼의 리소스를 필요로 하는지 알기 어렵기 때문에 - 저 claim matrix와 resource vector를 알아내는게 쉬운일이 아니기 때문에 avoid를 하는 것은 쉬운일이 아니다\navoidance는 미래를 알고 대비하는 것 이기 때문에 보수와 방임의 중간정도이다\n\nDetection strategy §\n\n\nDetection의 경우에는 저 Claim matrix를 알 수가 없고 단지 Request matrix만 알고있는 상황이라는 점에서 Avoidance와는 좀 다르다 - 여기서 request matrix는 앞으로 더 요청할 수도 있지만 일단 지금은 요정도 요청한다이런 의미의 표이다\n그래서 Request matrix와 Available vector를 가지고 프로세스 종료 시나리오를 짜봣을때 시나리오가 안나오면 deadlock이라고 판단하게 되는 것 이다 - 시나리오 짜는 방법은 저 request matrix 이후 더 이상 요청을 하지 않고 종료된다는 가정 하에 종료 시나리오를 짜는 방법이다\n\nRecovery strategy §\n\n프로세스들을 다 죽일수도 있지만 그럼 처음부터 다다시 해야되므로 효율적이지 않다\n방법1 : git reset HEAD^마냥 그 주기적으로 detection을 하고 이전 detection했을때의 상태를 저장해놨다가 deadlock이 발생하면 이 지점으로 다시 돌아가는 방법으로 해결할 수도 있다\n방법2 : deadlock이 풀릴때까지 프로세스를 하나씩 뱉게 하거나 죽여버리는 것이다\nDetection &amp; Recovery는 방임형 해결방법이다 - 걍 냅뒀다가 deadlock이 발생하면 해결하는 것 이므로\n\n밥먹는 철학자 문제 §\n\n철학자는 스파게티를 먹는데 2개의 포크가 필요하다\n포크 하나를 동시에 두명이 들 수 없다\n이 경우 deadlock이 걸리는 상황은 모든 사람이 왼쪽(혹은 오른쪽)의 포크만 들고 기다리는 상태이다\n해결법1 - 한번에 4명에게만 포크를 들 수 있는 자격을 준다\n해결법2 - 한번에 짝수번째/홀수번째에게만 포크를 들 수 있는 자격을 준다\n해결법3 - 포크를 드는 순서를 다르게 한다 - 기준을 한명 정해서 그사람을 기준으로 짝수번째 위치의 사람은 왼쪽거를 먼저 들고, 홀수번째의 사람은 오른쪽꺼를 먼저들게 하는 식으로 하면\n"},"os.spring.2021.cse.cnu.ac.kr/7.-메모리-관리":{"title":"7. 메모리 관리","links":[],"tags":[],"content":"Overlay 기법 §\n\n옛날에는 메모리가 부족하기 때문에 프로그램의 일부분만 메모리에 올려놓고 올려놓은 부분을 전부 실행하고 나면 나머지 부분을 올려서 프로그램을 구동햇다\n새로 올라온 부분은 이전 부분을 지워버리게 되는데 이것을 이제 overwrite라고 한다\n근데 이제 프로그램을 잘못 나눠서 나머지 부분을 실행시키는데 앞부분의 자원이 필요해지면 또 아래서 갖고와야 되므로 프로그램의 구동시간이 오래 걸리게 된다 - 따라서 제대로 나눌 수 있도록 잘 프로그래밍 하는 것이 중요했다 이말이야\n이런 프로그램을 나눠 순차적으로 메모리에 올리며 구동하는 것을 Overlay기법이라고 한다\n얘는 이제 swapping이랑은 다르다 - swapping은 바꿔치기하는거고 overlay는 덮어쓰는 개념\n\nMemory, Program Partition §\n\n이제 multiprogramming을 하기 위해 여러개의 프로그램을 메모리에 올리고싶어졌다\n그래서 메모리를 쪼개서(memory partition)여러 프로그램을 올리게 되는데\n메모리를 쪼개다 보면 프로그램이 그 공간 안에 다 안들어갈 수가 있으므로 프로그램도 쪼개게 된다(program partition)\nOS는 이제 메모리를 어떻게 쪼개고 프로그램도 어떻게 쪼개서 여기에 집어넣을건지를 관리해야 한다\n\nAddress Translation §\n\n우리가 코드를 짤때 쓰는 변수같은것들은 다 symbolic address이다 - 우리가 변수에 값을 저장한다는 말은 그 변수가 의미하는 주소에 저장된 값이 그것이라는 소리이므로\n근데 이제 컴파일 과정을 통해 오브젝트파일(c언어에서 .o 파일)로 바뀌게 되면 이 주소는 logical(relative) address가 된다 - 얘는 프로그램의 시작주소를 0이라고 했을때 해당 symbolic address가 저장된 곳의 위치 - 시작점과 현위치의 차이점이라고 생각하면 된다이다.\n이게 실행가능한 파일(executable code, machine code)가 되어 실행되면 실제로 메모리에 저장된 주소인 physical(absolute) address가 된다\n\n얘는 실제 주소를 가리켜야 되므로 레지스터 하나에다가 프로세스가 적재된 메모리의 첫 시작점을 저장하고 거기에 relative address를 더해 physical address를 구하게 된다\n다만 여기서 시작 주소라는 것은 PCB를 제외한 곳의 시작주소이다\n그래서 시작주소는 Base register, 끝주소는 Bounds register에 저장된다\nbounds register는 경계선을 그어줌으로써 허용된 범위 밖을 참조하지 못하게 하는 기능을 한다\n\n\n근데 swapping이 일어나게 돼 얘가 하드로 내려갔다가 다시 올라오면 원래 있던 그 위치로 올라오게 되는 것이 아니다. 따라서 프로세스의 첫주소가 바뀌게 되는데 이렇게 swapping에 의해 프로세스의 첫주소가 바뀌어 physical address가 바뀌는 것을 Relocate라고 한다\nOS는 이놈이 swapping 되어 다시 올라올때 어떻게 첫주소가 바뀌는지를 관리해야 한다 - relocation돼도 문제없이 physical address를 얻어낼 수 있도록\n\nOS가 메모리 관리를 위해 해야되는 것 §\n\nRelocation : 이걸 추적하고있어야됨\nProtection : 남의 영역에 침범하지 않도록 관리\nSharing : 프로세스 간 공유 메모리가 있을 때 protection을 지키는 선 한에서 문제없이 공유될 수 있도록 해야 함\nLogical organization, Physical organization : 실제로는 프로그램이 여러개로 나뉘어서 메모리에 적재되지만 나뉘어지지 않은것처럼 생각하도록 동작해야됨 - 이때 유저 입장에서 붙어있는걸로 생각하는 것이 Logical organization이고 컴퓨터입장에서 나뉘어있는것으로 생각하는 것이 Physical organization이다\n\nFixed partitioning §\n\nFixed partitioning : 메모리를 나눌때 고정크기로 나누는 것\n\nEqual-size partitioning §\n\n그냥 딱 정해진 크기로만 자르는 것\n하지만 얘한테는 다음과 같은 문제점이 있다 :\n\n프로그램이 잘라진 크기보다 더 크면 프로그램을 잘라서 올리는 overlay기법을 사용해야 된다\n반대로 프로그램의 사이즈가 너무 작게 되면 나머지 공간들이 낭비된다 - 이 낭비되는 공간을 internal fragmentation이라고 한다\n\n\n따라서 나누는 크기가 너무 크면 internal fragmentation이 커지고 너무 작으면 overlay기법에 의해 IO request가 너무 많이 발생해 문제가 된다\n\nUnequal-size partitioning §\n\n얘는 이제 프로그램의 크기에 딱 맞게 메모리를 나누는게 아니고 약간 호텔에서 1-2인실, 3-4인실 있는것처럼 여러개의 사이즈로 미리 나눈 다음 프로그램의 크기에 맞게 이 나뉘어진 공간에 넣는구조이다\n이렇게 넣을때는 각 방마다 큐를 만들어서 미리 프로그램들을 분배해서 이 큐에 넣어놓는 방법도 있고 큐를 하나만 써서 메모리에 적재될때마다 그때그때 분배하는 방법도 있다.\n하지만 얘한테도 단점이 있다 :\n\n나눈 파티션의 갯수가 결국에는 메모리에 올라갈 수 있는 user program의 갯수가 된다. 따라서 fixed 보다는 올릴 수 있는 프로그램의 수가 적어지게 된다\n얘도 internal fragment가 생긴다\n\n\n\nDynamic partitioning §\n\nDynamic partitioning : 메모리를 나눌 때 프로그램의 크기에 따라 유동적으로 나누는 것 - 그냥 프로그램의 사이즈와 동일하게 나뉘어진다\n이제 얘는 다음과 같은 문제점이 있다 :\n\n프로그램이 메모리에 적재되어있다가 나가면 그 아래에 있던애가 위로 땡겨져서 빈공간을 채우는게 아니라 그냥 비워진 상태로 있게 된다\n근데 그 이후 이 공간보다 작은 프로그램이 여기 적재되면 남는공간이 생기는데 이 공간의 크기가 작을 경우 어떤 프로그램도 들어오지 못하는 수가 있다 - 이런 공간들을 External Fragmentation이라고 하며 이런 공간들이 많아지면 역시 메모리가 비효율적으로 돌아가게 된다\n즉, 메모리가 남는 현상에 대해 fixed의 경우에는 internal이란 이름을 붙인거고 dynamic의 경우에는 external이라고 이름을 붙인 것\n\n\n위와 같은 현상을 방지하기 위해 저 비워진 공간을 비워두지 않고 땡겨서 공간들을 다 합쳐 이 공간들을 활용하는 방법이 나온다. 이것을 Compaction이라고 하며 윈도우에서 “디스크 조각 모음”이라고 하는 것(물론 얘는 메모리가 아니라 하드의 빈공간을 합치는거다)이 여기에 해당한다\n\n적재 알고리즘 §\n\n일단 프로그램이 얼마의 메모리를 먹을지는 적재시점에 알기는 어렵다 - 그래서 대략적으로 추정해서 적재하게 됨\n아래와 같은 적재 알고리즘들을 Placement Policy - 적재정책이라고 하더라\nFirst fit : 메모리의 처음부터 찾기 시작해 가장 먼저 등장하는 적재 가능한 공간에 넣는 것\nBest fit : 메모리 전체를 다 뒤져서 제일 적게 External fragment가 생기는 곳에 넣는 것\nWorst fit : 메모리 전체를 다 뒤져서 제일 많이 External fragment가 생기는 곳에 넣는 것 - Worst라고 해서 안좋은게 아니다 - 저게 크면 저부분에 또 다른 프로그램이 올라갈 확률도 많아지므로\nNext fit : 제일 최근에 넣었던 부분 바로 옆에다가 적재하는 것\n저것들 중에 Best, worst가 적재하는데 제일 오래 걸린다\nBuddy system : 얘는 프로그램의 크기에 따라 메모리를 자르긴 하되 2의 배수에 맞춰서 메모리를 자르는 방식이다 - 만약에 100k를 요청하게 되면 128k의 메모리 공간에 적재하는 것 - 메모리 공간을 절반으로 자르고 자르고 해서 제일 잘 맞는 곳에다가 적재하게 된다\n\nPaging §\n\n일단 메모리를 고정크기로 잘게 나눈다. 이 나눈 고정크기의 메모리 조각을 frame이라고 한다\n그리고 프로그램도 같은 크기로 잘게 나눈다. 이 나눈 고정크기의 프로그램 조각은 page라고 한다\n이 둘의 크기가 같기 때문에 하나의 페이지는 하나의 프레임에 올라가게 된다\n고정크기를 활용하기 때문에 fixed partitioning의 상위호환이라 볼 수 있다\n\nPage table §\n\n얘는 프로그램을 메모리에 적재할 때 연속된 공간에 적재하지 않을 수도 있다\n대신 해당 프로그램이 어디어디에 적재되어있는지를 알려주는 역할을 하는 page table이 존재하게 된다\n전에 PCB를 모아놓은 Process table이 있다고 했는데 여기에 page table도 같이 들어있다\n이 page table은 배열처럼 인덱스마다 프로그램이 적재된 페이지의 번호를 저장한다 - 인덱스는 page번호(프로그램을 프레임 크기만큼 잘라서 앞에서부터 0, 1, … 이렇게 번호를 매긴 것), 안에 저장돼있는 값은 frame 번호(메모리 전체를 frame크기만큼 잘라서 0, 1, … 이렇게 번호를 매긴 것)\n따라서 page 번호는 프로그램을 앞에서 잘라 매긴것이므로 logical address를 표현할 때 사용되고 frame번호는 메모리를 앞에서부터 잘라 매긴 것 이므로 physical address를 표현할 때 사용되는 것이다\nfree frame table도 존재해서 남은 프레임들의 번호도 저장하게 된다\n\nPaging에서의 physical address 구하기 §\n\n\nRelative address는 수치상으로 시작점부터 얼마나 떨어져 있는지를 나타내는 개념이고\nLogical address는 relative address를 page 번호를 이용해 나타낸 개념이라는 차이점이 있다 - 어쨋든 둘 다 시작점을 기준으로 거리를 나타내는 개념이다\n왼쪽의 프로세스를 page크기인 1k로 자르면 오른쪽 그림처럼 나온다. Relative address 1502는 1024 + 478이므로 page 하나와 478만큼의 거리만큼 떨어진 곳이 해당 주소가되는 거고 이걸 logical address로 표현하면 page1번 시작점으로부터 478만큼 떨어져 있다는 의미로 page# = 1, Offset = 478이 되는 것이다 - Offset은 페이지의 시작점으로부터 얼마나 떨어져있는지를 나타내는 것\n이것을 이진법으로 계산한 것이 위쪽에 나와있는 수치들이다. 1024는 2의 10제곱이므로 16비트로 표현된 relative address에서 6비트 /10비트로 나누면 앞쪽부분이 page#, 뒤쪽부분이 Offset이 되는 것이다\n\n\n\n이것을 이용해 physical address를 나타내는 것은 이 그림에 나와 있다.\n일단 page# 이 1 이므로 이것을 page table의 인덱스로 넣어주면 거기 저장되어있는 값이 frame# 가 되는것이다\n따라서 이 frame# 을 6-bit page# 에다 넣어주면 바로 physical address가 나오게 되는 것 이다 - page table에 가서 frame# 만 가져다가 붙여주면 되기 때문에 address translation이 아주 간편하다\n\nSegmentation §\n\n이제 얘는 고정크기로 나누는게 아니고 메모리를 프로그램의 function(module)크기로 나눠서 적재하는 기술\n메모리와 프로그램을 같은 크기로 나누되 그 크기는 프로그램의 function(module)의 크기를 따라간다고 생각하면 된다\n이렇게 하는 이유는 memory sharing을 할때도 function(module)단위로 하게 되므로 이것의 크기를 기준으로 나누는게 좋겟다고 생각한것\n이렇게 function(module)을 기준으로 나눈 조각조각을 segmentation이라고 한다\n얘는 가변크기이기 때문에 dynamic partitioning의 상위호환이라고 볼 수 있다\n\nSegmentation에서 physical address 구하기 §\n\n\n얘는 paging처럼 크기가 고정되어 있지 않으므로 앞의 몇비트는 segment# 를 나타내는데 쓰이고 나머지는 Offset을 나타내는데 쓰이는 식으로 구성된다 - paging처럼 relative address에서 몇비트를 자른다고 해서 바로 segment# 가 구해지는게 아니다\n그래서 예시를 보면 segment# 에 4비트가 할당되어 있으므로 한 프로그램이 가질 수 있는 총 segment# 의 갯수는 2의 4제곱인 것이고 그 뒤에 offset으로 12비트가 할당되어 있으니 한 segment는 최대 크기가 2의 12제곱이 되는 것이다\n프로세스 전체를 segment0 750, segment1 1950으로 자른 다음(자르는 기준은 당연히 module이겠쥬?) 계산해보면 logical address segment1의 offset 752부분이 relational address의 1502와 같아지게 되는 것\n\n\n\n그래서 이 logical address로 physical address를 구하는 방법이 위 그림이다\nsegment table은 segment가 어디서 시작하는지에 대한 주소인 base와 한 segment의 길이인 length를 담고 있는 배열이다.\nlogical address의 앞 4비트를 이용해 인덱스를 알아내고, 그 인덱스로 가서 뒤의 16비트를 가져오면 그게 segment의 시작점 주소가 된다. - 이번에는 paging과 다르게 풀 주소값이 저장되어 있으므로 이 값을 offset이랑 더해 physical address를 얻어내는 것\n그리고 length는 offset값이 정상인지를 검사하는 용도로 쓰인다. 즉, segment의 길이가 length이므로 offset이 저 값보다 작아야 정상인 것\n\nPaged Segmentation §\n\n얘는 이제 저 둘을 합친 개념이다. 즉, function(module)별로 메모리에 적재를 하되 얘네들을 여러 frame에 걸쳐서 적재를 하는 것을 Paged segmentation이라고 한다\n즉, function(module)하나를 여러 연속된 frame에 걸쳐 적재하는 것\n"},"os.spring.2021.cse.cnu.ac.kr/8.-가상메모리":{"title":"8. 가상메모리","links":[],"tags":[],"content":"가상메모리 §\n\n봐봐라\n실제로는 프로그램의 전부가 메모리에 올라가는 것이 아닌 프로그램의 페이지 일부만 메모리에 올라가게 된다\n그리고 실제로는 페이지들이 하드에나 메모리에나 연속된 공간에 있지 않고 다 흩어져 있다\n하지만 우리가 생각할때는 이 페이지들이 전부 메모리에 연속적으로 적재되어있다고 생각하고 프로그램을 짜게 된다 - 이렇게 사용자입장에서 생각하기 편하게 하려고 착각을 유도하는 기법을 가상 메모리(Virtual Memory) 라고 한다\n\n이렇게 가상 메모리 기법을 적용한 paging을 일반 paging과 구분해 Virtual Memory Paging이라고도 부르더라\n마찬가지로 가상 메모리 기법을 적용한 segmentation을 Virtual Memory Segmentation이라고 한다\n\n\n이렇게 함으로써 우선 메모리 사이즈보다 더 용량이 큰 프로그램도 메모리에 적재시킬 수 있고, 프로그램 전부가 올라가지 않기 때문에 더 많은 프로그램을 적재할 수 있어 Multiprogramming에서도 이점이 있다(Multiprogramming level을 높일 수 있다)\n\n그리고 이것은 프로그램 개발자의 관점에서도 프로그램 크기에 따라 다르게 프로그래밍 할 필요가 없다는 이점이기도 하다\n\n\n이때 원하는 페이지가 메모리에 적재되어있지 않고 하드에 들어있을때 Page fault가 일어나게 된다 - 이렇게 page fault가 일어나면 block을 먹고 IO operation이 일어나며 가져오고난 뒤에는 인터럽트를 걸고 다시 ready상태로 바뀐 다음에 dispatch되면 실행되는 과정을 거치는 것\n가상메모리가 잘 구동되기 위해서는 물리적으로 메모리 공간을 나눠 page가 들어올 frame들을 구성하는 하드웨어적인 역할 과 page replacement같은 기능을 수행할 소프트웨어적(운영체제적)인 역할 이 중요하다\n\nPage 사이즈 정하기 §\n\nPage 사이즈가 작으면 만약에 page fault가 일어났을때 한번에 가져오는 양이 적기 때문에 page fault가 자주 일어나게 된다\n또한 page table의 사이즈가 커져 PCB가 커지기 때문에 많은양의 메모리를 먹게 된다\n하지만 반대로 page 사이즈가 너무 크면 작은 프로그램의 경우에는 page하나에 담기고 남은 부분이 internal fragmentation이 되기 때문에 메모리의 낭비가 생기게 된다\n이렇듯 운영체제를 설계할때는 항상 대조되는 선택지의 장단점이 존재하기 때문에(Trade-off라고 한다) 이것을 잘 조화시켜서 최선의 결과를 내는 Optimal Design이 중요하다\n요즘의 경우에는 메인메모리의 값이 그렇게 비싸지 않기 때문에 fragmentation이 그렇게 큰 문제가 안돼 page의 사이즈를 크게 하는것이 추세란다\n\n\n\n첫번째 그래프에서 왜 사이즈가 작을때 page fault가 작아지는지는 모르겠음 - 어중간할때는 왜 큰지도 모르겠음\n어쨋든 사이즈가 커지면 한번에 많이 갖고오므로 page fault가 잘 안일어난다는게 중헌것이고\n두번째 그래프는 프로세스 하나에 대해 frame이 몇개가 할당되는지에 대한 그래프다. 높을수록 프로세스 하나에 많은 frame을 할당받으므로 메모리에 올라갈 수 있는 프로세스의 갯수는 적어지고 대신 보다시피 page fault rate는 적어진다\n\n\n\n근데 할당되는 프레임의 갯수가 많아지면 rate가 줄어야 정상인데 replacement algorithm 이 잘못되면 저렇게 rate가 치솟는 현상이 생기고 이것을 Belady’s anomaly라고 한다\n\nPage Replacement §\n\n이전에 프로세스가 메모리에 들어와야 되는데 메모리에 자리가 없으면 한놈이 자리를 비켜주고 하드로 내려가는거를 swapping이라고 했는데\nPaging기법에서도 동일하게 메모리에 자리가 없으면 어느 한 놈이 자리를 비켜주는 동작을 하게 되고 이것을 Page Replacement라고 한다\n근데 이때 아무 page나 내려보내게 되면 프로그램이 비효율적으로 동작할 수도 있다\n\n즉, page 교체 알고리즘에 따라서 동작의 효율성도 달라질 수 있다는 소리임\n뭐 예를 들면 우선순위가 비교적 높은 놈의 page를 내려보내면 얘를 조만간 다시 갖고 올라와야되기 때문에 page fault가 자주 일어나 IO request도 자주 일어나게 되는 것\n\n\n그리고 page는 어차피 원본의 page가 하드디스크에 저장되어있기 때문에 메모리에 적재되어있던 page와 하드디스크에 있던 원본의 page가 차이가 없으면 하드로 내려보낼 때 굳이 새로 write하지 않고 하드에서 올라오는 page를 그 자리에 overwite하게 된다\n하지만 메모리에 올라와있던 page에 변경이 생기게 되면 그제서야 하드에 write하는 작업을 하게 된다\n그리고 이제 안그래도 IO가 일어나서 기다렸는데 자리가 없어서 replacement까지 일어나면 OS입장에서는 굉장히 기다리는 시간이 아까우므로 OS는 항상 일정한 수만큼 blank(비어있는) frame을 만들어놓는다 - 그래서 IO가 끝나면 바로바로 올릴 수 있게\n\n위에꺼를 반영한 paging / segmentation §\n\n\n여기서 페이지 테이블의 한 행의 구조를 나타낸 것이 아래 그림인데 보면 frame number만 있는게 아니고 앞에 Control Bit가 붙는다\n얘는 데통에서 헤더마냥 frame / page 의 여러가지 정보를 담는 부분이다\n일단 P는 이 page가 현재 메모리에 적재되어있냐를 나타내는 비트(Present)이다.\n\n즉, 이게 enable되어 있으면 frame number부분에 유효한 number가 들어가 있을 것이고\ndisable되어 있으면 메모리에 적재되어있지 않다는 뜻으로 유효하지 않은 number가 들어있게 된다\n\n\n그리고 M은 이 page가 변경되었냐를 나타내는 비트(Modified)이다\n\n위에서 설명한것처럼 page replacement를 할 때 변경되지 않았으면 굳이 하드에 write를 하지 않아도 되기 때문\n\n\nsegmentation의 경우에도 앞에서 배운거랑 마찬가지되 P, M이 붙게 된다\n\nPaging의 address translation 방법 복습 §\n\n\n가상 주소에서 offset은 그대로 가고 page# 을 이용해 frame# 를 찾는거\n레지스터에 저장된 page table의 시작점, 즉. page table ptr을 이용해 page table로 이동하고, page# 를 인덱스로 하여 frame# 을 얻어내 physical address를 얻어내는 것\n\nThrashing §\n\n\n봐봐라\n메모리에 많은 프로세스가 올라가게 되면, 즉, multiprogramming level이 올라가게 되면 당연히 cpu utilization도 늘어난다\n근데 multiprogramming level이 늘어난다고 무조건적으로 좋은것은 또 아니다 이말이야\n\n왜냐면 multiprogramming level이 늘어나면 하나의 프로세스에게 할당되는 공간이 줄어들고 그러면 page fault가 더 자주 일어나게 되기 때문이다\n그래서 저 위의 그래프에서 보이듯이 일정수준까지는 multiprogramming level이 늘어갈수록 cpu utilization도 늘어나게 된다.\n하지만 그 수준을 넘어서게 되면 위에서 설명한것처럼 page fault가 자주 일어나 cpu utilization이 급격하게 하락하게 된다\n이 지점을 Thrashing이라고 하는 것. 즉, multiprogramming level이 과도하게 많아지면 page fault가 너무 자주 일어나 cpu utilization이 급락하는 것을 의미한다\n따라서 운영체제 입장에서는 Thrashing은 반드시 막아야 되는 현상이다\n\n\n따라서 multiprogramming level이 너무 낮으면 프로세스 하나가 블락을 먹었을때 대체제의 선택폭이 좁아져 cpu utilization이 안좋고 또 너무 높으면 thrashing이 일어나기 때문에 안좋아져서 적절한 level을 잡는 것이 중요 하다\n\nLocality - 지역성 §\n\n만약에 프로그램에 while문이 하나 있다고 하고 이부분이 세개의 page로 나뉘어졌다고 해보자\n근데 만약 메모리에 공간이 없어서 두개의 frame밖에 할당하지 못한다면 루프가 돌때마다 page fault가 일어나므로 아주 효율성이 떨어질 것이다\n따라서 다음과 같은 경우에는 해당 프로세스에게 3개 이상의 frame을 할당하는 것이 효율성을 높이게 된다\n이렇듯 프로세스를 이루는 page들 중에서도 집중적으로 실행되는 page들을 중간에 끊지 않고 전부 메모리에 올려 page fault를 줄이는 것을 지역성(Locality) 이라고 한다\n\nCombined segmentation &amp; paging §\n\n\n이부분은 별로 설명 안함 - 가상메모리에 page# 와 seg# 둘 다 있어서 page table과 segment table을 둘 다 이용한댄다\n\nMulti-Level Hierarchical Page Table §\n\n\npage table을 다계층 구조로 만들어 page table의 사이즈를 줄이는 기법이다\n\n봐봐라\n만약에 page# 에 20비트가 할당되어있고 offset이 12비트인 32비트 체제라면 page table의 길이는 2의 20승이다\n하지만 프로그램의 크기가 작아서 page가 몇개 되지 않는다면 2의 20승 중에 일부만 사용하고 나머지는 버리게 되는 셈이다\n근데 이것을 두개의 계층으로 나누면 첫 10비트는 첫번째 계층 table에서의 index를 나타내고 나머지 10비트는 두번째 계층 table에서의 index를 나타내는데\n만약에 프로그램을 구성하는 page의 갯수가 2의 10제곱보다 작으면 하나의 2^10 사이즈 테이블로 모든 page# 에 대응되는 frame# 을 저장할 수 있자네\n이때 이 2^10 사이즈 테이블이 2계층 테이블인거고 이 2계층 테이블들로 접근할 수 있도록 얘네들의 주소를 담고 있는 테이블이 1계층 테이블인 것이다\n따라서 page의 사이즈가 2^10보다 작으면 1계층 테이블에는 하나의 원소만 존재하고 2계층 table하나만 있어도 모든 page에 대응되는 frame을 저장할 수 있으므로 메모리를 2^11 만 차지하게 되는 것 - 계층구조를 도입하기 전인 2^20에 비해 엄청난 양의 공간을 절약할 수 있다\n\n\n이런식으로 가상주소의 page# 구역을 여러개로 쪼개 page table하나로 모든 page에 대응하는 것이 아닌 page table을 계층적으로 구조화해 동적으로 page table이 생성되며 메모리를 절약하는 방식 이 Multi-Level Hierarchical Page Table인 것이다\n다만 이 방식에 장점만 있는 것은 아니다 - 다계층이 될 수록 address translation은 복잡해지기 때문에 수행시간이 오래 걸리는 것 = 공간과 시간이 반비례하는 현상이 여기서도 나타나게 되는 것이다\n\n\n\n따라서 보면\n\n첫 10비트와 page table ptr를 통해 알아낸 1계층 테이블로 이 가상주소의 frame# 을 담고 있는 2계층 테이블의 주소를 알아낸다\n그리고 2계층 테이블로 가서 두번째 10비트를 이용해 frame# 을 알아내게 되는 것\n\n\n\nInverted Page Table §\n\n\n봐봐라\n일단 Inverted Page Table의 개념은 프로세스들마다 존재하는 page table을 하나로 합쳐 OS에 하나만 존재하는 테이블로 만드는 것이다\n이렇게 바꾸는 과정은 약간 데베식의 설명을 곁들이면 하나의 frame# 을 특정하기 위해서는 page# 와 pid를 기본키로 하면 특정할 수 있다\n\n근데 프로세스마다 존재하는 page table은 이미 pid가 PCB에 저장되어있기 때문에 page# 만으로 하나의 frame# 을 특정할 수 있었던 것 인데\n이것을 이제 하나의 테이블로 합치면 pid는 알 수가 없기 때문에 pid 어트리뷰트를 하나 추가하고 거기에 대응되는 frame# 을 저장하는 것 - 저기 그림에서 Chain이라고 표시된 부분이 frame# 이 저장되는 부분이다\n근데 하나의 메모리 공간을 여러 프로세스가 공유하는 경우도 생긴다 - 뭐 공유 메모리라던가, 하나의 프로그램을 여러번 실행시켜 read-only인 코드는 여러개의 프로세스가 공유하는 등\n이것을 지원해주기 위해 chain값으로 다른 프로세스의 페이지가 담긴 frame# 을 넣어서 참조하게 할 수 있다\n\n\n따라서 page# 을 가져와서 테이블에서 자신과 page# 와 pid가 같은 인스턴스를 찾아 chain 어트리뷰트의 값인 frame# 을 받아 address translation 을 하는 것\n이때에는 찾는 과정을 빠르게 하기 위해 hash function을 이용한다 - 파이썬 딕셔너리할때 그 해시임\n\nLookaside Buffer §\n\n얘는 저장장치의 한 종류인데\n보통 하나의 값을 배열에서 찾거나 할때는 처음부터 serial하게 쭉쭉 찾아나가자네?(O(n))\n근데 이걸 사용하면 배열의 모든 원소를 한번에 비교해 원하는 값을 찾는 것 같은 기능을 제공해준다(O(1))\n저장장치의 한 종류이므로 하드웨어이고 이런 강력한 기능을 제공하는 대신 좀 비싸다\naddress translation을 담당하는 lookaside buffer를 **Traslation Lookaside Buffer(TLB)**라 하고 얘는 레지스터의 한 종류이다\n\n얘를 이용해 address translation을 하는 방법 §\n\n\nPage table의 일부분을 저 TLB로 올린다\n이제 가상주소 하나를 translation할 때 page# 을 저기 TLB에 먼저 넣어본다\n만약에 hit(찾음) 이면 바로 frame# 가 나오게 되고 miss(못찾음) 이면 이제 그제서야 page table로 가서 serial하게 찾게 된다 - page table의 일부분만 TLB에 올라갈 수 있으므로 miss될 수 있다\n찾으면 Locality를 활용하기 위해 TLB에 이 page를 넣어놓는다 - 또 사용되면 빠르게 hit시키기 위해 → 그리고 translation을 해 frame# 을 얻어내는 것\n하지만 page table에서 봤더니 얘가 메모리에 없을 수도 있다 - 그러면 page fault handling routine이 실행되어 이놈을 갖고오고 처음부터 다시 하게 되는 것\n\n\n이 방법은 운이 없어서 miss가 뜨면 TLB에 접근하는 시간만큼 손해이긴 하다\n하지만 위에서 말한 Locality를 이용하면 hit의 비율을 90퍼센트 이상으로 끌어올릴 수 있고 이러면 serial하게 비교하는 경우가 거의 없기 때문에 아주 빠르게 address translation이 가능하다\n\nCache §\n\n캐시도 TLB와 비슷하게 one-time search를 지원해주는 저장장치이다\nphysical address를 구하고 나서 원래는 이 주소에 해당하는 메모리 공간으로 가 instruction을 실행하는데\n메모리에 가기 전에 먼저 cache에 가서 이 주소에 대한 instruction이 이미 존재하는지를 찾는다\n그래서 만약에 hit라면 바로 cpu로 올려 실행하게 되는 것 이고\n아니면 그제서야 메인메모리의 해당 주소로 가게 되는 것\n"},"os.spring.2021.cse.cnu.ac.kr/9.-Segmentation":{"title":"9. Segmentation","links":[],"tags":[],"content":"Segmentation §\nSegmentation 의 장단점 §\n\n우선 장점은 모듈 단위로 끊기 때문에 모듈의 protection과 data shraing이 잘된다는 거고\n단점은 이제 external fragmentation이 발생한다는 것과 이것을 최소화하는 것이 힘들다는 것이다\n\nAddress Translation §\n\n\n이전에도 한번 설명한거같은데\n일단 Seg# 를 인덱스로 하고 Seg Table Ptr을 이용해 테이블에 접근하고\n거기서 Base는 Segment의 시작주소가 담겨있으므로 이거에 offset을 더하면 된다\n그리고 Length는 Segment의 길이로 offset은 이것보다 커서는 안된다\nPaging과 Segmentation의 Address Translation 차이점을 잘 기억해라\n\nSegmentation Paging §\n\n\n그래서 보통은 Segmentation과 Paging을 섞은 Segmentation Paging을 사용한다\n얘는 Module단위로 Segment으로 나뉘긴 하는데 이 각각의 Segment들은 일정한 크기의 Page로 나뉘는 것\n따라서 Logical address도 ( Seg# - Page# - offset ) 순서로 구성된다\n\nAddress Translation §\n\n\n보면 이제 일단 Seg Table Ptr를 이용해 테이블에 접근하고 Seg# 를 인덱스로 해서 해당 원소에 접근한다\n근데 여기서 중요한 것은 Seg# 를 인덱스로 한 곳에는 Page Table의 주소가 들어있다. 즉, Segment table은 Process마다 하나씩 갖지만 Page Table은 Segment마다 하나씩 갖게 된다\n그렇게 Page table로 접근해 Page# 를 인덱스로 해서 frame# 을 알아낸다\n그리고 offset앞에 frame# 을 딱 붙여주기만 하면 변환이 마무리되는 것\n\n\n\n따라서 주소와 테이블 인스턴스는 저렇게 구성된다\n아까 말한것처럼 Segment Base에 Page Table의 시작주소가 들어가게 되는 것\n그리고 Page Table도 기존처럼 변경 유무를 저장해 replacement를 쉽게 하는 등의 기능들을 지원하기 위해 Pbit와 Mbit같은 Control Bits가 존재한다\n\nOS Policies for Virtual Memory §\n\n아래의 용어들을 다 알아야된다\n\n\nFetch Policy §\n\nFetch Policy : 언제 페이지를 하드에서부터 갖고올 것이냐\nDemand Paging : 요구가 있을때 갖고옴. 즉, 참조를 할때 그제서야 갖고오는 정책\n\n당연히 메모리는 적게먹는다. 하지만 Page fault가 많이 일어나게 되는 단점이 있다\n\n\nPrepaging : 하드에서 갖고올때 걔만갖고오는게 아니고 다음에 쓸거같은애들도 같이 갖고 옴\n\n예를들면 page# 1 을 가져올때 page# 2도 나중에 쓰게될 확률이 높으므로 얘도 같이 가져오는 것\n메모리는 좀 더 먹지만 page fault가 적게 일어난다는 장점이 있다\n따라서 오늘날 주로 쓰이는 OS정책임\n\n\n\nPlacement Policy §\n\nPlacement Policy : best fit 같은애들. segment를 빈공간 어디에 적재할 것인가\n당연히 paging기법을 사용하면 이런거를 고민할일이 없기 때문에 요즘은 별로 중요하지 않은 정책이다\n\nReplacement Policy §\n\nReplacement Policy : Page fault가 일어났을 때 어떤애를 선택하여 아래로 내려보낼 것인가 - 교체대상 선정\nFrame Lock : 커널같은 중요한 프로세스들은 하드로 내려가면 안되기 때문에 lock을 걸어서 replacement 대상에서 제외하는 것\n\n\n\nReplacement Algorithm 예시 - 이거 시험문제 나온다 - 어떤 알고리즘을 선택했을때 앞에서 배운 Anomaly(이상현상)이 일어나는지 생각해볼것 - 정 모르겠으면 구글링해서 찾아봐라 - 안알려주노 ㅅㅂ\n위에 나열돼있는 숫자들이 요청된 페이지 번호, 그리고 그 아래가 프로세스에 할당된 프레임의 모습이다 - 3개로 일정하고 자신의 프로세스 내에 있는 페이지를 버리므로 local이라고 할 수 있다 - 예시에서는 초기에 적재되는 page fault는 무시하고 page fault가 일어나 replace가 일어나야되는 것만 카운트했다\n\nOPT(Optimal) : Replacement가 일어났을 때 미래의 페이지 사용을 보고 안쓰이거나 가장 나중에 쓰이는 (혹은 가장 최근에 사용된 - 가장 최근에 사용된 놈은 다시 사용할 가능성이 비교적 낮다고 판단)페이지를 내려보낸다 - 당연히 미래의 일을 알아야되므로 구현이 불가능 하며 다른 알고리즘과의 비교를 위해 존재하는 것이다 - 위의 예시에서는 3번의 Fault가 일어나며 제일 좋은 성능을 보여주지만\nLRU(Least Recently Use) : 제일 오래전에 사용된 놈을 버리는 구조\nFIFO(First In First Out) : 이건 뭔지알제? 제일 먼저 들어온놈이 먼저 나가는 구조 - 얘는 LRU랑 헷갈리면 안된다 - LRU는 제일 오래전에 사용된거고 FIFO는 제일 오래전에 메모리로 올라온거임\nCLOCK(Secondary Chance Algorithm) :\n\n\n\n\n\n이게 뭔뜻이냐면 원 밖에 있는 숫자는 frame# 을 의미 하고 저 한칸한칸에는 해당 프레임에 할당된 page# 와 몇번사용(참조)했는지(use)가 저장되어있다\n그리고 저 시계바늘이 룰렛마냥 방출될 애를 가리키는 역할이다\n일단 이러한 구조때문에 CLOCK이라는 이름이 붙어있는 것\n그리고 이 알고리즘이 구동하는 방식때문에 Second Chance Alg라는 이름이 붙었는데\n저 시계바늘이 가리키고있는 놈의 use가 0이 아니면 얘를 방출시키지 않고 다음칸으로 넘어가며 use를 0으로 초기화하기 때문에 한번 더 기회를 준다는 의미에서 저런 이름이 붙은 것이다\n이제 반대로 시계바늘이 가리키고있는놈의 use가 0일 경우에는 그놈을 방출시키고 새로운 페이지를 들이는 것\n따라서 위의 예시에서 frame# 2, 3의 use가 0으로 바뀌고 4번에 새로운 페이지가 들어오며 들어옴과 동시에 한번 사용하기 때문에 use는 1로 되어있는 것이다\n이렇게 되면 use가 0이라는 것은 시계바늘이 한바퀴 돌때동안 사용되지 않았다는 뜻이므로 가장 오래전에 사용된거랑 비슷하다 - LRU와 유사한 효과, 성능을 낸다\n반대로 use가 0이되고 나서 시계바늘이 한바퀴 돌때동안 사용되었다면 다시 use가 올라가므로 시계바늘이 다시 돌아왔을 때 방출되지 않고 다시 0으로 바뀌게 되는것\nPage Buffering : 얘는 뭐냐면\n\n만약 메모리의 일정부분을 free로 유지하기 위해 페이지 한놈을 하드로 내려보냈다고 해보자\n근데 실행되다가 이놈이 다시 필요해진 순간이 왔을때 page table로 가서 Pbit를 보면 당연히 하드로 내려갔으므로 없다고 뜰것이다 이말이야\n근데 만약에 아직 이자리에 다른 프레임이 overwrite되지 않았으면 이놈은 free이긴 해도 데이터는 그대로 남아있을거란말이지\n그래서 바로 IO를 때려 하드에서 갖고오기보다는 데이터가 아직 overwrite되지 않았을 수도 있으므로 free인 저 공간을 다시 조사해 원래의 페이지가 남아있으면 다시 Pbit를 바꾸고 그대로 사용하는 개념이다\n\n\n\nResident Set Management §\n\nResident Set Size : 한개의 프로세스에 몇개의 프레임을 할당할 것 인가\n\nFixed : 고정된 갯수의 프레임을 할당\nVariable : 가변갯수의 프레임을 할당 - 요즘 추세란다\n\n\n\n\n\nWorking Set Model : 걍 단순하다 - 특정 시점에 Window size(할당되는 프레임 최대 갯수)만큼의 최근 페이지 참조(위의 예시에서 한 시점 기준 window size만큼 위에있는만큼의 페이지를 묶어서)를 보고 그거를 집합으로 묶어 그 시점에의 할당 프레임 갯수를 정하는 것\n\n알고리즘이 간단하고 Locality가 반영된다는 장점 이 있음\n하지만 실제로 써보니까 Locality도 제대로 반영 안되고 에 따라 너무 할당되는 갯수도 달라지고 window size를 정하기도 어려운 등의 문제가 있더라\n\n\n\n\n\nVariable-Interval Sampled Working Set(VSWS) - 얘는 이제 page fault rate의 상한선과 하한선을 정해놓고 할당갯수를 변화시키면서 rate가 너무 높으면 할당갯수를 늘리고 rate가 하한선보다 떨어져서 할당갯수가 너무 많으면 줄이고 하는식으로 유동적으로 할당갯수를 줄이는 방식이다\nReplacement Scope : 하드로 내려보낼 페이지를 정하는 범위\n\nGlobal : 현재 프로세스가 아닌 다른 프로세스의 페이지를 내려보냄 - 속도를 위해 요즘은 얘를 사용한댄다\nLocal : 현재 프로세스의 페이지를 내려보냄\n\n\n\nCleaning Policy §\n\nCleaning Policy : 프로세스가 종료되고 프레임들을 비우는 것에 대한 정책\n메모리에 있는 페이지가 변경되었을 경우에 변경될때마다 하드에 있는 페이지를 바꿔주기(Demand Cleaning)보다는\n메모리에 있는놈이 하드로 내려갈때 변경사항을 한번에 업데이트해주는 방법(Precleaning)을 이용한댄다\n\nLoad Control §\n\nLoad Control : 프로세스를 메모리에 올려주는 Loader와 관련된 정책 - 몇개의 프로세스를 올려 multiprogramming level을 어떻게 가져가 최적의 cpu utilization을 낼 것인가(Thrasing을 내지 않을 것인가) - 위에서의 Resident Set Management와도 연결되는 내용\n여기서 multiprogramming level이 너무 높아 page fault가 너무 많이 일어나 프로세스를 내쫒을때는 다음과 같은 룰들을 적용한다(이게 전부는 아님 - 참고)\n\n우선순위가 낮은놈\nfault를 많이 일으키는 놈\n마지막으로 실행된놈\n가장 적은 프레임을 가지고있거나\n가장 사이즈가 큰 프로세스\n\n\n"},"pl.spring.2021.cse.cnu.ac.kr/(충남대)-프로그래밍-언어-개론-강의록":{"title":"(충남대) 프로그래밍 언어 개론 강의록","links":["pl.spring.2021.cse.cnu.ac.kr/1.-OCaml-문법-(1)","pl.spring.2021.cse.cnu.ac.kr/2.-OCaml-문법-(2)","pl.spring.2021.cse.cnu.ac.kr/3.-재귀-호출-최적화-기법","pl.spring.2021.cse.cnu.ac.kr/4.-Syntax와-Semantics","pl.spring.2021.cse.cnu.ac.kr/5.-Lexical-Analyzer-(Lexer,-어휘분석기)","pl.spring.2021.cse.cnu.ac.kr/6.-Syntax-Analyzer-(Parser,-구문분석기)","pl.spring.2021.cse.cnu.ac.kr/7.-언어의-정의","pl.spring.2021.cse.cnu.ac.kr/8.-문법적-설탕과-식별자","pl.spring.2021.cse.cnu.ac.kr/9.-함수와-함수호출","pl.spring.2021.cse.cnu.ac.kr/10.-1등-시민-함수","pl.spring.2021.cse.cnu.ac.kr/11.-조건분기문","pl.spring.2021.cse.cnu.ac.kr/12.-재귀함수","pl.spring.2021.cse.cnu.ac.kr/13.-명령형-언어-(1)","pl.spring.2021.cse.cnu.ac.kr/14.-명령형언어-(2)"],"tags":[],"content":"Table of Contents §\n\n1. OCaml 문법 (1)\n2. OCaml 문법 (2)\n3. 재귀 호출 최적화 기법\n4. Syntax와 Semantics\n5. Lexical Analyzer (Lexer, 어휘분석기)\n6. Syntax Analyzer (Parser, 구문분석기)\n7. 언어의 정의\n8. 문법적 설탕과 식별자\n9. 함수와 함수호출\n10. 1등 시민 함수\n11. 조건분기문\n12. 재귀함수\n13. 명령형 언어 (1)\n14. 명령형언어 (2)\n"},"pl.spring.2021.cse.cnu.ac.kr/1.-OCaml-문법-(1)":{"title":"1. OCaml 문법 (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\n들어가기에 앞서 §\n\nOCaml은 점유율 낮은 ㅈ망언어인것은 맞다.\n하지만 지독하게 매니악한 극한의 함수형 언어란 것임에는 이견이 없는거같다\n한번 배워놓으면 다른 언어에서의 함수형 기능을 좀 원활하게 습득할 수 있지 않을까 싶다\n\nOCaml §\n\n함수형 언어\nStrongly typed language : 정적 자료형 선언\n\n하지만 자료형 추론기능을 제공하므로 타입을 써주지 않아도 됨. 단, 동적선언이 아니므로 자료형 미스매치의 경우 오류가 난다\n\n\nPolimorphism : 기억안나제?\nPattern matching : 아직 뭔지 모르겠음\nModule system : 모듈기능 제공\nOOP : 객체기능을 사용할 수 있다\n\n자료형 §\n\n() : unit. void와 같은 기능이다\n모든 자료형은 원시타입이다. 객체타입이 아니다\n실수의 사칙연산은 반드시 기호 옆에 .를 붙여줘야 한다\n\n예를들어 +연산은 +.이다\n\n\n문자열 연산\n\n^ : 문자열 이어붙이기\n“문자열”.[인덱스] : 인덱스 접근\nString.length “문자열” : 길이구하기\nString.sub “문자열” 2 3 : 슬라이싱\n\n\n주의할 논리연산자\n\nx = y, x &lt;&gt; y : 값비교 연산자\nx == y, x != y : 값, 주소비교 연산자\n=가 할당연산자가 아니라는것에 유의해라\n\n\n\n컴파일 §\n\nDune 파일 고치고\n커맨드에 이걸 친다\n\ndune exec --profile release ./file.exe\n화면 입출력 §\n\n화면 출력\n\nFormat.printf 출력할거\n\n화면 입력\n\nlet x = read_line() in\n함수호출 §\n\n호출시 인자를 넣어줄때 괄호를 쓰지 않고 띄어쓰기로 대체한다\n인자들을 구분하는것도 띄어쓰기를 이용한다\n\nfunc(a, b) → func a b\n\n\n오캠엘에서의 함수는 무적권 값을 반환해야 한다 : 아무것도 반환할게 없으면 ()을 반환하면 된다\n\n()는 unit이라는 값으로 void와 의미는 동일하지만 어떤 ‘값’이라는 점에서 차이점을 가진다\n\n\n\n변수 선언, 초기화 §\nlet 변수 = 값 in\n\n일반적인 언어처럼 = 로 할당하는게 아닌 let = in 이라는 구문을 써야 한다\n모든 변수는 선언과 함께 초기화가 이루어져야 한다\nscope는 변수의 사용 범위를 나타내며 in이 그 역할을 한다 - in을 사용하면 로컬, 사용안하면 글로벌\nOCaml에서는 모든 변수가 불변으로 선언됨\n\nx에 1을 넣고 나중에 2를 넣으면 변수 x에 2를 넣는게 아니라 변수x를 새로 할당해서 2를 넣는다 - 주소값이 달라진다\n\n\n\n시퀀스 §\n\nOCaml에서는 세미콜론(;)이 문장종료기호가 아닌 다음 문장 실행 이라는 뜻을 가진다\n따라서 더 이상 실행할 문장이 없는 마지막 문장에는 세미콜론을 붙이지 않는다\nbegin-end 구문을 이용해 명시적으로 실행방향을 정해줄 수도 있고\nin도 무적권 다음 문장이 실행되게 되므로 let-in구문을 통해 다음문장이 실행되게 해줄 수도 있다\n\nWildcard §\n\n언더바(_)로 사용할 수 있는 와일드카드는 아무 값이라는 의미를 가진다\n오캠엘에서 함수나 연산에서 반환되거나 결과로 나온 값을 let-in을 통해 어딘가에 저장하지 않으면 오류가 난다(unit의 경우에는 오류가 안난다)\n만약 함수의 반환값을 받아서 버리기 위해서는 와일드카드 _ 를 사용하면 된다\n\n함수선언 §\nlet 함수이름 = fun 매개변수 -&gt; 리턴연산 in\nlet 함수이름 매개변수 = 리턴연산 in\n\n두번째처럼 표현하는 것을 curried function이라고 한다\n\n함수의 타입 표시 §\n\n반환값 → 매개변수1 → 매개변수2 → ... → 마지막 매개변수\n예를들어 int두개를 받아 float하나를 반환하는 함수의 경우 이 함수의 타입은 float → int → int 이 된다\n\n함수의 매개변수보다 부족하게 인자를 줬을 때 §\n\n인자가 다 매개변수에 채워지고 남은 매개변수는 그대로 남아 결과가 어떤 값이 아닌 함수가 된다\n함수에 일부 인자만 전달하는 것으로 partial application이라고도 한다\n\n튜플은 파이썬과 똑같다 §\n\n다만 타입 기호는 * 로 한다\n예를들어 (1, 2.34)의 경우 int * float 이 타입인 것이다\n\nHigher order function §\n\n함수를 인자로 받는 함수를 의미함\n\nlet f x = f x in\n\n이렇게 어떤 함수를 동적으로 실행하는것을 지원한다\nppt예제 보면서 느낌을 기억할 것\n\nOCaml의 경우 반복문을 지원하지 않는다 §\n\n대신 무조건 함수를 재귀적으로 돌려 반복을 수행하게 만든다\n단, 어떤함수를 재귀적으로 호출하려면 함수이름 앞에 rec이라는 키워드를 붙여줘야 한다\n\n조건문은 if-then-else형태로 실행된다 §\nif 조건 then 참결과 else 거짓결과\n\n여기서 주의할 점은 참결과와 거짓결과의 자료형이 무조건 같아야 한다\n\n함수 몸체 및 main은 하나의 expression으로 구성되어야 한다 §\n\nlet-in문의 경우 사이에 들어가는 놈이나 in 다음줄을 let-in문이 다 감싸서 하나의 expression으로 취급된다\nif-then-else도 인덴트 안의 내용은 하나의 expression으로 취급된다\nbegin-end나 ;을 통한 시퀀스도 하나의 expression으로 취급된다\n이 점은 고려하여 모든놈이 하나의 expression으로 되어 있어야 하고 그렇지 않으면 오류가 난다\n"},"pl.spring.2021.cse.cnu.ac.kr/10.-1등-시민-함수":{"title":"10. 1등 시민 함수","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\nFirst-class Function §\n\n함수를 값으로 취급해 변수에 저장하거나 인자로 저장, 반환값 등으로 사용할 수 있는 것\n\nFVAE §\n\n일단 이름이 없는 함수(람다마냥)만 정의\n그리고 Syntactic sugar를 이용해 이름이 있는 함수도 정의\n\nConcrete Syntax §\n\n\n(fun var → expr) 가 무명함수를 선언하는 부분\nexpr’ expr’ 가 함수를 호출하는 부분\n\nAbstract Syntax §\n\n\n람다x.e 가 무명함수를 선언한다는 소리이고\n\n저걸 lambda abstraction 라고 하고 더하기 빼기처럼 하나의 연산기호이다\n파이썬에서 [lambda 매개변수 : 몸체] 이렇게 무명함수를 정의하는 것이 여기에서 착안한 아이디어이다\n\n\n\n\n\n이런 AST로 나타내짐\n당연히 x는 binding occurence이고 그의 scope는 e이다\ne e 로 함수를 호출하는 것\n\n\n\n이런 AST를 가짐\n\n값의 domain §\n\n이전까지는 정수만 ‘값’이 될 수 있지만\n이제는 함수도 ‘값’이기 때문에 값의 범위를 확장시켜줘야 한다\n그래서 이젠 값(Value) = 정수(Z) +D Closure로 정의됨\n여기서 Closure라는 것은 (매개변수, 몸체, 함수 정의시점의 Store) 튜플 을 의미하는데 함수 정의시점의 Store도 갖고있는 이유는 Lexical scope에서도 전역변수의 scope는 함수 내부까지 들어오기 때문 이다\n\n하지만 Lexical scope이기 때문에 전역변수가 아닌 외부의 지역변수는 내부에 들어오지 못한다\n\n\n그리고 +D연산자는 도메인 간의 합 을 나타내며 ocaml에서 disjoint union과 동일하고 이 수업에서 정의한(통용되지 않는)연산자다 (합집합)\n그리고 Value의 원소는 v, 정수(Z)의 원소는 n, Closure의 원소는 &lt;ㅅx.e, 시그마&gt; 로 표현한댄다\n또한 이제 스토어에 저장되는 값이 정수가 아니라 값이기 때문에 기존의 정수만 저장하는 체제에서 수정해야 한다\n\n\n\n요래 바뀌드라\n근데 저 and라는 놈은 OCaml에서 상호참조 를 지원해주기 위해 존재한다\n\n저거를 나눠서 type 두개로 쪼갤 수 있지만 그렇게 하면 아래에서는 위의 타입을 사용할 수 있지만 위에서는 아래놈이 아직 선언되지 않은놈이기 때문에 참조할 수가 없음\n따라서 이때에는 저 and를 사용해준다\n\n\nvalue는 스토어 t를 사용하고 t는 value를 사용하기 때문에 상호참조인데 그렇기 때문에 저 and를 사용해야 되는 거고 또한 Store.ml에 저장해야 되는 것\n\n만약에 다른 파일에 선언하게 되면 순환참조(Circular Dependency), 즉, 서로가 서로를 참조해 그 loop를 빠져나오지 못하고 서로 계속 참조해 컴파일이 불가능한 경우가 발생한다\n\n\n\nSemantic Relation §\n\n\n아래화살표 P는 프로그램p가 값v로 계산된다 는 의미\nv는 이제 정수뿐만이 아니라 함수도 포함하는걸로 확장된다\n\n\n\n아래화살표E는 표현식e가 값v로 계산된다 는 의미\n마찬가지로 정수뿐만아니라 함수까지 포함하는 v로 확장됨\n저 아래화살표 사용할때 양쪽의 자료형 주의해야된다\n\n그냥 계산된다고 아래화살표가 아니라 그 자료형으로 계산될때를 말하는거임\n기말에서는 다 틀리게 할 거랜다\n\n\n\nBigstep Operational Semantics §\n\n\n이제 프로그램의 결과는 정수 n이 아니라 값v로 확장됨\n\n\n\ne를 계산할 결과가 정수 n이어야 한다 : 함수 &lt;ㅅx.e, 시그마&gt; 라면 함수끼리의 덧셈은 존재하지 않기 때문\n\n결과가 함수라면 Runtime error를 발생시킨다\n\n따라서 Add할때 화살표 옆에다가 v쓰면 안된다!!\n\n\n\n\n뭔가 문제가 생겼을 때 인터프리터 입장에서는 exception인거고 프로그램 입장에서는 runtime error이다\n\n둘이 다른것!!\n\n\n\n\n\nLetIn의 경우에도 정수 n에서 값v을 지원하는 것으로 확장된다\nadd나 sub과는 다르게 계산의 결과가 함수여도 된다는 것 에 주의할 것\n\n\n\n무명함수의 선언은 위와 같다\n\n현재의 시그마에서 저런 함수 정의문이 나오면 (매개변수, 몸체, 시그마)의 튜플로 계산 이 되는 것\n\n\n함수의 적용(apply)는 그 아래와 같다\n\n현재의 시그마에서 e1이 (x, e3, 시그마’)으로 계산이 되고 e2가 v1으로 계산되며 x가 v1으로 계산되는 새로운 시그마(매개변수의 값이 업데이트된 새로운 시그마)에서 e3을 계산한 결과가 v2이면 e1 e2는 v2로 계산이 되는 것\n\n\n여기서 중요한 것은 시그마가 시그마’으로 바뀌는 건데 이는 함수 선언 시점에의 시그마 이기 때문에 그렇다\n\n\n\n여기서 보면 첫번째 foo에서는 빈 메모리가 튜플의 세번째 원소로 들어가는 반면에 두번째 bar에서는 foo가 추가된 메모리가 튜플의 세번째 뭔소로 들어가는 것을 알 수 있다\nproof tree 시험에 반드시 낸댄다 → semantics 옆에 두고 같이 보면서 pdf예시들 다 그려봐야 된다\n\n\n\n이거 화살표 따라 가면서 이해하고 proof tree까지 다 그려보고 모르겟으면 강의 50분경 확인해라\n\n\n\n여기서 &lt;ㅅy.y+2, []&gt; 가 아니라 &lt;ㅅy.y+x, [x → 2]&gt; 인 이유는 저 ㅅy.y+x 가 선언될 당시에는 매개변수x에 2가 매핑되기 때문에 x → 2가 선언될 당시에의 시그마 이므로 저래되는거다\n이 예시 시험에 나올거같다\n\nLexical scope vs Dynamic scope §\n\n\n이 예시 proof tree그려서 꼼꼼하게 분석해라\n그냥 시그마냐 시그마’냐 구별 잘해야 된다\n\nSyntactic sugar를 이용한 Named function의 지원 §\n\nSyntactic sugar이기 때문에 AST는 수정할 필요 없이 Concrete syntax와 parser만 수정하면 된다\n\nSyntactic sugar를 이용한 Multiple parameter의 지원 §\n\n여러개의 인자를 받는 함수를 syntactic sugar로 표현하는 것은 curried form 을 이용하면 된다\n인자 하나를 넣고 함수 반환하고 또 그거에 인자 하나 더 넣고 또 함수 반환하고 이런식으로 연쇄적으로 계산해서 모든 인자에 대해 계산하는 것\n\nSyntactic sugar를 이용한 LetIn의 지원 §\n\n\n이런식으로 할 수도 있다!\nin뒤에 나오는 놈이 제일 나중에 연산된다는 것과 함수의 몸체는 제일 나중에 연산된다는 것에 착안해 in뒤에있는놈을 함수의 몸체로 두고, LetIn의 변수명을 매개변수명으로 하고 이 함수를 e1에 대해 apply되게 해 자연스레 e1의 결과가 매개변수에 들어가고 그것으로 e2를 계산하는 동일한 흐름이 완성된다\n\nFunction Application §\n\n함수형 프로그래밍에서는 function call 대신 function application라고 부른다\n뭔말인고 하니 함수형이 아닌 언어에서는 ‘함수 f가 인자 x로 호출된다’라고 표현되지만 함수형 언어에서는 함수 f가 인자 x에 apply된다이렇게 표현한다\n함수형 언어가 아닌 언어에서는 그냥 함수에 인자를 넣어서 호출하는거지만 함수형 언어에서는 함수 또한 값이기 때문에 호출이라는 말을 안쓰고 인자에 apply된다 라는 말을 쓰는 것\n\n어떤 값에 적용된다? 정도로 생각하면 될듯\n\n\n\n함수형 언어는 정의가 간결하다 §\n\n함수를 값으로 취급하는 것은 매우 강력한 기능이며\n함수와 그의 적용으로 대부분의 동적을 수행할 수 있다\n\n따라서 AST, semantics, interpreter를 모두 간결하게 짤 수 있음\n\n\n하지만 이 모든것들을 그냥 냅둔다면 프로그래머는 이 모든 기능을 함수와 그의 적용으로만 구현해서 사용해야 되기 때문에 Syntactic sugar를 이용해 표현력을 확장시킨다\n즉, 프로그래머가 Syntactic sugar을 이용한 표현을 쓰면 그것을 함수와 그의 적용으로 인터프리터가 바꿔서(Desugaring) 인터프리트 하는 기법을 사용\n"},"pl.spring.2021.cse.cnu.ac.kr/11.-조건분기문":{"title":"11. 조건분기문","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\nExpression vs Statement §\n\n얘네 둘의 구분은 언어마다 다르다\n다만 보편적으로는 결과값이 나오는 코드 조각을 Expression이라고 하고 값으로 계산되지 않고 프로그램의 상태가 전이되는 코드 조각을 Statement라고 한다\n\n당연히 Expression의 경우에는 상태가 전이되지 않것제?\n대부분의 함수형 언어는 Expression만 지원하고\nc언어같은 imperative언어는 Statement도 지원한다\n그리고 자바스크립트같은 애들은 함수형도 지원하고 imperative도 지원하기 때문에 둘 다 지원함\n\n\n여기서 상태가 전이된다는 것은 변수에 값을 추가하는 것 처럼 추상메모리가 변화하는 것 을 의미한다\n분기문의 경우 값이 계산되지 않기 때문에 statement이다. 다만, 삼항연산자의 경우에는 값이 계산되기 때문에 분기문의 expression 버전이다\n\nCFVAE §\n\nFVAE에 분기문을 추가한 버젼\n수업에서는 오른쪽화살표S 가 statement를 나타내며 (구 store, expression, 업데이트된 store) 의 튜플 과 같다\n그리고 얘는 함수형 언어이기 때문에 분기문도 expression으로 지원 한다. 즉, 분기문이 참일때의 값과 거짓일때의 값으로 계산된다는 것 이다\n\nConcrete Syntax §\n\n\n분기문 if then else와\n조건식 &lt;\n그리고 boolean값인 “true”, “false”를 추가함\n\nAbstract Syntax §\n\n\nboolean값을 나타내는 b\n분기문을 의미하는 e ? e : e (당연히 AST이기 때문에 삼항연산자를 나타내는건 아니다)\n그리고 조건을 나타내는 &lt; 가 추가된다\n\nValue §\n\n\n조건식을 계산한 결과인 boolean값이 추가되었으므로 Value의 범위를 확장해준다\n\nBigstep Operational Sementics §\n\n\n뭐 별거 없다\n정수간의 연산이랑 별다를거없음\n당연히 &lt;의 경우 e의 계산값이 정수가 아니라면 런타임 에러가 난다\n\n\n\ne1의 계산결과가 참이냐 거짓이냐에 따라서 계산결과가 e2의 결과(참일 경우), e3의 결과(거짓일 경우)로 나뉘기 때문에 두개의 rule로 정의를 한 것\n마찬가지로 e1의 결과가 boolean이 아닌 경우에는 런타임 에러가 나는 것\n\nSyntactic sugar §\n\nboolean을 syntactic sugar를 이용해 0, 1로 표현하거나 0이아닌 정수, 0으로 표현하는 것도 가능 하다\n\n\n\n위의 분기문이 C언어 스타일로 바꾼 것\n\n0이 아닐때는 참으로 계산, 0일때는 거짓으로 계산된다\n\n\n또한 boolean, 분기문을 함수로 표현하는것도 가능하다\n\n참인 경우에는 인자 x, y를 받아 x를 돌려주는 함수로 표현, 거짓인 경우에는 인자로 x, y를 받아 y를 반환하는 함수로 표현\n따라서 e1 ? e2 : e3 의 분기문을 e1 e2 e3의 function application으로 표현할 수도 있다\n\n\n참과 거짓이 함수로 표현되므로 아래처럼 표현할 수 있다\n\n\n\n&lt;의 결과가 함수로 나오므로\ne1 ? e2 : e3 의 경우에는 e1의 결과가 함수가 되어 인자인 e2, e3의 결과값에 e1의 결과인 함수를 application하는 것으로 처리하는 것이 가능하다\n\nBoolean in Syntactic Sugar §\n\nboolean값을 값의 도메인을 확장하지 않고 표현하기\nC언어 스타일 : 0과 1로 표현\n함수형 언어의 스타일 : 참인 경우에는 인자 x, y를 받아 x를 돌려주는 함수로 표현, 거짓인 경우에는 인자로 x, y를 받아 y를 반환하는 함수로 표현\n"},"pl.spring.2021.cse.cnu.ac.kr/12.-재귀함수":{"title":"12. 재귀함수","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\n직간접 호출 §\n\n직접호출(Direct Recursion) : 함수 A가 자기자신인 A를 다시 호출하는것\n간접호출(Indirect Recursion) : 함수 A가 일단 다른 함수 B를 먼저 호출하고 그 함수 B가 A를 호출하는것\n\nRCFVAE §\n\nRCFVAE는 함수 재귀호출을 지원하는 언어이다\n원래 CFVAE에서는 &lt;ㅅx.e, 시그마&gt; 에서 함수 몸체를 계산하는데 필요한 추상메모리가 시그마인데 함수선언시에 이 시그마에 자기자신 함수가 들어있지 않기 때문에 자기자신을 재귀호출할 경우 자기자신은 Free Identifier로 분류되어 Runtime error가 나게 된다\n\nConcrete Syntax §\n\n\n일반적인 함수 호출을 지원하는 let fun in구문과 별도로 let rec fun in 구문을 concrete syntax에 추가했다\n\nAbstract Syntax §\n\n\n여기에도 마찬가지로 let rec x = e in e 추상문법과 그것을 나타내는 AST를 추가하였다\n\nBigstep Operational Semantics §\n\n\n위에꺼가 기존의 일반함수 선언법, 아래꺼가 재귀함수 선언법이다\n일단 재귀함수 호출법에서는 e1을 계산한 결과가 Closure이어야만 하고 그렇지 않은 경우에는 Runtime error를 출력해야 한다\n일단 저 시그마 프라임은 전에 함수를 정의할때처럼 스코프가 함수 내부인, 함수의 몸체를 계산할때 쓰이는 추상메모리 이고\n시그마 투프라임은 재귀함수 호출 구조를 그대로 생각하면 된다\n\n재귀함수를 정의할 때에 안에 자기자신이 들어가듯이 시그마 투프라임을 정의할 때도 자기자신을 이용하여 재귀적으로 정의한 것\n\n\n시그마 투프라임 없이 시그마 프라임 하나로만 정의하면 재귀가 한번밖에 돌지 못하는 구조가 된다?\n\n시그마 투프라임이 없는 경우를 생각해보고 왜 안되는지를 생각할것\n\n\n\n\n\n이 예시를 보면\n\n일단 저기 빨간글씨 (-1 &lt; x)는 오타인거같고\n시그마 = [sum = &lt;ㅅx.(x&lt;1) 0 (x+(sum(x-1))), 시그마&gt;]의 말뜻은 함수 정의시 시그마에 ”sum = Closure” 를 추가한 시그마를 함수 몸체를 계산할때도 사용하겠다 의 의미가 되는 것이다\n\n\n\nOCaml Code §\n1. 시그마 투프라임을 그대로 정의해보기 §\n\n\n위처럼 정의하게 되면 우측(RHS - Right Hand Side)의 s’’은 아직 Free Identifier이기 때문에 에러가 난다\n\n2. Rec 키워드 이용해보기 §\n\nOCaml에서 함수를 정의할 때 “let 함수이름 인자 = 몸체 in”은 “let 함수이름 = fun 인자 몸체 in”의 Syntactic sugar 이기 때문에 “let rec 무언가 = 무언가 in”도 지원한다는 것을 알 수 있다\n\n\n\n근데 위처럼 정의하면 에러가 난다\n\nrec 키워드를 사용할때는 조건이 붙기 때문\n\n일단 RHS가 함수의 정의이고 그 함수의 몸체에서 재귀호출을 하거나\nRHS가 Disjoint Union의 Constructor이고 그의 인자로 재귀호출되며\n\n이게 무슨말이냐면 위의 예시처럼 ClosureV라는 Disjoint Union(자료형)을 생성하기 위해 “ClosureV (인자)” 형태의 Disjoint Union Constructor (자료형 생성자)를 호출해서 인자를 넣어 ClosureV 자료형의 객체를 생성한것\n\n\nRHS 가 Function Application 이어서는 안된다\n\n\n\n\n위의 예시에서는 세번째 조항때문에 문제가 생기는 것 이다\n\n3. Function Application을 제거해보기 §\n\n저 insert함수가 그냥 :: 으로 리스트에 추가하는 연산이 전부이기 때문에\n\n\n\n이렇게 표현하면 된다\n하지만 여기서는 이제 에러는 안나지만 Stack Overflow가 일어나게 된다\n왜냐면 Function Application이\n\n\n\n이렇게 정의되었기 때문\n전에 boolean을 생각해보면 boolean을 인자 두개를 받아서 둘 중 하나를 반환하는 함수로 구현을 했는데 이때 반환되지 않는 인자의 값도 계산한다면 낭비일 것이다\n\n\n\n이 예시를 보면 &lt;ㅅy.x, [x → 0]&gt; (sum (-1)) 부분에서 y에 (sum (-1))이 담기긴 하지만 반환값은 x이므로 사용되지 않는다\n\n근데 이제 (sum (-1))을 계산하느라 또 재귀호출이 되고 어차피 -1 &lt; 1이기 때문에 또 0을 반환해야되는데 반환하지도 않을 인자 (sum (-2))를 계산하고\n이런식으로 가다 보니 스택이 터져 오버플로우가 나는 것\n이것을 해결하기 위해 Expression Freezing 이 필요하다\n\n\n\nExpression Freezing (Lazy Evaluation) §\n\nExpression Freezing(Lazy Evaluation) : 어떤 expression을 등장과 동시에 계산하는 것이 아닌 얼려두었다가 값이 필요해지면 그제서야 계산을 하는 방법\n위의 경우처럼 인자의 값 계산을 늦춰 계산할 필요가 없으면 계산하지 않는 것을 지원하기 위해존재한다\n\n즉, 함수를 먼저 호출하고 인자의 값이 필요해지면 그때 인자의 값을 계산하는 방법\n따라서 call-by-need 라고도 부른다\n\n\n반대개념으로는 Eager Evaluation 가 있으며 얘는 반대로 인자를 먼저 계산하고 함수를 호출하는 방식\n대부분의 함수형 언어들은 Eager Evaluation을 주로 사용하지만 이런 Lazy Evaluation또한 지원한다\n\n예시1 §\n\n\n왼쪽이 Eager의 경우고 오른쪽이 Lazy의 경우이다\n보면 “ # 뭐시기 # “가 해당 부분을 얼린다는 의미로\n오른쪽을 보면 # 안의 expression을 계산하기 위해서는 expression 등장 당시의 store도 필요하기 때문에 (나중에 녹여서 계산할랫드니 store가 달라져서 값이 달라지면 안되니까) expression과 store를 같이 얼려놓는 것\n그렇게 인자 두개를 다 얼려놨다가 최종 계산시에 녹여서 계산하게된다\n\n예시2 §\n\n\n아까 무한루프를 돌았던 예시를 다시 보면 0과 sum()을 둘 다 얼려놨다가 마지막에 0을 반환해야되므로 0을 녹여서 반환하는 것을 알 수 있다\n\nLazy Expression in OCaml §\n\n\nlazy (표현식) : 으로 표현식을 얼리고\nLazy.force(변수) : 로 얼려진 변수를 녹일 수 있다\n\nExpression Freezing을 지원하는 RCFVAE §\n\n일단 App의 Semantics를 바꿀 필요가 있고\n얼린 expression도 값이 될 수 있도록 Value domain도 확장시켜줘야 한다\n또한 녹이는 절차도 필요하다 - 값을 꺼내오는 것은 “Id”에서 진행하기 때문에 “Id”의 Semantics도 녹이는 것을 지원하기 위해 변경되어야 한다\n\nValue Domain §\n\n\n얼릴 값과 녹일때 사용하기 위한 얼릴 당시에의 store를 묶은 튜플로 FreezedExpr을 정의하여 추가해준다\n\nFunction Application §\n\n\n값을 바로바로 계산하는 Eager가 아니고 Lazy를 지원해주기 위해 e1을 먼저 Closure로 계산하고 e2를 계산하지 않고 얼려서 x와 매핑하여 시그마에 넣어주는 연산으로 바꿔준다\n\nId §\n\n\nFreezedExpr가 아니라면 그냥 바로 계산해주고(위에꺼)\nFreezedExpr이라면 거기에서 expression과 store를 꺼내서 얘네들을 계산해서 반환한다\n\n좀 더 구조적으로 정의 §\n\n\nValue를 FreezedExpr와 그것이 아닌 NormalValue로 먼저 나누고\nFreezedExpr의 원소인 I는 (e, s)의 형태를 갖고\nNormalValue의 원소인 m은 (정수 or 함수) 인 것으로 정의할 수도 있음\n그것을 가지고 Id를 정의하면 위 그림의 아랫쪽처럼 정의할 수 있다\n저 Id1에서 m대신 v를 쓰면 안된다!! 이렇게 Inference Rule의 Domain을 잘 지켜서 정답써야된다\n\nRecursion as Syntactic Sugar §\n\n일단 Fixpoint Combinator를 일아야 한다\nFixpoint Combinator의 수식은 다음과 같다\n\n\n\n그리고 이놈의 특징은 다음과 같다\n\n\n\n즉, 임의의 함수 f에 대해 fix f는 f의 fixed point이다\n여기서 fixed point라는 것은 x = f(x) 를 만족하는 x를 의미하고\n따라서 Fixpoint Combinator는 임의의 함수 f를 인자로 받아x = f(x) 를 만족하는 함수x를 반환하는 함수이다\n뭔말인지 모르것제? 나도 모르겠다\n일단 저 수식이랑 특징만 기억하고 이 아래 예시를 봐라\n\n\n\n일단 저 fix로 어떻게 재귀함수를 만들어내는지 알려드림\n함수 sum을 아래 F처럼 변형한 뒤 fix에 넣어주면 재귀함수가 된다\n위의 과정을 보면 fix의 특징을 이용해 재귀적으로 함수가 돌아가는 것을 보이는데 이 특징이 저 수식을 통해 유도되는 것이다\n그럼 F는 어떻게 만들어내냐\n\n\n\n이렇게 재귀호출되는 함수를 인자(f)로 받게 해서 함수를 구성하면 된다\n\n\n\n더 간단하게는 ㅅsum. 만 붙이면 된다\n따라서 재귀함수를 Syntactic Sugar를 이용해 표현하고 Desugaring을 하는 과정은 다음과 같다\n\n\n\n걍 저렇게 fix F 만 해주면 재귀적으로 함수가 돌아감\n\n\n\n실제 구현에서는 위와 같은 Fixpoint Combinator를 사용함\n\nx x가 미리 계산되면 아까처럼 stack overflow가 나기 때문에 x x를 나중에 계산하기 위해 freezing 얼려놓는것\n함수란 것이 결국에는 인자가 들어와야 계산되므로 계산시점을 내가 정할 수 있어 expression freezing이랑 유사한 기능을 한다\n\n\n정 이해안되면 여기는 fix의 수식(+구현시 사용되는 수식)과 특징, F를 구성하는법, fix F로 돌리면 재귀함수가 된다는 것 이거 그냥 외워라\n"},"pl.spring.2021.cse.cnu.ac.kr/13.-명령형-언어-(1)":{"title":"13. 명령형 언어 (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\n명령형 언어 §\n\n명령형 언어(Imperative Language) 는 메모리의 상태를 바꾸는 명령들을 통해 프로그램을 구성하는 언어\n즉, 명령을 하나씩 실행할때마다 메모리의 상태가 바뀌며 프로그램이 모두 실행되면 최종 상태가 됨\nC / C++, Java등이 해당됨\n일반적으로 Statement를 지원하는 언어는 모두 명령형언어이다\n함수형 언어는 보통 명령형 언어는 아니지만 반대개념은 아니다\n\n\n\n이걸 보면 한문장이 실행될때마다 메모리의 상태가 바뀌는 것을 알 수 있다\nif문도 expression인 조건식으로 특정위치로 분기한 다음 statement가 실행되는 것을 알 수 있다\n\nMiniC §\n\n이번 수업에서 정의하는 C언어의 축소판\nUntyped, Interpreted Language 로 정의해본다\n\n따라서 타입에러에 대한 런타임 에러가 날 수 있음\n\n\n\nConcrete Syntax §\n\n\n뭐 별거 없다\n\nAbstract Syntax §\n\n\n알파벳 위에 바 가 있는 것은 그냥 그게 여러개 있다(list이다)라고 생각하면 된다\ns는 변수할당(x = e)과 분기문 (e ? s : s-opt)으로 구성되고\ns-opt는 false branch를 지원하기 위한 것으로 s가 있을수도 있고 없을수도 있다는 것이다\n\n\n\n이렇게 오른쪽으로 코드로 바꿔보는거 할 줄 알아야 한다 - 시험각\noption은 ocaml에서 지원하는 타입으로 앞에꺼가 있을수도 있고 없을수도 있다는 소리이다\n\nValue Domain §\n\n\n별거 없쥬?\n다만 여기서도 코드로 바꾸는 거 알아놔야 된다 - 여기서는 and를 사용하지 않지만 and를 어떻게 사용하는지도 알아놓자\n\nSemantics §\n\nImperative Language의 경우 statement가 실행되면 메모리의 상태 전이가 일어나므로 statement는 메모리의 상태를 어떻게 전이시키는지를 명시하는 것으로써 Semantics를 작성할 수 있다\n\n\n\nProgram Semantics : program을 전부 실행한 후의 메모리 상태 (“ → P” 로 표현)\n\n\n\nStatement Semantics : statement 실행 시 변화된 추상 메모리 (“ → S “ 로 표현)\n\n\n\nExpression Semantics : 현재의 메모리 상태에서 expression이 계산되는 값 (“ 아래화살표 E “로 표현)\n\nBigstep Operational Semantics §\n\n나머지는 다 배운거고\n\n\n\nAND와 OR는 저렇게 &amp;&amp;B, ||B 의 논리값 연산자를 통해 표현된다는 것\n저기 오타는 적당히 알아듣도록\n\n\n\nequal to의 경우에는 정수간의 equal to 연산과 boolean간의 equal to 두개로 나눠서 표현한다\n따라서 정수와 논리값 간의 equal to 의 경우에는 런타임 에러가 나도록 처리한다\n\n\n\nStatement의 경우에는 ” → S “ 를 이용해 메모리의 변화로 표현한다\n위에 등장하는 If는 e가 True로 계산될때의 Branch 이다\n따라서 보면 True Branch의 statement들이 하나씩 실행될때마다 추상메모리가 변화하고 마지막의 최종 메모리가 이 If문의 결과 메모리가 되는 것\n\n\n\nFalse의 경우에는 False Branch가 존재할 수도 있고 존재하지 않을 수도 있기 때문에 위처럼 두개로 나눠서 표현된다\n첫번째는 False Branch가 없을때의 얘기로 이때에는 메모리 상태가 전이되지 않는다\n그리고 두번째는 False Branch가 존재할때의 얘기로 이때에는 True Branch일때처럼 하나씩 계산해서 마지막까지 계산했을 때의 메모리 상태가 최종상태가 되는 것\n\n\n\n그리고 Program은 Statement의 list이므로 빈 메모리에서 시작해서 최종 메모리로 끝나는 연산으로 표현된다\n\nOptional Value in OCaml §\n\n\n보면 ’a option 이라는 타입은 아무것도 없음을 나타내는 None과 하나가 존재한다는 Some으로 구성되어 있으며\n뭐 pattern matching으로 None와 Some을 매치시켜 사용하면 될듯\n값이 없음을 뜻하는 NULL과 유사하나 예기치 않은 오류가 날 수 있기 때문에 값이 있을수도 있고 아닐수도 있는 경우에는 이렇게 옵션으로 처리하는 것이 좋다\n"},"pl.spring.2021.cse.cnu.ac.kr/14.-명령형언어-(2)":{"title":"14. 명령형언어 (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\n반복문의 구조 §\n\n\n별거없다\n\nMiniC에서의 반복문 §\n\n일단 _while문만 지원하면 syntactic sugar를 이용해 do-while이나 for문을 지원할 수 있다\n\n\nConcrete Syntax §\n\n\nC언어와 동일한 concrete syntax를 따른다\n\nAbstract syntax §\n\n\n하나의 expression과 statement list로 구성된다\n\nSemantics §\n\n\nconditional expression이 참일때와 거짓일때 두가지의 경우로 나눠서 정의한다\n참일때 반복에 대한 의미가 안들어가있어서 좀 헷갈릴 수 있는데 마지막 while(e) s 부분이 재귀적으로 자기자신을 다시 호출한다는 의미로 받아들이면 된다\n\n먼저 e가 참인지 보고, slist를 계산하여 스토어를 업데이트한 뒤, 그 스토어에서 다시 while루프를 호출해 다시 e를 확인하고 s를 실행하고 하는식으로 굴러간다 이거임\n\n\n\nPointer §\n\n어떤 언어가 pointer를 지원한다는 뜻은 그 언어가 Reference와 Dereference를 지원한다는 소리이다\nReference : 어떤 변수의 메모리 주소를 열람하는 것 - C언어에서 &amp;var를 의미함\nDereference : 메모리 주소를 이용해 그 주소에 저장된 값을 열람하는 것 - C언어에서 *addr 를 의미함\n\nMiniC에서의 Pointer §\nConcrete Syntax §\n\n\n원래 우리가 정의한 MiniC에서는 변수의 선언이 없었다 - 걍 변수명을 쓰면 새로 선언되거나 호출되거나 했었는데\n이제는 var이라는 키워드를이용해 변수 선언을 하고\nid = expr을 하면 선언된 그 변수에 값이 들어가며\nexpr = expr을 통해 주소에 저장된 값을 바꿔주는 것을 하게 됨\n위의 세개는 전부 스토어가 바뀌므로 statement라고 할 수 있고\n\n\n\n&amp;와 * 를 이용해 reference하거나 dereference하는 expression을 만들어준다 - 얘네는 스토어가 바뀌지 않으므로 expression이 되는 것\n\nAbstract Syntax §\n\n\n위에서 추가해준대로 변수 선언과 주소에 저장된 값을 바꿔주는 statement\n그리고 reference와 dereference를 해주는 expression 들이 추가가 된다\n또한 변수에 값을 할당하는 것은 syntactic sugar로 처리할 수 있다 x = e; -&gt; *&amp;x = e;\n\n\n\nreference와 dereference, vardeclstmt는 변수 하나만을 필요로 하기 때문에 string하나로 구성이 되고\nstorestmt는 expr의 결과를 주소로 하는 위치에 다음 expr의 결과를 할당할 것이므로 expr 두개의 튜플로 구성된다고 할 수 있다\n\nAbstract Memory Model in MiniC §\n\n\n원래의 MiniC에서는 스토어에 [변수이름 → 값] 으로 저장이 되었지만\n이제는 포인터를 지원하기 위해 중간에 주소의 개념을 추가하게 된다\n즉, 스토어를 Env(환경)과 Mem(메모리)로 니누어\nEnv(환경)에는 [변수이름 → 주소] 로 매핑되게 하고\nMem(메모리)에는 [주소 → 값] 으로 매핑되게 하는 것\n즉, Env는 ref의 과정을 지원하기 위해 존재하는 것 이고\nMem은 deref의 과정을 지원하기 위해 존재하는 것 이다\n다시말해 원래의 스토어에서처럼 변수명으로 값을 꺼내는 한종류의 기능이 아닌 변수명으로 주소를 꺼내는 것과, 주소로 값을 꺼내는 두종류의 기능을 지원하는것으로 바꿔준다는 소리\n시그마의 정의가 바뀌었으므로 헷갈리지 않게 조심할것\n그리고 이제는 주소 또한 값이 돼야 하므로 Value domain에 addr도 추가 하게 된다\n\n\n\n이 예제 보면 딱 감이 온다 어케하려는건지\n\nValue, Store Domain §\n\nSemantic Relation §\n\n\n원래는 프로그램은 스토어 하나만 반환하는 거였는데 env와 mem 두개를 반환하는 것으로 변경되고\nstatement도 스토어만 바뀌는 거였는데 env와 mem이 둘 다 바뀌는 것으로 변경된다\n\n\n\n마찬가지로 스토어를 받아 expression을 계산하는게 아니고 env와 mem을 받아 expression을 계산해 value를 반환하게 된다\n\nBigstep Operational Semantics §\n\n얘도 그냥 대부분은 스토어를 env와 mem으로 바꾼게 전부이기 때문에 쉬운건 버리고\n\n\n\n변수에서 값을 꺼내오는 경우는 변수로 주소를 찾고 그 주소로 값을 찾아오기 때문에 위 그림의 첫번째처럼 된다\n\n다만 여기서 시그마에 대해서만 도메인 체크를 하는 것은 그 변수가 선언되었냐\n\n즉, bind되었느냐를 확인하는 것이고 만약 그렇지 않다면 runtime error가 나게 된다\n\n\n또한 M에 없을수도 있는데 이때 또한 runtime error가 나게 된다\n\n\n그리고 ref의 경우에는 주소값을 반환해야하기 때문에 그냥 env에서 찾아주면 된다\n\n이때에도 시그마 도메인에 없다면 선언을 하지 않은 것 이므로 runtime error가 나게 된다\n\n\n\n\n\nderef의 경우에는 * 뒤에 변수만 붙을 수 있다 (string으로 선언되어있으므로)\n따라서 변수가 선언되어있고 이 변수에 저장된 값이 어떤 주소라면 mem을 통해 그 주소의 값을 가져오게 되는 것\n\n\n\nstatement의 semantics는 위와 같다\n변수 선언의 경우에는 도메인에 일단 그 변수가 없어야 되고 해당 변수에 대해 할당하려는 주소값이 시그마 안에 저장되어있으면 안될때 그 변수와 주소를 매핑해주게 된다\n주소가 시그마 안에 있으면 안된다는 것을 Range() 라고 표현했는데 이미 다른 변수에게 할당되어있는 주소값에 해당 변수를 매핑하면 안되기 때문\n값 변경의 경우에는 e1을 계산한 결과가 주소여야 되고 e2가 어떤 value일때 그 주소에 매핑된 값을 새로운 값으로 바꾸는 과정을 수행한다\n\n주소와 값 간의 매핑관계를 바꾸므로 mem을 건드리게 되는 것\n\n\n\nNumeric Compilation §\n\nMiniC의 경우에는 컴파일을 하지 않지만 컴파일 언어가 어떻게 컴파일되는지는 한번 살펴볼 필요가 있다\n어떤 프로그램이 컴파일되고 나면 그 프로그램에서 변수라는것은 다 사라지고 물리주소값만 남게 된다\n\n\n\n위와 같은 프로그램이 어떻게 컴파일되는지를 알아보면\n\n\n\n일단 프로그램에 등장하는 변수들을 전부 “변수의 주소값에 대한 deref”로 바꿔준다\n\n이게 뭔소리냐면 변수 x 는 *&amp;x 와 같기 때문에 모든 변수를 저렇게 기계적으로 변환시켜주는 것\n\n\n\n\n\n그 다음으로는 변수의 주소값을 “&amp;변수”로 표현하지 말고 전부 “주소”로 바꿔준다\n\n즉, 위의 예시에서 x의 주소값인 &amp;x는 addr0이므로 a0라고 표현함\n\n\n\n\n\n마지막으로 어떤 주소를 deref후 ref를 하는것은 그 주소의 값과 같기 때문에 이러한 표현들을 다 걸러준다\n\n즉, *a0 를 하면 a0의 공간이 나오고 그 공간을 다시 &amp;하는 것은 원래의 a0와 같기 때문에 *&amp; 라는 표현을 다 삭제해주는 것이다\n\n\n\n\n\n그다음에 변수 선언부를 다 삭제해주면 주소만으로 구성된 표현이 나오게 된다\n"},"pl.spring.2021.cse.cnu.ac.kr/2.-OCaml-문법-(2)":{"title":"2. OCaml 문법 (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\n모듈 §\n\n대문자로 시작함 - 소문자로 해주면 컴파일이 되지 않는다(관례가 아님)\nimport해줄 필요 없음 - dune이 자동으로 모듈화한다\ndune은 굳이 안건들여도 된다 - (include_subdirs unqualified) 해주면 하위디렉토리까지 전부 모듈화시켜줌\n\nNested module §\n\n모듈 내에 모듈을 또 정의해서 사용 가능함\n\nmodule module_name_ = struct ... end\n\nnested module은 이렇게 접근 가능하다\n\nModule.Nested_module_.func_\n모듈 불러오기 §\n\n기본적으로 import는 할 필요 없다\n하지만 경로가 길어지면 불편해지므로 open이라는 기능을 지원한다\n\nModule_name_.func_\n(* 이건 아래와 같다 *)\nopen Module_name_\nfunc_\n\nopen 을 이용하면 모듈 내의 함수/변수 등을 . 로 경로를 들어가서 불러내지 않아도 바로 불러줄 수 있다\n하지만 같은 이름의 변수 / 함수의 경우 충돌이 있으므로 잘 생각해서 사용할 것(충돌이 일어날 경우 그늘효과에 의해 마지막에 불러온 놈으로 앞의 놈까지 다 가려진다)\nlet-open-in 을 통해 scope를 제한할 수 있다 - 해당 모듈 내에서만 open하여 사용하고 싶을 때\n함수 module을 이용해서도 모듈을 불러올 수 있다 - 모듈의 경로가 긴 경우 이것으로 닉네임을 설정해 사용할 수 있음\n\nmodule M_ = Module_\n\nconflict를 막을수도 있고 가독성도 떨어지지 않으므로 추천하는 방향이다\n\nPattern matching §\n\n매우 중요하고 유용하다\n값의 형태에 기반하여 다르게 처리함\n처리안한 형태가 있을 경우 warning을 뿜는다\n\nmatch expression_ with\n    pattern1_ -&gt; expression1_\n    pattern2_ -&gt; expression2_\n    pattern3_ -&gt; expression3_\n    ...\n\npattern에 선언되지 않은 변수를 사용해도 된다 - expression의 결과가 자동으로 그 변수에 할당됨 (매칭시 어떤 값을 담는 그릇)\n따라서 변수는 하나의 패턴에만 사용해야 한다(미리선언한 변수를 갖고와서 사용하는것도 안된다 이거야)\nwildcard를 pattern에 넣으면 나머지 전부의 경우의 수를 처리할 수 있다\n\n변수를 써도 되지만 이 변수를 다시 사용하지 않으면 warning이 나오므로 사용하지 않을거면 wildcard를 쓰는게 현명하다\n예상하지 못한 경우의 수가 있을 수 있으므로 항상 마지막엔 wildcard를 pattern에 넣어주는것이 에러가 안난다\n\n\n그리고 처음에 넣어준 expression의 결과값의 type을 보고 모든 가능한 범위가 커버되었는지 확인하므로 논리적으로는 가능한 범위가 커버되었어도 자료형적으로는 모든 범위가 커버되지 않았을 경우가 있다\n연속된 값을 pattern으로 처리하고 싶을때에는 정규식에서의 [a-b]와 비슷한 연산을 제공한다\n\n[a-b] (* 정규식에서의 이 표현은 *)\n&#039;a&#039; .. &#039;b&#039; (* 이것과 같다 *)\n\nif-then-else와 마찬가지로 모든 pattern에 대한 매칭값은 자료형이 일관되어야 한다\n\nfailwith §\n\n파이썬에서의 raise와 비슷하다\n\nfailwith &quot;error_message&quot;\n\n에러를 발생시키고 넣어준 문구를 반환하는 함수이다\n아주 많은 경우의 수에 대해 각각 복잡한 구현을 해야한다면 하나의 경우의 수 pattern에 넣고 나머지는 failwith로 두고 이런식으로 점진적으로 구현하는 것이 가능하다\n\n리스트 §\n\n원소들의 타입이 반드시 같아야 한다\n리스트의 타입은 int list, string list 등 type list 형태이다\n\n이것이 해당 리스트의 자료형 이름이 되는 것\n\n\n리스트의 원소 구분은 세미콜론(;)이다\n:: 연산자\n\nappend_first기능\n\n\n@ 연산자\n\n+기능\n\n\n다행히도 동적배열을 지원한다\n\nList.iter 함수 §\n\n아무것도 반환하지 않는 함수와 리스트를 받아 각 원소들을 함수에 넣어 실행하고 아무것도 반환하지 않음\nargs:\n\nf(function) : 리스트를 받아 뭔가를 실행하고 unit을 반환\nl(list) : 함수에 넣어줄 값들을 원소로 하는 리스트\n\n\nreturn:\n\nunit : 아무것도 반환하지 않음\n\n\n\nList.map 함수 §\n\n함수와 리스트를 받아 리스트 원소들을 함수에 넣어 실행하고 그 결과를 다시 리스트로 묶어 반환\nargs:\n\nf(function) : 원하는 동작을 담은 함수\nl(list) : 함수에 넣어줄 값들을 원소로 하는 리스트\n\n\nreturn:\n\nlist : 함수 실행 결과들을 묶어서 만든 리스트\n\n\n\nList.fold_left 함수 §\n\nf와 어떤 값x, 리스트l을 받아 f(f(f(x, l[0]), l[1]…)을 실행하는 함수\nargs:\n\nf(function) : 원하는 동작을 담은 함수\nx(whatever) : 어떤 값\nl(list) : 중첩실행할 리스트\n\n\nreturn:\n\nwhatever : 결과값\n\n\n자료형 유의해라 - f, x, l에 어떤 자료형을 넣어야 하는지\n\n리스트 패턴매칭에의 활용 §\n\n:: 연산자는 append_first라는 기능을 하기도 하지만 패턴매칭에서 패턴으로 활용하면 쪼개는 기능으로 활용할 수 있다\npattern을 a :: b 이렇게 적어주면 리스트의 첫번째 원소가 a로 들어가고 첫번째 원소를 제외한 나머리 리스트는 b에 담기게 된다\n\nDisjoint unions §\n\n여러개의 자료형들을 하나의 자료형으로 묶어서 다양한 형태를 갖는 하나의 자료형을 정의하는 것이다\n\ntype type_name_ =\n    | Identifier1_ of int\n    | Identifier2_ of string\n    | Identifier3_ of char\n    ...\n\nIdentifier은 variant라고 불리는데 type_name_ 자료형의 한가지 형태라고 볼 수 있다.\n\n예를들어 number 자료형에 Integer of int라고 명시한다면 Integer 3은 정수로써 기능은 하지만 자료형은 number인 것이다\n\n\ntype_name_ 은 반드시 소문자로 시작하여야 한다\n그리고 Identifier 은 반드시 대문자로 시작하여야 한다\nof 자료형은 반드시 적어줘야 하는 것은 아니다 - of 자료형을 적지 않으면 unit을 대체하는 자료형이 생성되는 것이다\nIdentifier 값 으로 type_name_ 의 자료형을 하나 생성할 수도 있지만 그 반대도 된다\n\ntype_name_ 을 자료형으로 하는 변수를 만든 다음 이 변수에 값을 넣어주면 이 값의 자료형에 따라 Identifier 가 결정되기도 함\n\n\n따라서 pattern matching에서 pattern에 걸리도록 할 수 있다\ntype이 모듈이 들어있을때 type의 variant을 사용할때도 모듈이름을 붙여줘야 한다\n\nDisjoint union을 활용한 내장 자료형 - option §\n\nNone과 Some의 두 형태를 가짐\n어따쓰는건지는 나도 잘 모르겠다\n\n함수에서의 자료형 명시 §\nfunc_name_ (arg1 : type) (arg2 : type) ... :type\n\n이렇게 매개변수는 : 자료형 을 함께 괄호로 묶어주고 리턴타입은 맨 끝에 저렇게 적어주면 된다\n"},"pl.spring.2021.cse.cnu.ac.kr/3.-재귀-호출-최적화-기법":{"title":"3. 재귀 호출 최적화 기법","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\n재귀문 최적화 §\n\n함수형 언어에서는 알고리즘적으로 최적화할 수 있는 방법이 많지 않다\n대신 이런 최적화는 컴파일러에서 수행하므로 우리가 할 것은 컴파일러가 최적화를 잘 해줄 수 있는 방향으로 코드를 짜야 된다\nOCaml에서 변수는 불변하게 선언되는데 이것이 최적화에 아주 많은 도움이 된단다\n\nTail call optimization §\n\n함수가 하나 더 실행되어 callee가 하나 생성되면 이전의 caller를 지워버리는 기법\n메모리를 추가적으로 먹지 않으므로 메모리 관리에 유용하다\n\n방법 §\n\n재귀를 호출할때 함수의 맨 끝에서 호출하면 된다\n재귀의 경우 다시 돌아와야 되는 이유는 돌아온 이후에 코드가 더 있어서 작업을 더 해줘야 하기 때문\n하지만 돌아온 이후에 할일이 없어 바로 caller가 종료되는 구조라면 굳이 돌아오지 않아도 된다\n따라서 맘편하게 caller를 메모리에서 지워도 되므로 재귀호출시에 메모리를 더 먹지 않는다\n\n이런식으로 굴러가게 하는 것을 tail call optimization이라고 하는 것\n\n\n\n활용 - 누산기(Accumulator)이용 §\n\n결과값을 다 더해야 하는 함수의 경우 재귀 호출 종료 후 더하는게 아니고 매개 변수 acc를 하나 추가해서 값을 누적하는 작업도 함수 내에서 수행하게 함\n하지만 매개변수를 추가해야 되므로 함수의 구조가 바뀌게 된다\n\n이것을 방지하는 방법은 구조가 바뀐 함수를 기존 구조의 함수로 포장지를 싸듯이 감싸는 것이다.\n즉, 기존 구조의 함수 내에 매개변수가 추가된 함수를 local하게 넣어서 기존 구조 함수는 재귀적으로 실행되지 않고 안에 들어있는 함수가 재귀적으로 호출되어 tail call적으로 연산을 수행함\n이렇게 되면 함수의 구조도 바뀌지 않고 메모리 사용도 현저히 줄어들므로 꿩먹고 알먹고 이다\n이러한 구조를 wrapping한다\n\n\n"},"pl.spring.2021.cse.cnu.ac.kr/4.-Syntax와-Semantics":{"title":"4. Syntax와 Semantics","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\nImperative &lt;-&gt; Declarative §\n\nImerative : 보통의 명령들을 나열해 문제를 푸는 방법을 선언하는 방식으로 프로그래밍 하는 것\nDeclaraive : 문제를 푸는 방법을 적는게 아니라 어떤 문제인지를 적어서 프로그래밍하는 방법\n\n문제는 얘가 알아서 풀어준다\n옛날에는 구렸는데 요즘은 엔진이 좋아져 종종 쓰인댄다\nSQL같은게 여기에 해당한다고 할 수 있음\n\n\n\n프로그래밍 언어의 번역 vs 해석 §\nCompile §\n\n번역은 그냥 동일한 의미의 기계어로 바꾸는 것 (Compiled language)\n오류를 컴파일 타임에 잡을 수 있다\n프로그램 전체를 검토해 기계어로 바꾸기 때문에 최적화 가능 (성능의 이점)\n비교적 low level이어서 시스템 프로그래밍에도 사용할 수 있다\n다만 비교적 배우기 어렵고 컴파일 과정이 복잡하다\n그리고. static-typed language이다\n\n컴파일 시점에 변수들의 자료형이 모두 결정된다\n\n\n자바같은 경우에는 JVM이라는 가상 기계어 환경으로 컴파일해 구동하는 과정을 거친다\n\n여러 플랫폼에서 일관되게 지원하기 위함\n\n\n\nInterprete §\n\n해석은 언어를 읽고 이해해 바로 실행하는 것 (Interpreted language)\ninterprete는 프로그램을 통째로 컴파일하는 과정이 아닌 바로바로 해석해서 실행하게 된다\n\n컴파일의 경우에는 통째로 번역하기 때문에 최적화가 용이하지만 인터프리트의 경우 한줄한줄 바로바로 실행하기 때문에 최적화가 어려움\n속도가 비교적 느리다\n\n\n간단한 검증만을 수행하기 때문에 오류를 미연에 방지하기는 컴파일 언어보다 어렵다\n대신 배우기 쉽고 자유로우며 자료형들이 동적으로 선언(Dynamic-typed language)된다\n스크립트 언어들이 여기에 해당된다\n그리고 shell들도 이런식으로 구동된다\n\n프로그래밍 언어의 구성 §\n\n프로그래밍 언어는 syntax와 semantics로 구성되며 얘네들은 해당 언어의 **specification(사용 설명서)**에 기술된다\nSyntax : 명령어들이 어떻게 생겼는지\nSemantics : 해당 syntax가 어떻게 작동하는지를 기술\n\nsyntax별로 semantics가 정의되게 된다\n\n\n\nUnspecified Behaviors §\n\n특정 syntax에 대해 일부로 semantics를 정의 않는 것\n동작을 정의하는데에 있어 자유를 부여함\n\n이때 자유라는 것은 나의 자유가 아니라 어떻게 동작할지는 해당 언어의 컴파일러 / 인터프리터 개발자의 자유이다\n얘네들을 개발할때 임의적으로 정의해서 개발을 하게 된다는 것\n컴파일러 / 인터프리터에 따라 다르게 작동할 수 있다\n\n\n보통 어떻게 정의하든 별로 중요하지 않을 때 이런식으로 기술한다\n\n정의가 중요했으면 당연히 semantics를 정의했겠지\n\n\n다만 개발자는 얘가 semantics를 정의하지 않은 놈이라는것을 알고는 있어야 한다\n\nUndefined Behaviors §\n\n특정 syntax에 대해 semantics가 정의 않은 것\n얘네들은 약간 에러같은애들이다\n\n프로그램을 오작동하게 하지만 에러로 처리하기에는 성능면에서 안좋거나 하는 등의 사유가 있는 애들\n\n\n얘를들어서 쓰레기값에 접근하는 경우이다\n\n얘네들은 에러는 안나지만 undefined여서 오작동하게 된다\n\n\n따라서 개발자는 어떤 경우에 undefined인지를 반드시 숙지해야 한다\n"},"pl.spring.2021.cse.cnu.ac.kr/5.-Lexical-Analyzer-(Lexer,-어휘분석기)":{"title":"5. Lexical Analyzer (Lexer, 어휘분석기)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\n프로그래밍 언어란 §\n\n프로그래밍 언어는 &lt;정해진 문법&gt;을 따르는 &lt;알파벳 문자열&gt;이다\n\n구문분석기(syntax analyzer 혹은 parser) §\n\nG = 문법 = 규칙\n함수 L()를 인자로 받은 문법으로 만들 수 있는 모든 문자열들의 집합을 반환하는 함수라고 가정해보자 - 그럼 L(G) 는 해당 문법에 부합하는 모든 문자열의 집합이다\n임의의 문자열 s가 집합 L(G)의 원소인지를 판단하는 것이 syntax analyser 혹은 parser가 하는 일이다\n\nChomsky hierarchy §\n\n\n여기 보면 왼쪽에 있는 놈이 L(G)에 대응하고 오른쪽에 있는 놈이 Parser에 대응한다\n\nautomaton(복수형 - automata)이라는 것은 parser랑 비슷하게 어떤 문자열이 어떤 문법을 따르고 있는지 판단해주는 가상(상상에만 존재하는) 기계(머신)이다\n\n\n즉, 어떤 문자열이 [왼쪽]에 속하는 지를 [오른쪽]놈이 판단한다 이말이다\n그리고 원이 클수록 더 많은 표현을 할 수 있게 된다\n일반적인 프로그래밍 언어는 Context-Free Language로 정의된다\n그리고 일부의 프로그래밍 언어가 Context-Sensitive Language로 정의되고\nRecursively-Enumerable Language는 존재하지 않는다\n\n무한대의 저장공간을 가지고 있는 이상적인 parser가 Turung Machine이기 때문\n\n\n\n기본 정의 §\nAlphabet §\n\n여기에서 alphabet이란 &lt;기호&gt;들의 &lt;유한집합&gt;(finite set)이다\n굳이 영어의 알파벳이 아니더라도, 몇개의 기호들을 모아 집합으로 만들면 그게 알파벳이 된다 이거다\n알파벳은 Σ 시그마로 표현한다\n\nString - 문자열 §\n\n문자열은 알파벳 내 &lt;기호&gt;들의 &lt;유한 순서&gt;이다\n즉, 기호 몇개를 묶어 순서를 가지게 나열하면 그게 문자열이 된다는 것이다\n길이가 유한하다는 거지 문자열 집합의 크기가 유한하다는게 아니다 - 문자열 집합의 크기는 무한\n알파벳으로 만들 수 있는 모든 문자열의 집합을 Σ * - 시그마 별로 나타낸다\n빈 문자열은 ε로 나타낸다\n문자열만을 언어로 정의하면 유효하지 않은 놈들까지 포함되게 된다\n\n이메일 언어를 정의하기 위해 대, 소문자와 @를 알파벳으로 정의하고 이 알파벳으로 만든 문자열 집합을 이메일 언어로 정의해버리면 @@@도 이메일 언어에 포함되게 됨\n언어의 정의는 좀 더 복잡하게 할 필요가 있더라\n\n\n\n문자열 연산 §\n\n접합 : {xy | x → Σ * 1, y → Σ * 2} - 문자열 두개 같다붙인거\n합집합 : {x | x → Σ * 1 OR x → Σ * 2} - 문자열 두개 OR\n클레이니 스타(kleene closure) : {x | x → ε OR x → Σ OR x → ΣΣ … } - 결국에는 (Σ *) * 는 Σ * 와 같게 된다 - 정규식에서의 별표\n\n문자열 연산을 이용하여 “정밀하게” 언어를 정의하기 §\n\n“정밀하게”정의한다는 것은 “올바른” 문자열만을 언어에 포함시키겠다는 의미이다\n문자열 연산을 활용하여 우리가 원하는 언어만 언어에 포함시키도록 해야 한다\n\n정규식 §\n\n정규식 배웠제?\n정규식으로 표현할 수 있는 언어를 정규 언어라고 한다\n\n저기 chomsky 다이어그램에서 regular language라고 돼있는 애들이 이거임\n\n\n표현력이 아주 제한적이다\n\n생각해보면 정규식은 {ab, aabb, aaabbb, aaaabbbb … }같은 애들을 검거하지 못한다\n\n\n따라서 거의 모든 프로그래밍 언어는 정규언어가 아니지만 Parser에서 정규식을 활용해 입력받은 문자열이 프로그래밍 언어의 syntax에 맞는지 확인한다\n정규식을 문자열 집합으로 표현해보면 이래된다\n\n\n\n정규식에서의 연산자 우선순위 → () &gt; 클레이니스타 &gt; 접합 &gt; 합집합\n\ns가 L에 속한다 §\n\n이 말인 즉슨 문자열 s가 언어집합 L의 원소이다 라는 말이다\n하지만 언어집합L은 무한집합이기 때문에 L의 모든 원소를 나열한 다음 문자열 s가 속하는지를 할 수는 없다\n\nFinite State Automata §\n\n오토마타는 추상기계, 그니까 어떠한 작업을 하는 기계를 머릿속에 상상하면 그놈을 automata라고 부른다\n그니까 FSA(Finite State Automata) 혹은 FA(Finite Automata) 는 유한한 동작 단계를 가지는 머릿속에 존재하는 기계하는 뜻이다\n\n상태를 기계가 작동하며 거치게 되는 단계들이라 생각하면 된다\n\n\nFSA는 다음과 같은 요소들로 구성되어 있다\n\nQ : 상태들의 집합이다. 즉, 기계가 작동하며 거치게 되는 모든 단계들을 모아놓은 것이다\nΣ : 알파벳. 가호들을 모아놓은 집합\nq : 시작 상태. 기계가 작동하기 전 초기의 단계라고 생각하면 될 것이다. 이것도 상태이므로 Q의 한 원소이다\nF : 종료 상태의 집합. 종료될때는 뭐 정상적으로 종료되었는지 아니면 뭐 ㅈ됐는지 등등 다양한 상태를 가질 수 있으므로 집합으로 표현된다. 이것도 마찬가지로 상채이므로 Q의 부분집합이 된다\nδ : 전이 함수 집합. 전이 함수라는 것은 어떤 경우에 다음 상태(단계)로 넘어가고 어떤 경우에 현재 상태(단계)에 머물러 있어야 되는지 등의 동작을 말한다\n\n\n이제 이 기계를 작동시켜 보자.\n\n어떤 문자열이 들어오고 이것이 언어에 속하는지를 판단하기 위한 FSA를 하나 만들었다고 해보자.\n일단 q의 상태로 시작할 것이다.\n그 이후 문자열의 첫번째 문자와 q상태를 전이함수에 넣어 상태를 하나 얻어낸다.\n그리고 또 그 다음 문자와 얻어낸 상태를 전이함수에 넣어 또 상태 하나를 얻어낸다.\n이렇게 문자열의 모든 문자를 훑고 나면 내 손에 최종 결과로 나온 상태가 하나 쥐어져 있을 것이다.\n이것이 종료상태F에 포함된다면 나는 이 문자열이 이 언어에 해당한다고 말할 수 있을 것이고, 그렇지 않다면 포함되지 않는다고 말할 수 있을 것이다.\n또한 작동하는 와중에 전이함수에 정의되지 않은 동작을 해야돼서 상태가 도출되지 않아도 이 언어에 포함되지 않는다고 말할 수 있다.\n\n\n\nLexical Analyzer (Lexer), Syntax Analyzer (Parser) §\n\n코드 한줄을 이 lexical analyzer(혹은 lever)를 통해 토큰으로 바꾸게 된다\nlexical analyzer(혹은 lexer) 는 정규식을 이용해 코드를 토큰들로 쪼개는*프로그램이다\n토큰은 뭐 OCaml에서의 let, fun같은 &lt;키워드&gt;나 =, +, (, )같은 &lt;기호&gt;(어휘항목이라고도 한다)들을 나타내는 하나의 자료형이다\n이 Lexer는 보통 Parser와 같이 동작한다\n\nParser가 토큰 하나를 요청하면 Lexer가 제네레이터마냥 토큰을 하나 던져주고 이런식으로 동작한다\n정규식에서의 ‘소비’개념때문에 제네레이터처럼 작동할 수 있는 것\n\n\n검거 실패했을 경우 syntax error가 발생한다\n\nlexer가 검거에 실패하면 parser가 에러를 판단하고 내보내기 때문\n\n\n"},"pl.spring.2021.cse.cnu.ac.kr/6.-Syntax-Analyzer-(Parser,-구문분석기)":{"title":"6. Syntax Analyzer (Parser, 구문분석기)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\nLexer , Parser §\n\nLexer : 문자열 → 토큰\nParser : 토큰 → Abstract Syntax Tree(AST)\n\nContext Free Grammar(CFG)소개 §\n\n대부분은 이걸로 무한한 문자열 집합을 표현하며\n일부의 언어가 더 고급진 CSG(Context Sensitive Grammar)을 사용한다\n\n하지만 얘의 경우에는 많은 용량을 사용해 파서에게 부담을 안겨준다\n\n\nCFG는 정규표현식보다 더 많은 표현력을 가진다\n\n따라서 정규표현식으로 표현 가능한 문자열을 CFG로 표현 가능하지만 그 반대는 아니게 된다\n\n\n하지만 정규언어가 더 간결하기 때문에 lexer의 경우에는 정규식을 쓰고 parser에서는 정규언어로는 부족하기 때문에 CFG를 쓰는 것\n\nCFG 표현 §\n\n&lt;&gt; : 논 터미널 (다른 기호들로 치환되는 기호)\n\n경유지 같은 느낌\n\n\n→ : 치환이라는 의미\n\n좌측을 우측으로 바꿔치기할 수도 있고 우측을 좌측으로 바꿔치기 할 수도 있음\n\n\n| : or\n0, 1, E : 터미널 (다른 기호들로 치환되지 않는 기호)\n\n종착지같은 느낌\n\n\n\nCFG 수학적 표현 §\n\nΣ : 터미널들의 유한집합\nN : 논터미널의 유한집합\nP : 규칙의 집합\n\n‘ → ‘ 좌측의 논터미널을 우측의 터미널, 논터미널의 조합으로 치환 가능하다\n이때의 ‘ → ‘쌍을 규칙이라고 하는 것\n\n\nS : 시작 논터미널 (시작 기호)\n\n당연히 S는 N의 원소이다\n\n\n\nBackus-Naur form - CFG를 컴퓨터 내에서 기술하는 방법 §\n\n→ 를 ::= 로 기술함\n논터미널을 기술할때는 &lt;&gt;표기는 생략함\n=의 좌측은 무조건 논 터미널로 인식\n\nCFG로 문자열 만들기 - Derive §\n\n\n시작 논터미널로부터 시작해\n규칙에 따라 논터미널을 치환한다\n\n이 규칙에 따른 치환을 유도라고 한다\n\n\n그래서 더이상 치환할 논터미널이 없으면 그게 만들어낸 문자열이 된다\n유도는 =&gt;D 로 표현한다\n\n약간 치환되는 과정을 나타내는 것\n\n\n\n문자열을 CFG로 판별하기 §\n\n\n단순하다. 유도의 반대과정을 거치면 된다\n즉, 오른쪽을 왼쪽으로 치환하는 과정을 반복해서 시작 터미널이 나오면 CFG에 속한다고 표현할 수 있는 것\n이 반대과정은 기호로 =&gt;p로 표현한다\n\n유도(Derivation)의 반대는 파스(Parse)\n\n\n하지만 이 파싱의 알고리즘은 CFG에서는 제공하지 않는다 (형태만을 지정하므로)\nLL(k), LR(k)등의 알고리즘이 존재한다\n다행히도 파서 생성기가 존재한다 (CFG를 가지고 파서를 자동으로 만들어주는 놈)\n\nC언어에서 Bison같은놈이 이런 기능을 한다\n\n\n\nParse tree(Derivation tree) §\n\n이 유도/파스의 과정을 Tree 자료구조로 표현한 것이 Parse(Derivation) tree이다\n\n\n\n각 노드는 터미널 혹은 논터미널로 되어 있다\n루트 노드는 시작 논터미널이고 중단 노드는 논터미널, 리프 노드 만이 터미널이 된다\n부모와 인접한 자식들간의 관계는 좌측 논터미널과 우측 기호들 간의 관계와 일치한다 (자식이 많을 경우 하나하나 생각하는게 아니라 왼쪽 → 오른쪽으로 읽은 것이 우측 기호가 되는 것)\n리프 노드를 왼쪽 → 오른쪽으로 읽으면 유도된 문자열 이 나오게 되는 것\n트리를 거꾸로 읽으면 Parse의 과정 을 알게 되는 셈이다\n\n유도의 종류 §\n\n좌측 우선 유도(Leftmost derivation) : 왼쪽부터 차례로 유도해 나가는 것\n우측 우선 유도(Rightmost derivation) : 이번에는 오른쪽에서부터 차례로 유도해나가는 것\n근데 어떻게 유도하냐에 따라 Parse tree가 달라지고 이것은 결과적으로 AST에도 영향을 끼쳐 비효율적인 동작을 하게 될 수도 있다\n대신 유도 방법이 정해지면 항상 동일한 Parse tree가 나와야 한다\n\n만약에 여러개가 나온다면 문법을 잘못 정의한 것(모호하게 정의한 것)\n하나의 유도방법에는 하나의 Parse tree만\n\n\n문법의 모호성이 나오지 않게 신중하게 작성해야 한다\n\ntip : 좌측의 논터미널이 우측에 두번 이상 나오도록 치환규칙을 짜면 문제가 생기던데\n\n\n\nAST(Abstract Syntax Tree) §\n\n\nAST랑 Parse tree와는 다르다\nParse tree는 실제 문자열이 유도되는 모든 과정을 나타내는 개념적인 과정이고 (따라서 CFG가 있으면 Parse Tree를 유도해낼 수 있는거)\nAST는 parse tree에서 언어의 구조적(동작), 내용적(값) 구문 구조만을 포함시켜 우리가 정의한 규칙을 따른다\n\n어딘가에서 유도되는게 아니고 정의하는 것이여라\nParse tree를 가지고 우리가 단순화시켜서 정의하는 것이다\n\n\n따라서 Parser는 Parse tree를 반환하는게 아니고 AST로 반환한다\n이제 이 AST를 가지고 컴파일러나 인터프리터가 실행하게 된다\n"},"pl.spring.2021.cse.cnu.ac.kr/7.-언어의-정의":{"title":"7. 언어의 정의","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\nConcrete, Abstract syntax §\n\nConcrete syntax : 구체적 문법(우리가 사용)\n\nRE, CFG를 구체적 문법이라고 생각하면 된다\n\n\nAbstract syntax : 추상(요약) 구문(컴파일러가 사용)\n\nAST나 BNF(Backus-Naur form)으로 명시된 Abstract syntax를 의미한다\n\n\n\nAST §\n\n구문은 또 다른 구문들로 정의된다는 재귀적 특징은 트리에서 트리의 subtree 또한 트리라는 재귀적 특징과 닮아있으므로 프로그래밍 언어의 구문을 트리로 표현하는 것을 효과적이다\nAST를 쓰는 이유: 불필요한 문법적 디테일을 제거\n\n언어마다 다른 구체적 문법적인 것들을 배제하고 어떤 것들을 받아서 순수하게 어떤 동작을 하는지를 명시하는 것이 추상 문법이다\n뭐 함수를 선언할때 def를 쓸건지, function을 쓸건지 하는 것들은 세부적인 디테일이므로 언어와 독립적인 Abstract syntax를 정의하느데에는 필요 없기 때문\n또한 2 + 1, 02 + 001같은 의미는 같지만 형태만 다른 구제적 문법들을 별도로 정의할 이유가 없기 때문에\n\n\nAST의 경우에는 우리가 정의하는 것이기 때문에 구조가 하나로만 도출되는 Parse Tree와는 다르게 다양한 구조를 가질 수 있다\n\n수업에서 Abstract Syntax를 정의한 방식 §\n\nAST : 부모노드에 얘가 어떤 연산인지를 적어주고, 자식노드에 어떤 인자들이 연산되는 지를 적어주는 식으로 트리를 구성했다\nBNF AS : Abstract Syntax를 BNF로 기술한 것이다.\n\n\n\n(e ::= n) 은 AST (Num - n)와 같다\n(e ::= e + e) 은 AST (Add - e e)와 같다\n(e ::= e - e) 은 AST (Sub - e e)와 같다\n저 표현은 이 세개의 트리를 합쳐놓은 것과 같은 표현이 되며 각각의 트리를 Langauge construct라고 한다\n\nAST 정의 수업에서의 예시 - 언어 AE 기술하기 §\n\n언어 AE는 Arithmetic Expression, 즉, 정수의 합과 차를 표현하는 언어이다\n집합 E는 언어 AE의 모든 AST의 집합이다\nn이 정수일때, 이 정수는 Num이라는 parent node를 가진다\n\nNum은 AE의 숫자를 표현 하는 노드\n\n\n또한 Add노드도 두개의 E의 원소를 자식으로 받는 AE의 덧셈을 표현 하는 노드이다\nSub도 마찬가지로 AE의 뺄셈을 나타내는 노드 이다\n트리를 보면 아래서부터 위로 연산이 되므로 연산의 우선순위를 나타내는 괄호는 이런 상하관계를 시용하면 표현할 수 있다\n매번 트리를 그리기는 귀찮으므로 이것을 코드 형식으로 표기할 수도 있다\n\n’n’은 Num 트리를 가리키고 ‘e1 + e2’는 Add트리, ‘e1 - e2’는 Sub트리를 나타낸다.\n여기서 +와 -는 연산자가 아니라 그냥 기호일 뿐 이다\n\n이제 코드 표기법과 BNF표기법을 이용해 트리를 표기할 예정이랜다\n이 코드 표기법에서는 트리의 상하관계 즉, 우선순위를 나타낼 때 괄호를 사용하는 것도 암묵적으로 허용한댄다\n\n\n\n\n이때의 n, e1, e2를 metavariable(고차원 변수) 라고 한다\n\n실제 프로그래밍 언어에서의 변수와는 다르게 정의된 어떤것으로든 치환될 수 있는 것?\n뭔지 감만 오제?\n\n\n\nSemantics §\n\n프로그래밍 언어의 Semantics : 이 프로그래밍 언어는 어떻게 계산, 실행되는지\n해당 프로그래밍 언어로 구현된 모든 프로그램의 실행시 행동을 정의?\n프로그램적 Semantics : 이 프로그램은 어떻게 계산, 실행되는지\n약간 이런 느낌인거 같다 : 프로그래밍 언어의 Semantics는 더 포괄적인 실행을 의미하는 거고 프로그램의 Semantics는 약간 해당 프로그래밍 언어로 표현된 하나의 코드 예시? 가 어떻게 실행되는지\n이 프로그램적 Semantics는 언어적 Semantics에 기반을 두게 된다\n아닌가\n\n프로그래밍 언어의 Semantics §\n\nAST를 기반으로 한다\n\n불필요한 문법적 디테일을 무시할 수 있고, AST의 각 구문별로 의미를 정의할 수 있으므로\nAST하나당 하나의 대응되는 Sementics를 정의한다는 말이다\n\n\n\n수학적 Semantics 정의 §\n\nSemantics가 자연어로 정의되면 읽는 사람마다 다르게 받아들이는 모호성을 야기할 수 있으므로 이것을 수학적으로 표현해야 한다\n\nBinary relation을 이용한 수학적 정의 §\n\nbinary relation은 걍 단순하게 생각해서 (키, 벨류)로 표현되는 키-벨류 쌍이라고 생각하면 된다\n\n집합 A의 원소를 키로 하고 집합 B의 원소를 벨류로 할 때 이것으로 만들 수 있는 모든 키-벨류 쌍의 집합을 AXB라고 한다\nAXB의 부분집합 R에 대해 이 R을 키-벨류간의 관계를 나타내는 기호라고 한다면\naRb라는 것은 “a가 A의 원소이고 b가 B의 원소이고 (a, b)쌍도 R의 원소이다”라는 것으로 정의할 수 있다\n걍 뭔소린지 모르겠으면 aRb라는 것은 a와 b의 관계가 R이다라고 생각해도 된다\n\n\n피피티에서 아랫쪽 화살표는 “좌항이 우항으로 계산된다”라는 의미로 받아들이면 된다\n\nInference Rule도 이용하기 §\n\nInference Rule : 분자에는 전제를 쓰고 분모에는 결론을 쓰는 형태의 기호\n분자의 전제가 전부 참이라는 전제 하에 분모가 참이 된다\n\nBig / Small step, Operational §\n\n프로그램의 계산을 중간단계를 다 생략하고 초기상태와 결과만 나타내는 것을 Bigstep이라고 한다\n반면에 중간단계를 생략하지 않은 계산법을 Smallstep이라고 한다\n이 계산을 머릿속에 존재하는 계산기가 계산해주는걸로 생각하고 표현하는 것을 Operational이라고 한다\nㅅㅂ small step이랑 orerational차이는 모르곘는데 시험에 나오면 그냥 operational이라고 쓰자\n\nProof tree §\n\n어떤 것의 증명 과정을 Inference rule을 이용하여 표현한 하나의 자료구조이다\n결론을 root로 그것의 전제를 차례로 파고들면서 더 이상 증명할 게 없을 때까지 파고드는 것이다\n부모노드와 자식노드는 inference rule로 연결하고 따라서 자식노드가 모두 참이면 부모노드도 참이 되는 구조를 가지게 된다\n일반적인 트리와 비슷하지만 root가 맨 아래에 위치하고 부모-자식 간 관계가 전제와 결론의 관계라는 특징을 가진다\n"},"pl.spring.2021.cse.cnu.ac.kr/8.-문법적-설탕과-식별자":{"title":"8. 문법적 설탕과 식별자","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\n언어의 확장 과정 §\n\nConcrete syntax의 확장\nAbstract syntax의 확장\nParser의 확장(CS → AS로 바꿔주는놈이 parser이므로)\nSemantics 확장(Abstract Syntax가 확장되었으므로)\nInterpreter 수정(AS → 기계어)\n\n\n컴파일 언어의 경우 더 많은 확장 단계를 가지게 된다\n\nSyntactic Sugar §\n\nConcrete syntax를 확장하되 확장된 구문을 기존의 Abstract syntax에 대응시키는 기법을 말함\nCS를 확장하므로 CS와 CS를 사용하는 parser는 확장해야 되지만 AS나 semantics 등은 확장하지 않아도 된다\nparser가 이 설탕쳐진 구문(확장된 CS)에서 설탕을 빼는 과정(기존의 CS로 변환하여 기존의 AS로 변환하는 과정)을 Desugaring이라고 한다\n하나의 AS에 대응되는 CS가 여러개가 되는 셈인거다\n\n따라서 CS를 하나 정의하고 그것을 기존의 AS에 대응만 시켜주면 되는 셈\n\n\n\nIdentifiers §\n\nIdentifier(식별자) : 함수, 변수, 프로퍼티, 메소드, 클래스들에 붙이는 이름을 식별자라 한다\n\nOccurrence of Identifier §\n\nOccurrence of Identifiers : 하나의 식별자는 프로그램에 여러번 등장할 수 있다는 개념\n\n등장의 종류 §\n\nBinding Occurrence : 식별자의 정의를 위한 등장\nBound Occurrence : 정의된 식별자를 사용하기 위한 등장\nFree Occurrence : 정의되지 않은 식별자를 사용하기 위한 등장\n\nScope of Identifier §\n\nBinding된 놈이 Bound될 수 있는 범위\n따라서 bind되어도 scope를 넘어가면 free identifier가 된다\nShadowing : 동일한 이름을 가진 식별자들의 scope가 겹치는 경우 bound했을 때 가장 가까운(가장 안쪽의, 가장 지협적인) scope를 따라가게 된다\n\n가장 가까운 놈이 먼 놈을 가린다는 의미에서 shadowing이라고 하는 것\n\n\n\nStore §\n\n요기 나오는 내용은 전부 언어 AE를 위해 수업에서 임의로 정의한 것이다\n\n개념은 통용되지만 용어나 구체적인 내용들은 수업용임\n\n\nStore : 가상 저장공간들의 집합\n\n가상 저장공간이라는 것은 변수를 받아 정수를 돌려주는 하나의 함수라고도 표현할 수 있다 (변수를 이용해 그 정수에 접근하는 것 이므로)\n근데 함수는 딕셔너리와도 유사하다(키를 이용해 벨류를 반환하므로)\n따라서 가상 저장공간은 변수를 받아 정수를 반환하는 딕셔너리라고도 생각할 수 있다\n가상메모리 = 변수이름을 받아 값을 돌려주는 함수 = 변수이름을 키로 받아 매핑된 값을 돌려주는 딕셔너리\n\n\n가상 저장공간 집합 Store는 변수를 받아 정수로 돌려주는 모든 함수(딕셔너리)들의 집합이다\n시그마 는 Store의 원소이다. 즉, 임의의 한 가상 저장공간(함수, 딕셔너리)이라는 말이다\n시그마[x → n] : 변수 x를 선언하고 n으로 초기화 하는 것(binding)\n\n즉, x를 받으면 n을 반환하는 규칙을 새로 함수에 추가하는 것\n즉, 키x와 값n을 딕셔너리에 추가하는 것\n선언, 초기화 후 업데이트된 시그마를 반환\n\n\n시그마(x) : 변수 x의 값(n)을 찾아 반환 하는 것(bounding)\n추상메모리 ~에서 라는 말의 말뜻 : 이게 말이 좀 어려울 수 있는데 그냥 이런뜻이다\n\ne에서 변수가 등장하지 않으면 이 메모리를 사용하지 않아도 되니까 추상메모리에서 라는 말은 별 의미없는 말이다.\n근데 e에서 변수가 등장한다면 이 변수를 정수로 고치는 바꾸는 것은 저 추상메모리에 정의된 규칙을 따른다는 소리이다\n\n\nternary relation : 말뜻은 뭔지 모르게땅\n\n이것의 기호는 ㅏ 이고 계산 문맥을 표현한다\n즉, EC ㅏ p 는 EC라는 규칙 하에 p가 참이라는 소리이다\n전제랑 문맥의 차이점은 이거다\n\n어떤 연산을 하기 위해 반드시 참으로 규명나야 되는 것은 전제로 들어간다.\n하지만 연산을 하기 위해 이용할 수도 있고 아닐수도 잇는 것은 문맥으로 들어간다?\n\n\n\n\n따라서 해당 추상메모리에서 표현식e를 계산했더니 정수n이 나왔다면 이 관계는 (추상메모리) ㅏ \\[(표현식e) 아래화살표 (정수n)\\] 로 말할 수 있는 것이다\n\n수업에서는 대괄호를 안쳐줬지만 생략된 것이므로 해당 추상메모리 하에서 “표현식 e는 정수 n으로 계산됨”은 참이라는 것을 뜻한다\n\n\n"},"pl.spring.2021.cse.cnu.ac.kr/9.-함수와-함수호출":{"title":"9. 함수와 함수호출","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  강의를 듣고 필기한 내용이기에, 다소 잘못된 부분과 부적절한 언행 이 포함되어 있을 수 있습니다.\n                  \n                \n\n수학에서의 함수와 차이점 §\n\n공통점 : 값을 전달하면 결과를 반환한다는 것\n차이점 : 수학에서는 함수를 정의하면 그 함수에 동일한 값을 전달하면 항상 동일한 값을 반환하지만 프로그램에서는 부작용이 있을 수 있어 같은 값을 전달해도 다른값을 반환할 수 있다\n\n부작용을 예로 들면 전역변수를 사용할 때 전역변수의 값에 따라 다른값을 반환 가능\n\n\n\nHigh order, First order §\n\n서로 반대의 개념\nFirst-order function : c언어에서처럼 함수를 인자로 받지도 못하고 함수를 반환하지도 못하는 특성\n\n함수를 객체 / 변수와 별도로 취급함\nSecond-class citizen이라고도 한다\n변수와 별도로 취급하기 때문에 변수를 저장하는 추상 메모리와 별도로 추가로 함수를 저장할 추상 메모리가 필요함\n\n\nHigh-order function : 함수형 기능을 지원하는 언어처럼 함수를 하나의 객체로 취급해 인자로 받을 수 있고 함수를 반환하는것도 가능\n\nF1VAE §\n\nfirst-order를 지원하는 함수 정의문 하나와 그 뒤에 표현식 이 나오는 예시언어\nfirst-order이기 때문에 함수를 저장할 별도의 메모리가 필요한데 그 함수 메모리의 집합을 FunDef 라고 정의\n\nFunDef의 원소는 함수이름(Var)를 키로 받고 (매개변수(Var) * 몸체 표현식(E)) 튜플을 벨류로 한다\n\n\nFunDef의 한 원소를 람다 라고 지칭\n람다(x) : 함수 이름(x)를 키로 조회해 매개변수와 몸체 표현식 튜플을 반환\n람다[x1 - &gt; (x2, e)] : 함수 이름(x1)을 키로 하고 매개변수(x2)와 몸체표현식(e) 튜플을 벨류로 하는 키 - 벨류 쌍을 추가하여 업데이트한 새 메모리를 반환\np 아래화살표P n : 프로그램 p는 정수 n으로 계산된다는 뜻 - (P, Z)튜플\nd 아래화살표D 람다 : 함수정의d는 그 함수를 저장한 람다로 계산된다는 뜻 - (D, FunDef) 튜플\n람다, 시그마 ㅏ e 아래화살표E n : 람다와 시그마를 이용해 e를 계산했을때 n이 나옴 - (FunDef, Store, E, Z)튜플\n\n참고) 저 튜플 ㅅㅂ 아직도 잘 이해가 안되는데 이전까지 사용하던 아래화살표가 (Store, E, Z)튜플인 것을 이용해 잘 이해해봐라\n\n\n\n함수의 호출 §\n접근1 - 치환(Substitution) §\n\n\ne[n / x] 라는 것은 e에 나오는 모든 x를 n으로 치환한다는 뜻이다\n다만 여기서 치환하는 대상은 파라미터를 bound 하는 애들 (파라미터에 대해 bound occurrence한 애들) 이다\n\n즉, 함수의 몸체(e)안에 매개변수랑 동일한 이름으로 bind occurrence가 이루어지면 그 이후부터는 전부 shadowing되기 때문에 치환하면 안된다\nshadowing이 된 값이 변수의 값으로 매핑되어야 되는데 인자의 값이 변수의 매핑되게 되어 문제가 생긴다\n\n\n\n\n\n결과는 이렇게 나온다 - 여기서 중요한 점은 치환이기 때문에 e1을 계산할 때는 어떠한 메모리도 참조하지 않는다는 것이 중요하더라\n\n접근2 - 가상 메모리 사용(Using Store) §\n\n\n일반적으로 우리가 프로그램에서 함수가 동작하는 과정 - 매개변수도 변수니까 매개변수와 그의 값을 가상메모리(Store)에 업데이트시켜서 그 가상메모리로 계산을 하자\n\n\n\n그에대한 결과다 - 여기서 또 중요한 점은 기존 e를 계산할때 사용한 가상메모리와 e1을 계산할때 사용한 메모리는 다르다는 점이다\n\n새로운 메모리가 생성되어 매개변수가 드감\n\n\n\nScope §\n\n보통 언어는 이 둘중 하나의 scope개념을 가지고 설계된다\nLexical(Static) scope : 컴파일 시점에 스코프가 정해짐\nDynamic scope : 실행시점에 스코프가 정해짐\n\n컴파일 시점이라는 것은 보통 한눈에 보면 어디까지가 볌위인지 알 수 있지만 실행시점이면 범위가 어디까지인지 한눈에 알기 힘듦\n예시 - 함수 외부에서 binding된 변수가 함수 내부에서도 bound가 가능한 언어의 경우\n\n\n위에서 가상 메모리를 사용한 함수의 호출에서 매개변수의 값을 계산할때와 함수의 몸체를 계산할때 별도의 메모리를 사용하는 것은 이 언어가 Lexical scope이기 때문인거다\n\n일반적인 Lexical scope에서는 함수의 내부로 외부변수가 들어오지 않기 때문\n따라서 Dynamic scope에서는 함수 외부의 변수가 내부로 들어오기 때문에 별도의 메모리를 사용하지 않는다\n\n\n\n\n\nDynamic으로 설계했을 때의 모습이다. 보다시피 e1을 계산할때 메모리가 그냥 [] 이 아니고 시그마가 붙어있는걸 알 수 있다\n졸라 강조하는거 보니 이 둘 개념 시험에 나오겠다 - 그리고 Substitution의 경우에도 Lexical과 Dynamic의 두가지로 모두 설계할 수 있다고 강조하는 거 보니 이거 저거 두개로 치환 구현하는거 시험에 나온다\n\nList of Function §\n\n위에서는 함수가 반드시 하나만 나와야되는 언어를 정의했다 (없어도 안되고 2개이상이도 안됨)\n따라서 이걸 0개 이상의 함수를 지원하는 언어로 바꾸면 다음과 같다\n\n\n\n\n보면 d위에 언더바가 있는데 걍 0개 이상이라는 의미란다\n\n\n\n원래는 (D, FunDef)였는데 (FunDef, D, FunDef)로 바꿈\n\n보면 마지막줄에 기존의 람다에서 새로운 함수선언 d를 추가한 새로운 람다로 계산되는 것을 알 수 있다\n\n\n\n\n\n그리고 이렇게 바꿀 수 있다\n\n\n\n이거 여러번 연습할 것!! - 뒤에 있는 예제도 함께 - ㅈㄴ강조한다 이새끼\n\nList of Parameters §\n\n\n요래 바꾼다\n\n\n\n빨간부분이 바뀐거랜다 - 이제는 매개변수가 Var하나가 아니라 VarList인 것\n\n\n\n저 동그라미부분이 바뀐것으로 저기만 수정해주면 된다\n시험공부할때 예제 다 꼼꼼히 해보면서 막히면 강의 참고해라 - 강의뒷쪽에 많이 나온다\n"}}