{"index":{"title":"매디쏜 디지딸 갈든","links":["os.fall.2022.ewha.ac.kr/(이화여대)-운영체제-강의록","os.spring.2021.cnu.ac.kr/(충남대)-운영체제-강의록"],"tags":[],"content":"\n    \n        \n    \n\n오리지날 씨리즈 §\n\n\n                  \n                  &quot;오리지날 씨리즈&quot; 는 Networked-thought 에 포함되지 않는, 강의 필기록과 같은 Sequential 한 문서를 모아놓는 항목입니다. \n                  \n                \n\n\n(이화여대) 운영체제 강의록\n(충남대) 운영체제 강의록\n"},"os.fall.2022.ewha.ac.kr/(이화여대)-운영체제-강의록":{"title":"(이화여대) 운영체제 강의록","links":["os.fall.2022.ewha.ac.kr/1.-운영체제란","os.fall.2022.ewha.ac.kr/2.-System-Structure-&-Process-Execution","os.fall.2022.ewha.ac.kr/3.-Process","os.fall.2022.ewha.ac.kr/4.-Process-Management","os.fall.2022.ewha.ac.kr/5.-CPU-Scheduling","os.fall.2022.ewha.ac.kr/6.-Process-Synchronize","os.fall.2022.ewha.ac.kr/7.-Deadlocks","os.fall.2022.ewha.ac.kr/8-1.-Memory-Address","os.fall.2022.ewha.ac.kr/8-2.-Physical-Memory-Allocation","os.fall.2022.ewha.ac.kr/9.-Virtual-Memory","os.fall.2022.ewha.ac.kr/10.-File-Systems","os.fall.2022.ewha.ac.kr/11.-Disk-Scheduling"],"tags":[],"content":"Table of Contents §\n\n1. 운영체제란\n2. System Structure &amp; Process Execution\n3. Process\n4. Process Management\n5. CPU Scheduling\n6. Process Synchronize\n7. Deadlocks\n8-1. Memory Address\n8-2. Physical Memory Allocation\n9. Virtual Memory\n10. File Systems\n11. Disk Scheduling\n"},"os.fall.2022.ewha.ac.kr/1.-운영체제란":{"title":"1. 운영체제란","links":[],"tags":[],"content":"운영체제 핵심 §\n\n\n운영체제의 핵심은 컴퓨터의 하드웨어 바로 위에 설치되어 아래로는 하드웨어 자원을 관리하고 위로는 사용자 혹은 사용자 애플리케이션을 위한 편의 기능을 제공하는 것이다.\n\n그래서 그 편의기능이 뭐냐\n사용자로 하여금 내가 실행시킨 프로그램만 실행되고 있게 느끼도록 해주고\n하드웨어를 제어하는 복잡한 작업을 대행하기 때문에 하드웨어에 대한 부분은 사용자가 고려하지 않아도 되게끔 해준다.\n\n\n자원 분배를 할때는 분배의 형평성과 효율성 (주어진 자원 내에서의 최고의 성능) 이 Trade-off 관계에 있게 되는데 운영체제는 이 둘을 적절하게 타협해서 분배를 한댄다\n\n뭐 예를들면 CPU 스케줄링할때 중요한 프로세스에다만 몰빵하면 중요하지 않은 프로세스는 CPU할당을 받지 못하게 되는 이러한 Trade-off\n\n\n\n운영체제, 커널 §\n\n커널은 운영체제의 핵심적인 부분으로 메모리에 항상 상주한다.\n따라서 좁은 의미의 운영체제는 커널만을 칭하고 (협의의 운영체제) 넓은의미에서는 커널 뿐 아니라 주변의 다른 시스템 유틸리티까지 포함한다 (광의의 운영체제).\n\n운영체제의 분류 §\n동시 작업 가능 여부 §\n\nSingle tasking: 한번에 하나의 작업만 처리\n\n일례로 MS-DOS 의 경우에는 한번에 하나의 작업만 처리할 수 있어 명령을 끝내기 전에 다른 명령을 실행시킬 수 없다\n\n\nMulti tasking: 한번에 여러개의 작업 처리\n\n사용자의 수 §\n\nSingle user: 머신을 한 번에 한 명의 사용자만 사용할 수 있는 운영체제\nMulti user: 머신을 한번에 여러명의 사용자가 (원격) 접속하여 사용할 수 있는 운영체제\n\n따라서 Multi user 를 위해서는 사용자 간의 격리를 위한 보안성이나 자원 할당 등의 부가적인 기능이 필요하다.\n\n\n\n작업 처리 형태 §\n\nBatch processing: 이건 작업을 바로 처리하는 것이 아니라 일정량 모아서 한번에 처리하는 형태\n\n따라서 작업을 요청하면 다른 작업이 일정량 모인 후에 실행되고 결과가 나올때 까지 기다려야 했다.\n지금은 거의 안쓰고 옛날 Punch card 같은 처리 시스템에서 많이 쓰였음\n\n\nTime sharing: CPU time을 잘게 쪼개 여러 프로세스를 돌아가며 실행시키는 형태\n\n뭐 지금의 운영체제가 다 그렇지 뭐\n다만 이건 시간상의 제약이 있지는 않다 → 시간을 쪼개 작업을 처리하지만 해당 시간 내에 끝내는 것을 목표로 하지는 않음\n\n\nReal time: 작업의 deadline이 있어 해당 deadline 전까지 작업을 끝마치도록 하는 형태\n\n시간이 중요한 시스템들 (뭐 원자력 제어 시스템이나 미사일 등) 을 위한 시스템\n시간 내에 끝나지 않았을때 진짜 ㅈ되는 것을 위한 것이 Hard realtime system 이고\n시간 내에 끝내야 하긴 하지만 ㅈ되지는 않는것 (뭐 동영상 스트리밍의 경우에는 1초에 24프레임을 불러와야 하니까) 을 위한 게 Soft realtime system 이라고 부르더라\n\n\n\nMulti-어쩌고 §\n\n프로세스를 병렬적으로 처리하는데에는 다음과같은 용어들이 있는데 어느정도는 구분할 수 있어야 한다\n\nMultitasking: 가장 범용적인 (범위가 큰) 용어 → 걍 프로세스가 여러개 작동될 수 있어 하나가 끝나기 전에 다른 하나가 실행될 수 있는 것\nMultiprogramming: 프로세스 여러개가 하나의 메모리에 적재될 수 있는 것\n\n뭐 당연히 Multitasking 을 위해서는 Multiprogramming 이 되어야 하고 어느정도는 Multitasking과 의미가 겹치지만 얘는 약간 메모리 측면을 강조한 용어라고 할 수 있다.\n\n\nTime sharing: 프로세스 여러개가 CPU time을 돌아가며 할당받는 것\n\n이것도 Multitasking 과 개념이 좀 겹치지만 얘는 CPU time을 강조한 용어라고 할 수 있다\n\n\nMultiprocess: 얘는 진짜 Multitasking과 차이가 없는거같은데\nMultiprocessor: 얘는 CPU가 여러개 달린 하드웨어적인 용어이다\n\n일반적으로 Multitasking 이라 할때는 싱글프로세서를 의미한다.\n\n\n\n\n\n운영체제의 구조 §\n\n\nCPU 스케줄링: CPU time 을 언제 누구에게 줄까?\n\n선입선출? 가장 빨리 끝나는 놈부터?\n\n\n메모리 관리: 메모리를 어떤 방식 프로세스들에게 할당해줄까?\n\n메모리를 어떻게 쪼개서 프로세스에게 할당할까?\n만일 메모리가 부족한 경우에 누군가를 디스크로 내보내야 한다면 누구를 내보낼까?\n\n\n파일 관리: 파일들을 디스크에 어떻게 저장해서 어떻게 읽을까?\n\n하나의 덩어리로 저장? 잘라서 저장?\n읽을때는 들어온 요청의 순서대로? 아니면 디스크 헤드랑 가장 자까이 있는 놈부터?\n\n\n입출력 관리: 속도도 느리고 제각각인 입출력장치랑 어떻게 상호작용할까?\n\nInterrupt 방식을 사용 → I/O 작업을 CPU가 계속 신경쓰는 게 아닌 작업이 끝났을 때 인터럽트를 걸어서 그때서야 CPU가 신경쓰도록 하는 방식\n\n\n"},"os.fall.2022.ewha.ac.kr/10.-File-Systems":{"title":"10. File Systems","links":[],"tags":[],"content":"File 이란? §\n\n이름을 통해 접근할 수 있는 정보들의 집합 을 File 이라고 하더라\n일반적으로 너가 아는 것들 이외에도\nLinux 에서는 다양한 장치들도 File 로써 관리된다 → 표준입출력이나 디스크들도 Linux 에서는 파일로 관리된다\n그리고 당연히 디스크같은 비휘발성 저장장치에 저장된다\n\nFile Operation §\n\nCreate, Delete\nOpen, Close\n\n파일의 Metadata 를 메모리에 적재하는 것을 Open\n메모리에서 내려 다시 디스크에 저장하는 것은 Close 라고 한다.\n파일을 읽거나 쓰기 위해서는 반드시 Open 되어있어야 하고 작업이 끝난 이후에는 Close 를 해야 한다.\n\n\nRead, Write\nReposition (lseek)\n\n파일입출력할때 생각해보면 포인터 (커서) 가 있어서 어디까지 읽었는지를 기억하자네\n이 포인터 (커서) 의 위치를 딴데로 옮기는 연산을 Reposition (lseek) 이라 한다.\n\n\n\nFile Metadata (Attribute) §\n\n이름에서 유추할 수 있듯이\n파일 자체의 내용이 아니고 파일의 유형, 크기, 권한 등의 파일을 설명하는 정보들을 File Metadata 혹은 File Attribute 라고 한다\n\nFile System §\n\nFile System 은 당연히 운영체제에서 파일을 관리하는 부분을 의미한다.\n이놈은 파일, Metadata, 디렉토리 계층구조, 저장 방법이나 보안성 부분을 관리한댄다\n\nDirectory, Partition §\n\nDirectory 는 뭐 너가 아는 그 폴더가 맞는데\n\n좀 더 정확하게 정의해보면 거기에 속한 파일들의 메타데이터 전부 혹은 일부를 내용으로 갖고 있는 파일을 Directory 라고 한다\n\n\nPartition 혹은 Logical Disk 는 하드웨어 디스크가 아닌 하드웨어 디스크를 쪼개서 논리적으로 여러개의 디스크를 사용하는 것과 같은 효과를 내게 하는 것을 의미한다\n\n이렇게 파티션을 나눠서 File System 을 설치하거나 Swap area 를 마련하는 등으로 활용한다.\n\n\n\nFile Open Operation §\n\n위에서 잠깐 봤지만 좀 더 깊게 드가보자고\n\n\n\n사용자 프로세스는 /a/b 경로의 파일을 열기 위해 open 시스템 콜을 한다 → 당연히 IO 작업이니까 직접 하지는 못하고 시스템 콜을 사용해야 한다\nFile System 이 Root (/) 에서부터 재귀적으로 파일의 위치를 찾아나가기 시작한다\n\nRoot 디렉토리의 위치는 File System 이 알고 있기 때문에 일단 이놈을 open 한다\nOpen 하게 되면 그놈의 메타데이터가 메모리에 올라가게 되는데, 메모리의 커널 영역 중 Open File Table 이라는 곳에 올라가게 된다\n\nOpen File Table 은 시스템 전체에 대해 열려있는 파일의 메타데이터가 테이블 형식으로 저장되어 있는 메모리의 커널 영역 중 한 부분이다\n\n\nRoot 의 메타데이터를 통해 Root Directory 의 Content 위치를 찾아내게 되고, 여기에는 하위 파일들의 메타데이터가 저장되어 있기 때문에 a 의 메타데이터를 찾아서 마찬가지로 Open File Table 에 올린다 (Open 한다)\nOpen → Content Reference 작업을 반복적으로 수행한다.\n\n즉, a 의 메타데이터를 이용해 a 의 Content 에 접근하고, 여기에서 b 의 메타데이터를 찾아 Open File Table 로 올리며 그것을 이용해 b 의 Content 에 접근한다.\n\n\n\n\n경로의 파일에 접근했다면, 해당 파일의 Content 를 메모리의 커널 영역에 올린다\n\n이 때에는 Open File Table 에 올리는 것이 아니라 열려있는 파일의 내용을 캐싱하는 Buffered Cache 에 올리게 된다\n이렇게 함으로써 프로세스는 디스크가 아닌 메모리에 캐싱되어있는 데이터에 접근하기 때문에 더욱 빠르게 데이터를 읽어올 수 있고\n여러개의 프로세스가 해당 파일을 Open 했을 때에도 디스크 IO 작업이 여러번 일어나는 것이 아니고 캐싱되어있는 데이터가 제공된다 → 즉, 파일을 Open 할 때에는 일단 해당 파일이 Buffered Cache 에 존재하는지 먼저 확인하고 없다면 그때서야 디스크 IO 작업이 이루어진다\n\n\n커널 영역에 올라가 있는 파일 Content 를 사용자 프로세스 영역으로 복사해 그놈이 접근할 수 있게 한다.\n요청한 파일의 File Descriptor 를 반환함으로써 Open 시스템 콜이 완료된다.\n\n옛날에는 File Descriptor 개념이 쬐까 헷갈렸는데 지금 딱 정리해준다\n일단 파일을 Open 했으면 해당 파일의 메타데이터가 Open File Table 에 저장되어 있겠지\n그럼 Open File Table 에 저장되어 있는 메타데이터의 주소를 PCB 에 존재하는 배열중 하나인 File Descriptor Table 에 넣는다\n\n즉, File Descriptor Table 은 해당 프로세스가 Open 한 파일의 Open File Table 내에서의 메타데이터 주소들을 담는 배열이다\n\n\n이때, File Descriptor Table 내에서의 해당 파일에 대한 인덱스 번호를 File Descriptor 라고 하는 것이다\n뭐 옛날에 배운 것 처럼 File Descriptor 0번은 표준 입력, 1번은 표준 출력, 2번은 표준 에러이다 → 프로세스가 실행되면 저 세 파일은 자동으로 열린다는 소리이다\n\n\n\n\n등장한 Table 들을 좀 비교해보면\n\nOpen File Table: 시스템 전체에 대해 열려 있는 파일들에 대한 Table\nFile Descriptor: 프로세스 하나에 대해 그놈이 열어놓은 파일들에 대한 Table\n\n\nFile Offset Table: 이건 파일 하나를 여러 프로세스가 열었을 때 각각 어디를 읽고 있는지가 다를 것이기 때문에 각 프로세스들이 어디를 읽고 있는지를 보관하는 테이블이다\n\nFile Protection §\nAccess Control Matrix §\n\n\nAccess Control Matrix 는 단순하게 어떤 사용자가 어떤 파일에 대해 권한이 있는지를 Matrix 형태로 저장해 놓은 것이다\n하지만 이 방법은 다소 비효율적이다 → 특정 사용자가 권한을 갖고 있는 파일은 한정적이기 때문에 쓸데없는 용량을 많이 차지하기 때문\n따라서 이것을 행 혹은 열 방향으로 Linked List 형태로 관리하기도 한다\n\n특정 사용자가 접근할 수 있는 파일들을 모아놓은 것을 Capability 라고 하고\n특정 파일에 대해 접근할 수 있는 사용자들을 모아놓은 것을 ACL (Access Control List) 라고 한다\n\n\n\nGrouping §\n\n\n하지만 ACM 을 이용하는 방법도 그다지 효율적이지 않다\n따라서 Linux 같은 UNIX 기반의 시스템들은 Grouping 방식을 이용해 접근 권한을 관리한다\n즉, 파일 소유주 (Owner), 일련의 사용자 집합인 그룹 (Group), 모든 사용자 (Public)에 대한 접근 권한을 각각 3비트로 표현하게 된다\n\n뭔지 알제?\n3비트에 대해 첫 1비트는 Read 권한 유무, 두번째 1비트는 Write 권한 유무, 세번째 1비트는 Execute 권한 유무를 뜻한다\n\n\n이렇게 되면 파일의 권한을 단순히 9비트로 표현할 수 있게 되고, 파일 소유주가 아닌 사용자에 대한 권한은 해당 사용자를 그룹에 포함시키거나 Public 권한을 조정함으로써 간편하게 관리할 수 있다\n\nPassword §\n\n뭐 이건 많이 사용되는 방법은 아니고\n특정 파일이나 디렉토리에 암호를 걸어 암호를 맞춰야만 접근할 수 있게 하는 방법이다\n\nMounting §\n\n\n특정 디스크 (파티션)에 대한 접근은 Root 를 통해 할 수 있지만\n다른 디스크 (파티션)에 대한 접근은 특정 디렉토리를 해당 디스크의 루트를 가리키도록 하여 수행할 수 있다 → 이 방법을 Mounting 이라고 하더라\n\nFile Content Access Method §\nSequential Access §\n\nSequential Access (순차 접근) 은 이름에서부터 알 수 있듯이 파일의 내용을 앞에서부터만 순차적으로 읽을 수 있는 방법이다\n즉, ABC 에서 A와 C에 접근하기 위해서는 B 에 무조건 접근해야 한다\n카세트 테이프같은 경우가 이렇다 → 무적권 앞에서부터만 접근해야 되는 놈\n\nDirect Access (Random Access) §\n\nDirect Access (Random Access, 직접 접근) 은 반대로 파일의 내용을 임의의 순서로 접근할 수 있는 방법을 의미한다\n즉, ABC 에서 A에 접근한 이후에 바로 C를 접근하는 것이 가능하다\n이것은 하드웨어적 서포트가 필요하고 그러한 서포트가 있어도 데이터들을 어떻게 저장하냐 따라 순차접근을 해야 할 수도 있다네\n뭐 디스크나 CD, 플래시 메모리 등이 다 지원한다\n\nDisk Allocation Methods §\n\n일단 몇가지 개념들\n\nBlock (블럭) 혹은 Sector (섹터): 디스크에 데이터를 저장하는 단위\n\n\n\nContiguous Allocation §\n\n\n말그대로 파일 하나를 디스크에 연속적으로 저장하는 방법\n장점:\n\n디스크에서 데이터의 위치를 찾은 다음에는 쭉 읽어들이면 되기 때문에 IO 가 빠르다\n\n만약 데이터들이 산발적으로 저장되어 있다면 그들을 모두 찾아야되지만 뭉쳐져있기 때문에 한번만 찾으면 됨\n따라서 IO 속도가 중요한 Realtime File 이나 Process Swapping 등에서 사용될 수 있다\n\n\n데이터가 시작위치부터 연속적으로 존재하기 때문에 Random Access 가 가능하다\n\n시작위치에서 Offset 만 알면 바로 원하는 부분을 찾을 수 있기 때문\n\n\n\n\n단점:\n\n메모리 관리때와 마찬가지로 Hole (혹은 External Fragmentation) 이 발생할 수 있다\n\n파일의 크기와 딱 맞는 공간이 없을 수도 있으므로 남은 만큼은 외부 조각으로 남는 셈\n\n\n파일 사이즈를 키우기 힘들다\n\n파일 하나가 연속적으로 저장되어야 하는데 뒤에 다른 데이터가 존재한다면 파일 사이즈를 키우기 위해서는 뒤에 있는 놈을 재배치하거나 사이즈 키우는 것을 포기해야 한다\n늘어날 수 있는 공간만큼 미리 공간을 선점하게 할 수 있지만 그렇다 하더라고 늘어날 수 있는 파일의 크기는 한정되어 있고 선점된 공간은 Internal Fragmentation 으로 남게 된다\n\n\n\n\n\nLinked Allocation §\n\n\n말 그대로 Linked List 마냥 데이터들을 연결지어놓은 것\n장점:\n\nExternal Fragmentation 이 없다\n\n\n단점:\n\nRandom Access 가 안된다\n\n어떤 특정 섹터에 접근하기 위해서는 무적권 그놈 앞에 있는 섹터들을 모두 방문해야 한다\n\n\nReliability 문제\n\n포인터를 통해 쭉 연결되어있는데 중간에 하나의 섹터에 문제가 생겨서 (Bad Sector) 포인터가 유실되면 그놈 다음에 있는 모든 섹터에 접근할 수 없다\n\n\n공간 효율성 문제\n\n일단 하나의 섹터에 무조건 다음 섹터를 위한 포인터를 저장할 공간이 마련되어야 하고\n일반적으로 섹터 하나는 512 바이트로 구성되어 있는데 이 중 4 바이트가 포인터를 위한 공간으로 사용되어 508 바이트라는 애매한 숫자가 된다 → 알다시피 대부분의 데이터 포맷은 2의 배수 크기를 가지도록 정의되어있는 것이 많은데 512 가 아닌 508 로 하면 좀 애매하다는 얘기인듯\n\n\n\n\n단점 보완\n\n이 방식을 보완한 FAT (File Allocation Table) 파일시스템은 포인터들을 별도의 공간에 모아서 관리하기 때문에 Reliability 와 공간 효율성 문제를 해결한다\n하지만 알다시피 파일의 크기가 커지면 테이블의 크기도 너무 커지므로 FAT 으로 구성할 수 있는 파일의 크기는 한정되어 있다\n\n\n\nIndexed Allocation §\n\n\n이것은 파일이 저장되어 있는 섹터들의 번호 (인덱스) 를 모아놓은 별도의 블럭을 하나 구성하는 방법이다\nFAT 랑 솔직히 뭐가 다른지 잘 모르겠음\n장점\n\n연속적으로 저장하는 것이 아니기 때문에 External Fragmentation 이 발생하지 않는다\n인덱스 블럭을 통해 특정 섹터에 바로 접근할 수 있기 때문에 Random Access 도 가능하다\n\n\n단점\n\n파일 크기가 너무 작은 경우에는 비효율적이다\n\n파일의 크기가 512 Byte 보다 작을 경우에도 최소한 데이터 섹터 하나랑 인덱스 블럭 두개가 필요하다\n\n\n파일의 크기가 너무 커도 문제다\n\n파일의 크기가 너무 커서 하나의 인덱스 블럭에 다 안들어갈 수도 있기 때문\n이때는 인덱스 블럭의 마지막은 다음 인덱스 블럭을 가리키게 하는 방법 (Linked Scheme) 을 이용하던지\n인덱스 블럭을 계층적으로 구성하는 방법 → 인덱스 테이블이 다른 인덱스 테이블들을 가리키게 하는 방법 (Multi-level Index) 를 이용할 수 있다\n\n\n\n\n\nUNIX File System §\n\nBoot Block §\n\nBoot Block: 얘는 UNIX 만의 특징이 아니고 모든 파일 시스템이 파티션 맨 앞에 Boot Block 을 둔다\n\nBoot Loader (Bootstrap Loader) 는 말그대로 컴퓨터가 부팅될때 OS 가 디스크의 어디에 저장되어 있고 어떻게 시스템을 초기화해야할지 등을 알려주는 부분이다\n뭐 요즘 Linux 배포판에는 GRUB 가 부트로더로 내장되어있제\n\n\n\nSuper Block §\n\nSuper Block: 얘는 파티션 전체에 대한 메타데이터라고 생각하면 된다\n\n즉, 어디서부터 어디까지 어떤 정보가 저장되어 있고 (가령 여기부터 여기까지는 Inode List 이다 등)\n비어있는 섹션은 어디이고 사용중인 섹션은 어디인지 등의 정보를 저장함\n\n\n\nInode, Inode List Block §\n\nUNIX 에서 Inode 의 개념은 중요하니까 좀 자세하게 알아보자고\n일단 UNIX 에서 파일의 메타데이터를 어떻게 관리하는지 알아보면\n파일의 이름을 제외한 모든 메타데이터를 Inode 라는 단위로 저장한다\n\n\n\nInode 의 구조는 위와 같다\n\n일단 Mode 부터 Count 까지는 뭐 그냥 파일들의 메타데이터들이고 그 다음부터가 중요한데\nUNIX 는 위에 소개한 Allocation Method 중에서 Indexed Allocation 을 변형한 방법을 사용한다\n그래서 Direct Blocks 부분에 데이터 섹션들의 인덱스를 저장하게 되는데\n파일의 크기가 클 경우를 대비해 3단계까지 Multi-level Index 를 제공한다\n\n즉, Single Indirect 는 인덱스 블럭을 한번 더 거쳐야 데이터가 나오고 Double Indirect 는 두번 더 거쳐야 데이터가 나오며 Triple Indirect 는 세번 더 거쳐야 되는 식\n\n\n\n\n그러면 파일의 이름은 어디에 저장하느냐 → 디렉토리의 내용에 저장된다\n\n즉, 디렉토리는 하위 파일들에 대해 이름과 Inode 번호 두가지를 저장한다\n\n\n\n\n\n이러한 Inode 들이 모두 저장되어 있는 파티션의 한 부분을 Inode List 라고 부른다\n\n헷갈리지 마라 → 파일의 메타데이터는 파일과 함께 저장되어 있는 것이 아니고 별도의 공간에 함께 모여서 관리된다\n\n\n\n(MS) FAT File System §\n\n\n위에서도 언급했듯이 FAT 파일 시스템은 Linked Allocation 의 단점들을 개선한 것이다\nUNIX 와 대조되는 차이점들에 대해 살펴보면\n\n일단 UNIX 와는 다르게 거의 모든 메타데이터가 Directory 에 저장된다\n\nDirectory 에는 추가적으로 파일의 첫 블럭의 포인터가 적혀 있어 파일이 어디서부터 시작되는지 알 수 있게 해놓았다\n\n\nFAT 부분에는 각 파일들의 FAT 정보가 저장되어 있는데, 이 테이블에는 파일을 구성하는 각 블럭들에 대해 다음 블럭의 포인터가 저장되어 있다\n\n마지막 블럭에 대한 엔트리에는 EOF 값이 들어가 있어 더이상 블럭이 없음을 나타낸다\n\n\n\n\n그래서 FAT 파일시스템의 작동 원리에 대해 대략적으로 보면\n\nDirectory 에 적혀있는 포인터를 통해 파일을 읽어나가기 시작한다\n하나의 블럭을 다 읽었다면, FAT 을 보고 다음 블럭의 포인터가 어디를 가리키는지 확인한다.\n위의 과정을 EOF 가 등장할 때 까지 반복한다\n\n\n이렇게 하면 Linked Allocation 이 가지는 단점들을 모두 해소할 수 있다\n\nRandom Access 문제\n\n파일이 열린 다음에는 FAT 이 메모리로 올라오게 되는데\n포인터를 따라갈 때 데이터 블럭을 모두 뒤지는 것이 아니라 메모리 내에 있는 FAT 내부에서만 움직이므로 데이터 블럭에 접근할 필요가 없어 훨씬 빠른 시간에 접근이 가능하다\n\n\nReliability 문제\n\n일단 포인터가 FAT 에 저장되므로 Bad Section 이 일어나도 이후의 데이터에 접근이 가능하고\n고가용성을 위해 FAT 의 복제본을 여러개 유지하기 때문에 FAT 이 망가져도 복구가 가능하다\n\n\n공간 효율성 문제\n\n포인터가 FAT 에 저장되므로 데이터 섹션의 512 바이트 중 일부를 할애할 필요가 없다\n\n\n\n\n\nFree Space Management §\nBitmap (Bit Vector) §\n\n\n뭐 이건 간단하쥬?\n블럭의 크기만큼 비트를 마련한 다음에 해당 블럭이 비었는지 아닌지를 0과 1로 표현하는 방법\n당연히 Bitmap 을 마련해야 하기 때문에 추가적인 디스크 공간이 필요하지만\nContiguous Allocation 이 아니어도 연속적인 Free Space 에 저장하는 것이 IO 에 도움이 되므로 연속적인 Free Space 를 찾을 때 효과적인 방법이다\n\nLinked List §\n\n이건 Free Block 들에 다음 Free Block 의 포인터를 저장해서 링크드 리스트 형식으로 묶어놓은 것인데\n추가적인 디스크 공간이 필요 없다는 점에서는 좋지만\n각각의 블럭들을 모두 방문해야 하기 때문에 연속적인 Free Space 를 찾는 것은 오래걸린다\n\nGrouping §\n\n\n이건 Multi-level indexed 랑 유사한 방법인데\nFree Block 하나에 n - 1 개의 Free Block 포인터를 저장하고 마지막 에는 다음 Free Block Table 을 가리키게 하는 방법이다\n근데 특징은 Linked List 와 유사함 → 추가 공간은 필요없지만 결국 연속적인 Free Space 를 찾는 것은 쉽지 않다\n\nCounting §\n\n이건 연속적인 Free Block 을 쉽게 찾아내기 위해 고안된 방법인데\n일반적으로 Block 이 반납될때는 연속적인 블럭을 반환한다는 성질에서 착안한 방법이다\n따라서 연속적인 Free Block 에 대해 시작 Block 의 포인터와 몇개가 연속되어있는지의 개수를 저장한다\n\nDirectory Implementation §\nDirectory Contents §\n\nLinear List: 디렉토리 아래에 위치한 파일들을 리스트 형태로 저장하는 것\n\n\n\n위에서 보다시피 struct{FNAME, METADATA} 형식의 리스트로 구현한다\n\n당연히 구현이 간편하지만\n파일이 존재하는지 알기 위해서는 선형 탐색을 해야 한다는 단점이 있다\n\n\n\n\nHash Table: 이것은 List 의 인덱스를 결정할때 마지막 인덱스가 아닌 해시 함수를 통해 인덱스를 지정하는 방법이다\n\n\n\n해시 함수를 사용하기 때문에 상수시간의 탐색 시간이 걸리지만\n\n매우 한정된 범위로 해시 함수를 돌려야 하기 때문에 충돌 (Collision) 이 날 수가 있다\n\n이건 뭐 자구시간에 배운것처럼 충돌이 나는 애들만 리스트로 관리하는 방법 등을 사용할 수 있겠제\n\n\n\n\n\nMetadata §\n\n이건 파일들의 메타데이터를 어디에 보관할지에 관한 것인데\n앞에서 배운것처럼 UNIX 에서는 inode 에 따로 보관하고 FAT 에서는 파일 포인터 이외에는 디렉토리에 때려박는다\n\nFilename Support §\n\n일반적으로 struct{FNAME, METADATA} 형식으로 디렉토리 Content 의 Entry 를 저장하게 되는데 이때 각 Entry 의 크기는 고정되어 있다\n이말인 즉슨 파일의 이름의 크기는 일정 크기로 제한되어야 한다는 것인데\n파일의 이름 크기에 제한을 두지 않기 위해 아래와 같은 방법을 사용해서 이름이 긴 파일들을 관리할 수 있다:\n\n\n\n위 그림처럼 파일 이름이 너무 큰 경우에는 잘리는 만큼을 디렉토리의 맨 마지막 Entry 에 모두 때려박고\n\n해당 Entry 의 파일 이름을 저장하는 부분 마지막에 잘린 이름을 가리키도록 포인터를 두는 방법으로 해결할 수 있다\n\n\n\nVFS, NFS §\n\nVFS (Virtual File System) 은 운영체제 간의 상이한 파일시스템을 프로그래머가 고려하지 않아도 되게 하기 위해 고안된 통일된 인터페이스이다\n\n즉, 프로그래머는 이 인터페이스로 파일입출력을 이용하기만 하면 해당 파일을 관리하는 파일시스템에 따라 알아서 내부적인 조작을 해준다는 것\n\n\nNFS (Network File System) 은 알다시피 파일을 네트워크를 이용해 접근할 수 있게 해주는 파일시스템이다\n\n\n\n위 그림으로 좀 자세하게 알아보자고\n\nIO 시스템 콜이 발생하면 일단 VFS 인터페이스를 통해 해당 파일의 IO 작업이 진행되는데\n만일 해당 파일이 로컬에 없고 외부에 있다면 NFS Client 데몬을 이용해 외부에서 갖고오도록 한다\n해당 요청은 RPC → Network → RPC 를 거쳐 실제 파일이 위치한 머신 (서버) 의 NFS Server 데몬에 도달하게 된다\n그럼 NFS Server 데몬은 VFS 인터페이스를 이용해 파일을 읽어서 내용을 보내주게 되는 것\n\n이때 VFS 인터페이스가 왜 사용되는지에 살짝 의구심이 들 수도 있는데 어차피 NFS Server 도 IO 시스템 콜을 할 테니까 당연빠따로 VFS 인터페이스를 거치게 된다\n\n\n\n\n\nCaching §\nPage Cache, Buffer Cache §\n\n일단 개념적인 차이점\n\nPage Cache 는 Swap area 에서 페이지를 메모리에 올릴 때 캐싱을 해서 Swap area 까지 가지 않게 하기 위한 캐시이고\nBuffer Cache 는 파일 IO 에서 한번 읽어온 블럭들을 캐싱해서 다른 프로세스에서의 요청에 조금 더 빠르게 대응하기 위한 캐시이다\n\n\n이외에도 캐시의 크기는 작기 때문에 내용을 교체하기 위한 알고리즘 (Replacement Algorithm) 에서도 차이가 나는데\n\nPage Cache 의 경우에는 이전 강의에서 말한 것 처럼 주소변환이 MMU 에 의해 이루어지므로 페이지 참조 횟수를 알 수 없어 Clock 알고리즘을 사용하고\nBuffer Cache 의 경우에는 파일 IO 라는 것이 결국에는 시스템 콜이기 때문에 운영체제로 제어권이 넘어가 파일 참조 이력을 운영체제가 알고 있다 → 따라서 LFU, LRU 등의 알고리즘을 사용하게 됨\n\n\n\nMemory Mapped IO §\n\nMemory Mapped IO 혹은 Memory Mapped File 은 파일의 일부를 그냥 가상메모리에 매핑시켜서 메모리에의 데이터 변경이 바로 파일입출력과 연동되도록 하는 개념이랜다\n이렇게 작동한다 → 파일의 일부분이 메모리의 페이지에 올라와있어 여기에 변경이 이루어지다가 Swap out 이 되면 Swap area 가 아닌 파일에 내려가 변경부분이 반영이 되고 다시 해당 파일에 접근할때에는 Page Fault 가 발생해서 파일이 페이지로 올라오는 것\n\n따라서 페이지에 접근할때는 커널의 도움을 받지 않아도 된다\n또한 Buffer Cache 의 내용을 복사해오지 않아도 된다는 장점이 있다\n\n\n당연히 처음에는 IO 를 해야 하기 때문에 mmap 이라는 시스템 콜이 최초에 이루어진다\n\n따라서 최초에 Buffer Cache 를 한번 거치게 된다 → MMAP 의 경우에 Page Cache 만 사용하기 Buffer Cache 를 사용하지 않는다고 생각하면 오산낙지다\n\n\nMMAP 을 사용하는 대표적인 케이스는 프로세스의 코드-데이터-스택 구조에서의 코드 부분이다\n\n왜냐면 프로세스의 코드는 변경되지 않기 때문에 굳이 Swap area 로 내리지 않고 실행파일이 위치한 곳으로 내려도 되기 때문\n\n\n\nUnified Buffer Cache §\n\nUnified Buffer Cache 는 Page Cache 와 Buffer Cache 를 분리하지 않고 하나로 합쳐놓은 개념이다\n\n요즘의 운영체제는 모두 이 방법을 이용한다네\n\n\n그래서 파일 IO 를 할 때에도 페이지 단위 (4Kb) 로 캐싱해서 구지 두개를 별도의 모듈로 구성하지 않는다는 느낌인듯\n또한 메모리 영역자체도 구분을 하지 않고 올려놨다가 때에 따라서 파일 버퍼로 사용하던지 아니면 페이지 캐싱을 하는 식으로 운영한댄다\n\n\n\n위 그림이 UBC 를 이용하지 않은 경우와 이용한 경우를 비교한 사진인데\n\n일단 UBC 를 사용하지 않았을때에는\n\n일반적인 파일 IO 의 경우에는 오른쪽의 경로에 따라 Buffer Cache 에 올라갔다가 사용자 프로세스로 복사되는 과정이 이루어지고\nMMAP 을 이용할 경우에는 왼쪽의 경로에 따라 파일이 Page Cache 에 등록되지만 최초에는 파일 IO 를 위해 Buffer Cache 를 거치게 되는 것\n따라서 MMAP 을 사용하든 사용하지 않든 모두 Buffer Cache 를 거치게 된다\n\n\n하지만 UBC 를 사용했을 경우에는\n\n일반적인 파일 IO 에는 별 다를 바 없지만\nMMAP 의 경우에는 Buffer Cache 와 Page Cache 가 구분되지 않기 때문에 최초의 파일 IO 에 의한 캐싱이 마치 Page Cache 로도 사용되어 캐싱이 두번 중복되는 비효율성을 해결한다\nUBC 의 경우에는 동기화 문제를 고려해야 한다\n\nUBC 를 이용하지 않았을 경우에는 하나의 파일을 여러 프로세스가 공유해도 Buffer Cache 를 기반으로 각자의 메모리 공간에 파일이 있지만\nUBC 를 사용하게 되면 공유하는 메모리 공간에 파일이 올라와있는 것과 마찬가지이기 때문\n즉, UBC 의 경우에는 한놈이 MMAP 을 해서 사용하고 있는 파일의 공간 (Page Cache 로 기능) 과 다른 한놈이 MMAP 이 아닌 파일 IO 를 해서 올려놓은 공간 (Buffer Cache 로 기능) 이 같기 때문에 동기화 문제가 발생할 수 있다는 것\n\n\n\n\n\n\n"},"os.fall.2022.ewha.ac.kr/11.-Disk-Scheduling":{"title":"11. Disk Scheduling","links":[],"tags":[],"content":"용어정리 §\nSector, Block §\n\nSector: 디스크에서 정보가 저장되는 가장 작은 단위\n\n하나의 섹터는 Header + Data (512byte) + Trailer 이렇게 세 부분으로 구성되고\nHeader 와 Trailer 에 섹터 번호하고 ECC(Error Correcting Code) 가 저장된다\n\nHeader 와 Trailer 에 드가는 정보는 Disk Controller 가 직접 접근하고 운영하는데\n만약 실제 데이터와 ECC 가 호환되지 않는다면 Bad Sector 로 간주하고 그에 따른 대응을 하게 된다\n\n\n\n\nBlock: 디스크 외부에서 바라봤을 때의 데이터 저장 단위\n\n이게 약간 헷갈릴 수도 있는데\nBlock 들이 디스크 내의 각 Sector 에 매핑되는 식으로 저장된다고 생각하면 됨\n그리고 Block 은 1차원 배열의 형태를 띈다 → Sector 의 경우에는 몇번째 원판의 몇번째 섹터 이렇게 2차원 배열로 생각할 수 있다면 Block 은 이런 물리적인 구분 없이 그냥 쭉 이어서 1차원 배열의 형태를 띈다는 것 → 뭔가 아닌거같기도 하고 확실하지 않음\n\n\n위와 같은 차이점때문에 섹터와 블럭의 사이즈는 같지 않을 수도 있는듯\n\n디스크의 구조 §\n\n\nPlatter: 디스크를 구성하는 각 원판\nTrack: Platter 내에서 같은 반지름을 가지는 Sector 의 집합\n\nCylinder 는 원래 여러 Platter 에 걸친 Track 들을 가상의 원통으로 묶은 것을 의미하는데 뭐 Track 이랑 비슷하게 생각해도 된다\n\n\nArm: 디스크를 읽어들이기 위한 막대\nRead-write Head: Arm 에서 실제로 데이터를 읽어들이는 부분\nSpindle: 디스크를 회전시키는 축\n\nFormatting §\n\nPhysical Formatting (Low-level Formatting): 디스크에 섹터들을 나누는 과정\nLogical Formatting: FAT 같은 파일 시스템을 디스크에 구성하는 과정\n\nPartitioning, Booting §\n\nPartitioning: 하나의 물리 디스크를 여러개의 논리 디스크로 나누는 과정\nBooting: 컴퓨터를 초기화하는 과정\n\n부팅은 다음과 같은 순서대로 일어난다\n\nROM 에서 Small Bootstrap Loader 를 실행시킨다\n\n메모리는 기본적으로 휘발성이지만 비휘발성의 아주 작은 공간인 ROM 이 존재한다\nCPU 는 메모리에밖에 접근할 수 없기 때문에 ROM 에 있는 부트로더를 실행함\n이놈은 Small Bootstrap Loader 라고 불리는데 이건 부팅을 시작하기 위한 기본적인 코드인 디스크에서 부트로더 전체를 메모리에 올리도록 하는 코드가 들어있다\n\n\nSector 0 에서 Full Bootstrap Loader 를 가져와서 실행\n\n위에서 SBL 이 부트로더 전체를 메모리에 올리는 역할을 한다고 했자네\n이때의 부트로더를 Full Bootstrap Loader 라고 하고 이것은 Sector 0에 저장되어 있다\nSector 0은 디스크에서 가장 최외각 트랙의 첫번째 섹터로 무적권 FBL 가 저장되도록 예약되어 있다\n\n\n\n\n\n\n\nDisk Access Time §\n\n디스크에서 데이터를 읽어오는 과정은 아래와 같이 세 부분으로 나눌 수 있다\n\nSeek Time: 디스크의 암(헤드)을 데이터가 위치한 실린더로 움직이는데 걸리는 시간\nRotational Latency: 암이 제대로 위치한 뒤에 디스크가 회전해 원하는 섹터가 헤더 위로 회전해오는데 걸리는 시간\nTransfer Time: 실제 데이터의 전송 시간\n\n\nDisk Bandwidth: 단위 시간동안 전송된 바이트의 수\n디스크에서 데이터를 읽어올 때 가장 오래 걸리는 것은 Seek Time 이고 Disk Bandwidth 를 극대화 하기 위해 섹터를 읽는 순서를 최적화하는 작업을 Disk Scheduling 이라고 한다\n\nDisk Scheduling §\n\nDisk Bandwidth 를 최대화 하기 위해서는 Seek Time 을 최소화 해야 한다고 했으므로 요청된 섹터들의 트랙 (실린더)를 기준으로 어떤 섹터를 먼저 읽을 지 결정한다\n\nFCFS (First Come First Service) §\n\n\n딱히 뭐 설명할 것도 없다\n그냥 무지성 선입선출\n당연히 비효율적이어서 안쓴다\n\nSSTF (Shortest Seek Time First) §\n\n\n이건 현재 헤드의 위치를 기준으로 가장 가까운 놈부터 처리하는 방식인데\n예상하듯이 Starvation 문제가 발생한다 → 한곳에 요청이 몰리면 그와는 멀리 있는 요청은 계속 순위가 밀리기 때문\n\nSCAN (+ C-SCAN, N-SCAN) §\n\n\nSCAN 은 기본적으로 다음과 같이 작동한다\n\n헤드가 디스크의 끝(최외각 혹은 최내각) 트랙으로 움직인다\n헤드가 반대쪽 끝으로 움직이면서 경로 상에 있는 요청들을 처리한다\n2번 과정을 반복한다\n\n\n따라서 가장 기본이 되는 SCAN 은 아래 그림 한장으로 설명된다\n\n\n\n\n\n보면 약간 엘리베이터와 비슷하기 때문에 엘리베이터 스케줄링이라고도 부른다\n\n이 방식은 Seek Distance 로 최적화 할 수 있고 Starvation 도 안생기는 장점이 있지만\n트랙의 위치에 따라 대기시간이 고르지 않다는 문제가 있다\n\n헤드가 한번 끝에서 끝까지 움직이는데 10초의 시간이 걸린다 하면\n가운데 트랙의 경우에는 가장 오래 걸려도 헤드가 절반을 움직이고 또 절반을 되돌아오면 되기 때문에 10초가 걸리지만\n외곽에 있는 트랙의 경우에는 헤드가 한번 쭉 움직이고 또 반대방향으로 쭉 되돌아와야 하기 때문에 최대 20초가 걸릴 수 있다\n\n\n\n\n위와 같은 문제를 해결하기 위한 SCAN 의 변형이 C-SCAN 이다\n\n헤드가 디스크의 끝(최외각 혹은 최내각) 트랙으로 움직인다\n헤드가 반대쪽 끝으로 움직이면서 경로 상에 있는 요청들을 처리한다\n위 과정을 반복한다\n\n\n보면 그냥 SCAN 과의 차이점은 3번 과정인데 그냥 SCAN 의 경우에는 양방향에 대해 경로상의 요청을 처리하지만\nC-SCAN 의 경우에는 단방향에 대해 요청을 처리한다 → 즉, 한쪽 방향으로 움직일 때만 요청을 처리하고 반대방향으로 되돌아 갈 때는 요청을 처리하지 않고 그냥 움직인다는 것\n따라서 아래의 그림으로 한장 정리가 가능하다\n\n\n\n\n\n따라서 이 방법을 사용하면 기존의 SCAN 방식에 있던 대기시간 불균형을 해소할 수 있다\nSCAN 방식의 변형 중에는 N-SCAN 이라는 놈도 있는데\n\n얘는 SCAN 과 유사하지만 이동중에 들어온 요청에 대해서는 경로상에 있어도 처리하지 않는다는 차이점이 있다\n즉, 한 방향으로 이동하기 전에 들어온 요청에 대해서만 이동하면서 처리하고 이동하는 중간에 들어온 요청은 지금 처리하지 않고 다시 반대방향으로 되돌아갈 때 처리한다는 입장임\n\n\n\nLOOK (+ C-LOOK) §\n\n\n위그림은 C-LOOK 이다\nSCAN 과 LOOK 의 차이점은 헤드가 어디까지 움직이냐에 달려 있다\n\nSCAN 의 경우에는 무조건 최외각-최내각에서 방향 전환을 하는 반면\nLOOK 의 경우에는 해당 방향에 더 이상 요청이 없으면 방향 전환을 한다\n즉, 트랙이 199까지 있을 때 요청된 트랙의 가장 큰 값이 180이면 SCAN 은 (오름차순일 때) 180 을 들르고 199를 간 다음에 내려가는 반면 LOOK 의 경우에는 180 을 들른 다음에 바로 내려간다\n\n\nSCAN 과 C-SCAN 의 차이와 동일하게 LOOK 과 C-LOOK 은 양방향이냐 단방향이냐의 차이밖에 없다\n\nDisk Scheduling Algorithm 의 특징 §\n\n일단 보통 SCAN 이나 LOOK 계열의 스케줄링 방식을 사용하고\n그리고 필요한 경우 쉽게 교체될 수 있도록 OS 와 별도의 모듈로 내장된다고 한다\n실제 Disk Bandwidth 는 이러한 알고리즘적 측면 외에도 파일을 어떤 방식으로 저장할지도 큰 영향을 끼친다고 한다 (연속 할당? 분할 할당?)\n\nSwap Area Management §\n\n일단 디스크를 사용하는 이유를 보면\n\n메모리의 경우에는 휘발성이기 때문에 비휘발성의 데이터 저장 장치가 필요했고\n메모리보다 저렴하되 메모리의 역할을 보조해줄 수 있는 저장장치가 필요하기 때문이다\n\n\n위 이유 중 두번째를 위한 것이 앞에서도 계속 나온 Swap Area 인데 어떻게 관리되는지 대강 알아보면\n\n\n\n뭐 요즘 우분투는 그냥 파티션 안쓰고 파일시스템으로 스왑영역을 관리하지만 디스크를 파티션해서 Swap Area 를 지정해 주는 것이 많이 쓰였다고 하더라\n\n일반적인 파일 시스템과 Swap Area 의 차이점은\n\n일단 파일보다 훨씬 더 빈번하게 참조되고\n메모리를 대체하는 공간이기 때문에 데이터들이 임시적이다 → 잠깐 머물렀다가 프로세스가 종료되면 사라지기 때문\n따라서 공간 효율성보다는 속도 효율성이 훨씬 중요하고 일반적으로 데이터를 나눠 저장하는 것이 아닌 한 덩어리로 저장 (Sequential Allocation) 하게 되고 블럭의 크기도 512바이트가 아닌 512Kb 등의 훨씬 큰 사이즈를 갖게 된다\n\n\n\n\n\nRAID §\n\n\nRAID (Redundant Array of Independant Disks): 는 디스크 여러개를 묶어서 고가용성과 속도 등의 이점을 얻고자 하는 방법이다\nInterleaving, Striping (분산 저장): 여러개의 디스크에서 데이터를 부분적으로 병렬적으로 읽어옴으로써 속도를 향상시키는 방법\nMirroring, Shadowing (중복 저장): 여러개의 디스크에 데이터를 중복해서 저장해서 Disk Failure 등의 문제 상황을 방지하는 방법\n\n단순히 중복해서 저장하는 것만이 아니고 Parity (에러 탐지 코드) 도 추가적으로 구성하기도 한다\n\n\n"},"os.fall.2022.ewha.ac.kr/2.-System-Structure-&-Process-Execution":{"title":"2. System Structure & Process Execution","links":[],"tags":[],"content":"System Structure §\n\n\nCPU + Memory = Computer\n나머지 디스크 키보드 등은 IO Device 라 부른다.\nMemory 는 CPU 의 작업공간이라 할 수 있음 → Instruction들을 하나씩 메모리에서 읽어다 실행시키게 됨 → PC가 메모리의 주소를 가리키기 때문\n\nCPU의 유일한 업무는 PC가 가리키는 Instruction을 가져와서 실행시키는 것 밖에는 없다.\n\n\nDevice controller: 각 device들을 관리하는 작은 CPU같은놈\n\nDevice controller 는 제어정보를 위한 Control register와 Status register 도 추가적으로 가진다\n또한 정보를 임시적으로 저장하기 위한 Buffer 도 존재함 → Local buffer\n\n이 Local buffer 에는 CPU(근데 대부분 DMA Controller) 가 접근해서 IO처리가 끝난 데이터들을 가져온다.\n\n\n근데 이제 Device controller 가 실행해야 되는 Instruction은 어떤 형태로 제공되느냐\n니가 많이 들어봤던 펌웨어 가 이러한 역할을 해준다 → 펌웨어가 약간 디바이스의 OS라 할 수 있는거지\nDevice driver: 컨트롤러가 하드웨어였다면 얘는 소프트웨어다 → 각 장치별 처리 루틴을 담은 OS 의 코드 일부분\n\n펌웨어는 실제로 디바이스 컨트롤러가 실행하는 Instruction이고 Device Driver 는 CPU가 실행하는 디바이스를 관리하기 위한 Instruction 이라는 차이가 있더라\n\n\n\n\nMode bit: 현재 실행중인 Instruction이 User mode 인지 Kernel mode 인지를 저장하는 플래그\n\n일반 사용자 프로세스가 시스템적으로 중요한 작업을 직접 할 수 없도록 하드웨어적으로 막아놓음\n0: 모니터(커널, 시스템) 모드 → 보안을 해칠 수 있는 중요한 명령어(Previleged instruction)들을 수행할 때\n1: 사용자 모드 → 일반 사용자 프로세스가 사용할 수 있는 안전한 명령어\nOS로 전환되기 전에는 해당 플래그가 0으로 바뀌고 다시 사용자 모드로 가기 전에는 1로 바뀐다.\nMode bit 이 1일때는 특정 프로세스의 메모리 공간밖에 접근할 수 없고 0일때는 모든 메모리 공간에 접근할 수 있다더라\n\n\nInterrupt line: IO 등의 인터럽트들이 들어오는 통로\n\nCPU는 메모리랑만 작업하고 그 외의 것들에는 관여하지 않는다\n따라서 IO 등의 작업이 필요할 경우에는 해당 작업을 Device controller 등에게 위임한 뒤 다시 메모리에 있는 Instruction들을 실행한다.\n만일 Device controller 가 작업을 마치게 되면 그때 인터럽트를 걸게 되는데\nCPU는 Instruction 하나를 실행한 이후 매번 Instuction line 을 체크해서 들어온 인터럽트가 있는지 확인하고\n인터럽트가 있으면 해당 인터럽트를 먼저 처리하게 된다\n얘는 소프트웨어적으로 큐형식으로 작동한다기보다는 하드웨어적 버스로 구성되어 전기신호를 보냄으로써 인터럽트가 걸리게 하는거 같다 → 근데 확실하지는 않음\n\n\nTimer: 프로그램의 CPU time을 재는 타이머\n\n프로그램이 IO 등을 만나면 이거때문에 더이상 해당 프로세스에서는 작업하지 못하므로 제어권이 딴놈에게 넘어가지만\n만일 IO가 안일어나면 이놈만 CPU를 잡아먹고있는 Monopolize 가 발생한다\n따라서 Context switching 이 일어나기 전에 Timer를 설정해놓고 실행하다가 타이머가 종료되면 Timer 인터럽트를 걸어 딴놈으로 옮겨갈 수 있도록 함\n\n\nDMA(Direct Memory Access): IO 디바이스에 의한 인터럽트는 생각보다 빈번하게 발생하기 때문에 매번 CPU에 인터럽트를 걸면 경장히 비효율적이다.\n\n따라서 저 DMA라는 놈이 중간다리 역할을 하게 되는데\n이름에서부터 알 수 있듯이 얘도 CPU와 마찬가지로 메모리에 접근할 수 있다.\n따라서 인터럽트가 발생할때마다 CPU대신 이놈이 메모리에 적재를 해주고\n몇 바이트 수준이 아닌 블럭 단위의 좀 많이 데이터가 모이면 그때 한번에 인터럽트를 걸어서 CPU가 알 수 있도록 해준다.\n근데 메모리에 CPU랑 DMA가 같이 접근하게 되면 동기화 문제가 발생하기 때문에\nMemory controller 가 마치 세마포마냥 접근을 중재해주게 되는 것이다.\n\n\n\nTrap, Syscall, Exception §\n\n프로세스는 IO 등의 커널 함수가 필요하면 직접 실행하거나 OS가 먼저 해주는게 아니라 프로세스가 OS에 요청하는 식으로 작동한다.\n왜냐면 사용자 프로그램이 실행되고 있을때는 Mode bit 이 1이기 때문에 권한이 없어 메모리의 커널 영역으로 점프하지 못하기 때문\n따라서 일반적인 함수나 분기, 반복과는 다른 방식으로 작동한다.\n사용자 프로세스는 커널 함수를 요청하기 위해 일종의 인터럽트를 걸어 해당 함수가 실행될 수 있도록 하는데 → 이런 인터럽트를 거는 과정 덕분에 Mode bit 이 0으로 바뀔 수 있고 따라서 커널 영역의 Previleged Instruction들을 실행할 수 있더라.\n이렇게 사용자 프로세스가 커널 함수를 호출하는 것을 **Syscall(System call)**이라고 한다.\n사용자 프로세스가 인터럽트 비스무리한걸 거는 경우가 한가지 더 있는데 바로 어떤 값을 0으로 나누려 하는 경우 등의 Exception 이 발생했을 때이다.\nSyscall하고 Exception을 합쳐서 사용자 프로세스가 거는 인터럽트 비스무리한걸 Trap 혹은 Software Interrupt 이라고 하더라\nSyscall 또한 어찌보면 사용자가 요청하는 커널 함수이기때문에 올바른 요청이냐에 대한 검증이 선행된다.\n그니까 대략 이런식으로 움직임 → IO 의 경우 예시임\n\nIO가 필요할 때 프로세스(A)는 해당 기능을 호출한다. (Syscall - Software Interrupt)\nOS가 CPU를 차지하며 해당 Device controller 에게 일을 시킨다.\n다른 프로세스(B)로 CPU가 전환\nIO 작업이 끝나면 해당 Device controller 에 의해 IO 인터럽트 발생 (Interrupt - Hardware Interrupt)\n그러면 DMA가 Device 에 있던 Buffer에서 데이터를 가져다가 메모리에 적재하고 즉당한 시점에 CPU에 인터럽트를 건다\nCPU 가 다시 OS로 전환되며 해당 인터럽트를 처리\nIO 인터럽트때문에 멈춰있던 프로세스(B)로 CPU가 넘어오며 진행 → 무조건은 아니고 일반적으로는 거렇다더라\nIO를 요청한 프로세스(A)로 CPU가 넘어오며 다시 작업 진행\n\n\n\nInterrupt Handling §\n\nInterrupt Service Routine: 얘는 특정 인터럽트가 걸렸을때 실행되는 Instruction 모음이다. = 해당 인터럽트를 처리하는 커널 함수\nInterrupt Vector Table: 얘는 위의 ISR들에 대해 인터럽트 번호-ISR 주소(위치) 를 매핑시켜놓은 테이블이다\n\n이것 덕분에 특정 인터럽트가 발생했을 때 그걸 처리하는 ISR이 어느 위치에 있는 지 알 수 있게 되고 해당 ISR 이 실행되게 되는 거다.\n\n\n\nSynchronous, Asynchronous IO §\n\n\n얘는 뭐가 좋고 뭐가 나쁘고가 아니고 걍 구현방식의 차이인데\n먼저 Synchronous IO 는 IO요청을 한 다음에 해당 IO가 끝날때까지 요청한 프로세스는 기다리다가 IO 인터럽트가 걸리면 그제서야 다시 프로세스가 재개되는 방식이고\nAsynchronous IO 는 끝날때까지 기다리지 않고 요청하는 작업을 끝내자마자 요청한 프로세스로 돌아갔다가 나중에 IO 인터럽트가 걸리면 데이터를 가져와서 계속 일하는 방식이다.\n일반적으로는 Synchronous 의 경우에는 읽기 작업에 많이 사용된다 → (보통은) 데이터를 읽어들인 다음에 그 데이터를 가지고 계속 작업하는 것이 순리이므로\n그리고 Asynchronous 는 쓰기 작업에 많이 사용된다 → (보통은) 데이터를 화면이나 디스크에 쓴 다음에는 프로세스에서 해당 데이터를 쓸 일이 많지 않기 때문\n물론 뭐 정해진건 아니다 → 읽기 요청도 Asynchronous 로 구현하거나 쓰기 요청도 Synchronous 로 할 수도 있다\n\nImplementation of Synchronous IO §\n\nSynchronous IO 는 구현방법이 2가지 인데 보통 후자의 방법으로 많이 한다.\n먼저 첫번째는 IO가 끝날때까지 Busy waiting을 하는 방법이다 → 즉, IO가 끝날때까지 CPU가 해당 프로세스와 함께 대기하는 방법\n\n하지만 당연하게도 이 방법은 비효율적이다\n비싼 자원인 CPU가 놀고 있다는 점에서도 그렇고\nIO가 하나 걸리면 딴거를 못하니까 IO 요청도 한번에 하나밖에 못하기 때문\n\n\n그래서 두번째 방법은 해당 프로세스로 CPU time 을 주지 않는 방법이다\n\n이렇게 하면 해당 프로세스가 어차피 실행되지 않기 때문에 자동으로 대기상태가 되는 효과가 있고\nCPU가 다른 프로세스로 옮겨가기 때문에 CPU time을 낭비하지도 않으며\n다른 IO syscall이 들어와도 일 시켜놓고 또 다른 프로세스로 넘어가면 되기 때문에 IO 요청도 여러개 받을 수 있다.\n\n\n\nIO Instruction Type §\n\n\nIO를 하는 방법에는 두가지가 있는데\n위 그림에서 왼쪽이 일반적인 상황으로 메모리에 접근하는 명령어와 디바이스에 접근하는 명령어(Special Instruction)가 별개로 존재하여 사용하는 방식과\n오른쪽처럼 각 디바이스들을 메모리처럼 취급해서 확장 메모리 주소를 붙인 다음 메모리 접근 명령어를 그대로 사용하는 방식이 있다 → 이 방식을 Memory Mapped IO 라고 부르더라\n\nMemory Hierarchy §\n\n\nPrimary: 레지스터, 캐시(S-Memory), 램(DRAM) → 빠르고 비싸고 (따라서 용량이 작고) 휘발성이고 바이트단위로 접근이 가능해서 CPU가 실행시킬 수 있고 (Executable)\nSecondary: 느린 대신 싸고 (용량 크고) 비휘발성이고 바이트단위가 아닌 섹터 등의 단위로 접근할 수 있어서 CPU는 실행시킬 수 없다.\n메모리에 접근하는것도 10개 정도의 Instruction이 소요되기에 이를 보완하기 위해 캐쉬 메모리를 두는거고\n재사용의 목적으로 처음에 접근할때는 물론 오래 걸리지만 한번 접근해서 캐쉬에 올려놓고 나서는 그 다음부터는 아래까지 안내려가도 되기 때문에 훨씬 빠르게 사용할 수 있음 → 이런거를 캐싱이라 한댄다.\n\nProgram Execution §\n\n\n뭐 옛날에 배운것처럼 프로그램이 메모리에 올라가서 실행가능한 상태가 되었을때는 프로세스라고 하는데\n메모리에 올라가기 전에 한 단계를 더 거친다 → Virtaul Memory 할당\n이건 다음과 같은 식으로 이루어진다\n\nVirtual Address Space 할당 → 프로세스 하나마다 주소 0부터 시작하는 가상의 메모리 공간을 할당하고\n\n이 가상 메모리 공간에는 많이 들어봤던 Code, data, heap-stack 이 드간다\n\n\nAddress translation 을 통해서 가상 메모리 공간을 실제 메모리에 할당한다.\n\n근데 가상 메모리 공간이 실제 메모리에 할당될때는 연속적인 공간에 할당되는게 아니고 쪼개서 당장 필요한것만 메모리에 올려놓고 나머지는 디스크의 Swap area 로 다시 내려놓았다가 사용할 일이 있으면 그때 가져오는 방식으로 작동함\n\n\n\n\n\nKernel §\n\n\nKernel 이 차지하는 메모리 공간도 당연히 Code, Data, Stack의 형태로 구성된다\n뭐 Code 에는 자원 관리나 인터럽트 처리하는 코드 및 편의기능이 드가있고\nData 에는 CPU, 메모리, 디스크를 관리하기 위한 자료구조들과 PCB가 적재된다\n\n다음시간에 배우겠지만 프로세스가 하나 실행되면 해당 프로세스의 상태같은 제어정보를 담기 위한 자료구조가 하나씩 생성되며 이들을 PCB(Process Control Block)이라고 부른다.\n\n\nStack에는 위 그림에서는 좀 헷갈리게 이름이 붙여져 있지만 결국에는 커널도 여러개의 함수로 구성되어있기 때문에 커널 함수가 실행될때마다 스택에 쌓이게 된다\n\n즉, 어떤 프로세스가 어떤 함수를 호출하면 그때 스택에 ~프로세스가 호출한 ~함수 의 형식으로 스택이 쌓이게 되는 거다\n따라서 커널은 프로세스별로 스택을 만들어서 특정 프로세스가 호출한 커널 함수 정보를 관리한다.\n\n\n\nFunctions §\n\n함수는 고급 언어 수준 뿐만 아니라 어셈블리어에서도 존재한다 → 어떤 언어로 코드를 작성해도 컴파일 이후에는 결국에는 걔네들이 다 함수형태로 바뀌게 된댄다\n함수에는 세가지 분류가 있다\n사용자 정의 함수: 말그대로 사용자가 정의한 함수\n라이브러리 함수: 사용자가 정의한 게 아니고 다른 사람이 라이브러리로 만들어놓은 함수\n\n라이브러리 함수도 당연히 컴파일 이후 바이너리에 함께 들어있게 되고\n따라서 프로세스가 된 이후에 일반 프로세스의 Code 공간에 존재하게 된다.\n\n\n커널 함수: 커널 프로그램의 함수\n\n이 함수를 호출하는게 결국에는 Syscall 인거고\nSyscall 이 필요한 이유를 좀 다른 관점에서 보면 Virtual memory에서 Address space 는 프로세스마다 갖고 있고 Address jump는 해당 Address space 내에서만 가능하기 때문에 다른 Address space 에 속하는 커널 함수로는 점프할 수가 없어서 Syscall 이 필요한 거라고 볼 수도 있다.\n\n\n\n\n\n그래서 프로세스 하나와 커널과의 상호작용만 보면 (Time sharing 같은거 다 빼고)\n사용자 함수나 라이브러리 함수가 실행될때는 해당 프로세스의 주소공간에서 User mode(Mode bit 1) 로 작동하다가\nSyscall이 발생하면 Kernel mode(Mode bit 0) 으로 변경되어 커널 함수가 실행되는 것이다.\n"},"os.fall.2022.ewha.ac.kr/3.-Process":{"title":"3. Process","links":[],"tags":[],"content":"Process and Context §\n\n일단 뭐 프로세스는 Program in Execution 을 의미한다.\n여기서 이제 프로세스의 문맥(Context) 가 중요한데\n이건 특정 프로세스가 어느 한 시점에 어떤 상태인지를 나타내는 정보라고 생각하면 된다\n다음과 같이 세개로 분류해볼 수 있다\n\nCPU 상태( → 레지스터 상태): PC 나 다른 레지스터에 어떤 값이 들어와있었나\nMEM 상태: Code 부분에는 어떤 것들이 담겨있고 Data의 변수들에는 어떤 값이 들어있고 Stack에는 어떤 함수 호출이 쌓여있는지 등등\nKernel 상태: 프로세스를 제어하기 위한 정보인 PCB에 어떤 값이 들어가있는지 혹은 해당 프로세스가 어떤 Syscall 을 호출해서 어떤 커널 함수들이 Kernel stack에 쌓여있는지\n\n\n프로세스의 상태 관리가 필요한 이유는 Context switching 때문이다 → Time sharing등을 위해 실행중인 프로세스를 바꾸려면 실행중이던 프로세스의 상태를 완전히 백업하여 백업된 Context 를 다시 불러왔을 때 이전에 실행중이던 상태 그대로 재개되어야 하기 때문시\n\n5 State Process Model §\n\n\n우리 빵효경 교수님은 5 State Process Model 로 설명을 한다\n5가지 상태중에 중요한건 가운데에 3가지인 Running, Ready, Waiting(Blocked) 인데\nRunning 은 CPU를 할당받아 한창 실행이 되고 있는 상태고\n\n위 그림에서 보이는것처럼 Running 상태가 끝나는건 3가지 경우가 있다\n타이머 종료\n프로그램 종료 (Exit)\n이벤트 발생 → 자발적 CPU 반납\n\n\nReady 는 다른건 다 준비됐고 CPU만 할당받으면 다시 실행할 수 있는 상태를 의미한다\n\n얘는 위 그림에서 보이는것처럼 프로세스가 생성되어 CPU만 받으면 되는 상태까지 오거나\nRunning 상태였다가 Timer 가 끝나서 CPU를 뺏겼거나\nBlock 을 먹었다가 Event 가 종료되어 다시 준비완료\n\n\n그리고 Blocked 는 Syscall 등의 이벤트에 의해 지금 당장 CPU를 할당해주어도 실행할 수 없는 상태를 의미한다\n\n여기서 이벤트는 IO 같은 Syscall 혹은 Interrupt 일 수도 있지만\n조리퐁같은 경우에도 이벤트가 된다 → 다른 쓰레드가 이미 공유 데이터를 쓰고있어서 현재 프로세스가 접근할 수 없는 경우에도 이벤트라고 말할 수 있다\n\n\n\nPCB (Process Control Block) §\n\n\n앞에서도 누누이 말했듯 커널에 저장되어 프로세스를 제어하기 위한 정보가 PCB (Process Control Block) 이고\n4개정도의 파트로 이루어진다\nOS 관련 정보에는 (1) 프로세스의 상태 (2) PID (3) 스케줄링 정보와 (4) 우선순위 정보가 드가고\nCPU 관련 정보에는 PC를 포함한 레지스터의 값들\nMEM 관련 정보에는 해당 프로세스의 Code, Data, Stack 의 위치 (메모리 주소) 정보\nFile 관련 정보에는 이놈이 열어놓은 파일 디스크립터들이 드간다.\n\nContext Switch §\n\n\nContext Switch 는 한 프로세스에서 다른 프로세스로 CPU 를 바꿔주는 과정인데\n다음과 같은 과정을 거친다\n\nA(중고)의 문맥 (PC, Reg, MEM 등) 을 전부 A의 PCB에 때려넣는다\nB(새삥)의 PCB에서 이전 문맥을 가져다가 전부 세팅을 한다\n\n\n근디 중요헌건 Context switch는 사용자 프로세스가 교체되었을 때에만 Context switch 라고 한다는 것이다.\n아래 그림 봐봐라\n\n\n\n(1) 같은 경우에는 Interrupt 혹은 Syscall 이 일어나서 ISR 이나 Syscall func 가 싱행된 후에 다시 원래 프로세스로 돌아왔다 → 이경우에는 Context switch 라고 하지 않는다 이거야\n\n일반적으로는 굳이 프로세스 교체가 필요하지 않은 이벤트의 경우에는 Context switch가 일어나지 않고 원래놈으로 되돌아온다\n\n\n하지만 (2) 같은 경우에는 이건 못참지\n\nTimer interrupt의 경우에는 의도적으로 프로세스를 교체하기 위한 거고\nIO 의 경우에도 오래걸리기 때문에 거의 대부분 프로세스가 Block 된다\n즉, 이런 경우에는 원래의 프로세스로 되돌아갈 수 없기 때문에 새로운 프로세스가 굴러들어오고, 따라서 Context switch 가 되었다고 표현한다.\n\n\n이건 사용자 → 커널 전환보다 사용자 → 사용자 전환이 훨신 오버헤드가 크기 때문이랜다\n\n예를들면 캐쉬를 비우는 Cache flush 의 경우에는 사용자 → 커널 전환에서는 완전 싹 비울 필요가 없기 때문에 이거로 인한 오버헤드가 현저히 적어진댄다\n\n\n\nProcess Queues §\n\n\n프로세스의 상태를 관리하기 위해 위처럼 Process Queue 가 소프트웨어적으로 구성되어있다\n하지만 프로세스는 선입선출로 관리되지 않기 때문에 아마 우선순위큐로 구현이 되어있지 않을까 싶은데\n어쨋든 대기 상태 큐인 Ready Queue하고\nBlock 먹은 이후 각 디바이스에서의 처리를 기다리는 Device Queues 가 있댄다\n마지막으로 모든 프로세스를 담는 Job Queue 가 존재한다\n그리고 큐에 들어가는 각각의 원소들은 PCB로\n아까 PCB의 그림에서 보면 PCB에 Pointer field 가 존재하는데 이걸 통해 각각의 PCB 들이 큐의 형태로 연결되어있게 된댄다\n\nScheduler §\n\nShort term scheduler(→ CPU Scheduler): 어떤 프로세스에게 CPU를 줄지 말지 결정하는 스케줄러\n\n즉, Ready queue 에 있는 프로세스들 중 어떤넘을 Running 으로 바꿀지 결정한다\n프로세스는 아주 찰나의 순간만 CPU를 잡고 있다가 쫒겨나므로 매우 빈번하게 Scheduling 이 발생한다 → 따라서 이름이 Short term 인 것임\n\n\nLong term scheduler(→ Job Scheduler): 어떤 프로세스에게 메모리를 줄지 말지 결정하는 스케줄러\n\n즉, New 상태에 있는 프로세스들 중 어떤놈을 Ready로 바꿀지 결정한다\n이건 Multiprogramming level 을 결정하는데에 아주 중요한 역할을 한다\n\n메모리에 너무 적은 프로세스가 올라가면 CPU가 비효율적이고 반대로 너무 많은 프로세스가 올라가있어도 중요한 부분이 메모리에 올라가지 못하기 때문에 IO가 너무 많이 일어나 CPU가 비효율적으로 작동한다\n따라서 Degree of Multiprogramming 을 제어할 필요가 있고 이것 제어하는게 Long term scheduler 인 것\n\n\n하지만 요즘의 Time sharing system에서는 사용하지 않고 일단 전부 Ready 로 박는다 → 이유는 바로 다음의 스케줄러가 존재하기 때문\n\n\nMedium term scheduler(→ Swapper): 어떤 프로세스를 스왑할지 결정하는 스케줄러\n\nLong term scheduler 가 사용되지 않는 대신 이놈이 Degree of Multiprogramming을 관장한다.\n즉, 프로세스 몇개가 메모리에 올라갈지 결정하는 것을 메모리에 적재될 시점부터 정하는게 아니고 적재한 다음에 결정하겠다는 소리임\n얘를 이용해 일단 프로세스가 생성되면 무적권 Ready 박고 Multiprogramming level 이 너무 높아지면 이 스케줄러를 이용해 프로세스 몇개를 디스크로 방출시켜서 낮추는 방식으로 작동한다더라\n\n\n\n7 State Process Model §\n\n\n일단 먼저 주의할점은 맨 위에 Running 두개는 사실 하나의 상태라는 점이다\n\n프로세스의 상태를 논할때는 무적권 사용자 프로세스를 말하지 커널 프로세스의 경우에는 상태의 개념이 없다\n그래서 만일 사용자 프로세스가 작동하다가 이벤트가 발생해 커널 함수가 실행되는 경우에도 여전히 Running 상태라고 말하며 위의 그림에서는 그걸 Monitor mode 라고 구분지어준 것 뿐임\n\n\n그래서 Medium term scheduler 가 등장하면서 새로운 상태인 Suspended ~가 등장하게 됐는데\n이건 Blocked 랑은 완전히 다른 개념이다 → Blocked 의 경우에는 IO 등의 이벤트가 완전히 해결되고 난 뒤에는 다시 Ready 로 돌아오지만\nSuspended 의 경우에는 메모리에서 아주 퇴출된 상태를 의미하며 이놈이 메모리로 다시 올라오기 위해서는 Medium term scheduler 에 의해 다시 머리채가 잡혀 올라와야 한다는 것\n그래서 메모리에 올라와있을 때를 Active 라고 하고 스왑되어 나갔을때는 Inactive 라고 한다\n\nThread §\n\n\n쓰레드 별거 없다\n만약 동일한 코드를 이용해 여러개의 프로세스를 실행시키면 각 프로세스마다 주소공간하고 PCB가 생성되게 될텐데\n이렇게 하면 Data 나 Code 등의 부분은 중복해서 메모리에 올라가므로 아주 비효율적이다 이말이야\n그래서 Thread 라는 것을 생각해내게 됐는데\n이건 Lightweight process 로 하나의 프로세스 내에서 별개의 작업을 하려고 할 때 공유할 수 있는 부분은 최대한 공유하고 분리해야만 하는 것만 분리시키자는 개념이다\n\n전통적인 프로세스를 Heavyweight process 라고도 하며 이것은 쓰레드를 한개만 갖고 있는 프로세스와 동일하다\n\n\n그래서 일단 분리해야 되는 부분은 다음과 같다\n\nPC: 당연히 쓰레드들마다 코드의 다른 부분을 실행시키고 있을 것이기 때문에 PC는 각 쓰레드마다 하나씩 있어야 할 것이다\nReg set: 마찬가지로 레지스터의 값들도 쓰레드마다 다를게 분명하다\nStack: 쓰레드들마다 코드의 다른 부분을 실행할 것이기 때문에 호출된 함수들도 다를것이고, 따라서 Stack 도 별도로 관리되어야 할 것이다\n\n\n즉, PCB 의 구조에서 프로세스의 실행과 관련된 부분인 CPU 관련 필드, 그리고 주소 공간에서 스택이 쓰레드마다 갖고 있게 되는 것이다.\n\n\n공통적인 부분은 프로세스 내에서 위의 세개를 뺀 나머지 (Data, Code 등등) 이며 이 부분을 Task 라고 하더라\n쓰레드의 장점은 크게 네가지가 있다\n\nResponsiveness: 하나의 프로세스 내에서 하나의 쓰레드가 블락먹어도 다른 쓰레드가 계속 일을 할 수 있기 때문에 사용자에게 더 빠른 응답을 제공해 줄 수 있다.\nResource Sharing: 쓰레드는 최소한만 생성하고 대부분 공유하기 때문에 메모리를 덜먹는다\nEconomy: 이건 위의 장점에 의해 산출되는 장점인데 대부분 공유하기 때문에 Creating 혹은 Context Switching 을 할 때 일반적인 프로세스를 생성하거나 갈아치울때보다 현저리 적은 오버헤드를 가진다\nUtilization of MP(Multi Processor) Architectures: 프로세서가 여러개인 경우 쓰레드를 여러 프로세서에서 실행시켜 병렬작업이 가능해진다.\n\n\n쓰레드 종류는 Kernel Thread 와 User Thread 가 있댄다\n\nKernel Thread 는 쓰레드의 존재를 커널도 알고 따라서 Context switch 도 커널에 의해 이루어지지만\nPOSIX 같은 User Thread 는 쓰레드의 존재를 커널은 모르고 라이브러리 형태로 제공된다 → 따라서 Context switch 등도 프로세스 딴에서 관리된다.\n\n\n"},"os.fall.2022.ewha.ac.kr/4.-Process-Management":{"title":"4. Process Management","links":[],"tags":[],"content":"Process Lifecycle §\nProcess Creation §\n\n프로세스는 (Init process 가 아니라면)부모프로세스가 반드시 존재하고, 부모 프로세스를 복제하는 방식으로 자식 프로세스가 생성된다\n\n뭐 init process 는 알다시피 sysvinit 이나 systemd 등이 있겠제\n따라서 프로세스는 init process 를 루트로 하는 트리형식의 계층 구조를 형성하게 된다\n이렇게 자식을 복제하는 것은 fork() 시스템 콜을 이용해 수행할 수 있다\n프로세스 생성이 시스템 콜인 이유는 사용자 프로세스가 직접 하기에는 어려운 작업이고 아마 보안상의 문제도 껴있을거다\n\n\n자식 프로세스도 당연히 프로세스니까 자원을 할당받을텐데 여기에는 몇가지 정책(모델) 이 존재한다\n\n자원을 부모와 공유하여 운영체제로부터 받지 않는 모델\n자원을 부모와 일부만 공유하고 나머지는 운영체제로부터 할당받는 모델\n부모와 공유하지 않고 전부 운영체제로부터 할당받는 모델\n\n\n생각해보면 자식 프로세스는 부모 프로세스와 독립적인 프로세스이기 때문에 자원을 공유하지 않고 운영체제로부터 할당받는게 맞는 거 같지만\nUNIX 같은 경우에는 효율성을 위해 일단 부모와 공유하는 방식을 사용한다\n\n뭔소리냐면\nfork() 과정에서 부모꺼를 복제한다고 했자네\n근데 자원을 복제하면 결국에는 똑같은게 두개가 생길거 아님 → 뭐 프로세스의 Data, Code, Stack 같은게 똑같은게 두개가 생기게 될거아님\n이게 좀 낭비같은거야\n그래서 UNIX 에서는 일단 자원을 복사하지 않고 공유하고 있다가 부모랑 달라지면 그때 복사를 하는 방식을 이용한다\n즉 Lazy copy 라고 말할 수 있는거임 → 이걸 Copy-On-Write (COW) 라고 표현한다\n\n\n\n\n복제하는 과정을 좀 더 자세히 살펴보면\n\n일단 fork() 가 불려지면 운영체제는 PID 를 제외한 부모의 모든 것(뭐 PCB나 바이너리 같은것들 → 앞에서 배운 Process context 에서 PID 만 뺀거라고 생각해도 된다)을 복사한다\n그리고 자식 프로세스에게 새로운 주속 공간을 할당한다\n\n\n하지만 fork() 만 존재한다면 모든 프로세스가 부모랑 같은 작업만 할거 아니냐 → 그래서 (일반적으로는) fork() 이후에 exec() 이라는 시스템 콜이 사용된다\n\nexec() 은 기존에 존재하던 프로세스에 새로운 프로그램을 덮어 씌우는 시스템 콜인데\n일반적으로 fork() 이후에 exec() 시스템 콜이 호출되는 식으로 프로그램이 프로세스로 변환된다\n따라서 프로세스의 생성은 fork → exec 이 두가지 단계를 거친다고 할 수 있다\n물론 저 두 단계는 독립적이어서 fork() 만 해서 부모를 복사하기만 할 수도 있다\n\n\n\nProcess Execution §\n\n자식 프로세스가 생성되었을 때 부모가 취할 수 있는 동작은 두가지가 있는데\n\n그냥 별개의 프로세스로써 자식이랑 같이 공존하며 실행되거나\n자식 프로세스가 종료되어야 진행이 가능한 경우에는 block 을 먹어서 자식이 종료될때까지 기다릴 수도 있다 (wait() 시스템 콜)\n\n\n\nProcess Termination §\n\n프로세스가 자발적으로 종료될 때에는 일단 exit() 시스템 콜을 이용한다\n\n프로그래밍 언어에서 지원하는 라이브러리(뭐 예를 들면 go 의 os 같은 거) 를 통해 exit() 시스템 콜을 호출할 수도 있고\n아니면 프로그램 코드가 종료되면 (뭐 마지막 중괄호가 닫히는 등의 main() 함수가 리턴되는 시점) exit() 시스템 콜이 작동되도록 컴파일러가 넣어주는 등의 방법 등\n여러가지의 방법이 있지만 어쨋든 자발적으로 프로세스가 종료될때는 exit() 시스템 콜이 무조건 호출된다\nexit() 이 호출된 다음에는 자식이 부모에게 output data 를 보내게 되고\n프로세스의 각종 자원들이 운영체제한테 반납된다\n\n\n그럼 자발적이지 않은 경우는 무엇이냐 → 부모 프로세스가 자식의 수행을 종료시키는 경우가 존재한다\n\n뭐 자식이 너무 많은 자원을 먹어서 한계치를 넘어선 경우랄지\n자식이 하고 있는 작업이 불필요해진 경우랄지\n부모가 종료된 경우랄지\n\n운영체제는 (init process 가 아닌 이상) 부모가 없는 프로세스가 존재하도록 하지 않는다\n따라서 부모가 종료될때는 자식을 전부 종료시킨 후에 종료되도록 하는데\n자식한테 또 자식이 있을 경우에는 또 그 자식이 종료되는 절차를 밟을 거 아님\n그래서 부모가 종료될때는 자식을도 단계적으로 종료되게 된다\n\n\n\n\n\nProcess Syscall §\nFork §\n\n\n이제 이건 fork() 시스템 콜에 대한 C 언어 코드 예제인데\n일단 흔히 나올 수 있는 질문 중 하나는 부모 코드에 fork() 가 있는데 부모 코드를 그대로 복제하면 자식 코드에도 fork() 가 있을 것이고 그럼 자식도 fork() 를 해서 자식이 무한대로 생성되는거 아니냐 인데\n\n아니다\n앞서 fork() 를 할 때에는 Process context 전체를 복사한다고 했자네\n따라서 PC 값도 복사가 되기 때문에 자식 프로세스는 프로그램의 맨 처음부터 실행하는 것이 아니라 fork() 가 호출된 바로 다음 시점부터 실행된다\n\n\n그럼 PC 값이 복사된다면 부모와 자식은 같은 Physical memory address 의 instruction 을 실행하게 될까\n\n그것도 아니다\n왜냐면 PC 에 들어가는 값은 Virtual memory address 이기 때문에 PC 값이 같긴 하지만 실제로 참조하는 Address space 는 다르고 따라서 다른 Physical memory address 를 참조하게 된다\nPhysical memory address 에 대해서 CPU 는 알지 못한다 → CPU 가 사용하는 주소는 전부 Logical (뭐 Virtual address랑 거의 같다고 재철소장님이 그랬으니까) 이고 이걸 Physical address 로 바꾸는 건 CPU 가 아니라 Memory Management Module 이 BASE 랑 LIMIT 레지스터 값을 이용해 수행한다\n참고\n\nDifference between program counter in the executable and program counter in the main memory\nDoes the program counter generate the virtual address or a physical address in a cpu?\n\n\n\n\n부모와 자식이 코드가 동일하다면 어떻게 다른 작업을 하도록 할 수 있을 까?\n\nC 언어에 구현되어 있는 fork() 함수는 호출했을 때에 PID 값을 반환하도록 되어 있는데\n생각해보면 호출된 이후에는 부모와 자식 이렇게 프로세스가 두개가 생기므로 fork() 함수는 각 프로세스에게 두번 PID 값을 반환한다고 생각할 수 있다\n근데 이때 부모 프로세스에게는 양수 정수값을 반환하는 방식으로 생성된 자식 프로세스의 PID 값을 반환해주고\n자식 프로세스에게는 0을 반환해준다\n이걸 이용해서 하나의 코드로 부모와 자식에게 다른 일을 시킬 수 있다\n\n\n\nExec §\n\n\nexec() 시스템 콜은 위에서 말한 것처럼 새로운 프로그램으로 현재 프로세스를 덮어씌우는 것을 수행한다\n그래서 C 언어에서는 이 시스템 콜을 위해 execlp() 라는 함수를 제공해주는데\n뭐 문법은 위에 사진 보던가 너가 찾아봐라\n\n3번째 인자부터 해당 프로그램의 Args 들이 들어가는데\n마지막 인자는 null string 을 넣어서 닫아줘야 한다네\n\n\n중요한건 exec() 시스템 콜을 호출하고 나면 새로운 프로그램이기 때문에 main() 함수의 맨 첫번째 줄부터 실행하게 된다\n\n어찌보면 당연한 얘기지 → 프로그램이 새로 프로세스가 됐는데 당연히 Process context 는 없는게 맞지\n\n\n다음은 exec() 을 실행하고 난 뒤에는 원래의 프로그램으로 되돌아오지는 못한다는 거다\n\n이것도 당연한 얘기다 → 기존의 프로세스가 새로운 프로그램으로 덮어씌워졌으니까 원래꺼는 없어지고 되돌아오지도 못하는게 인지상정\n\n\n마지막으로는 fork() 와 exec() 은 별개의 시스템 콜이기 때문에 fork() 없이도 exec() 을 호출하는게 가능하다는 거다\n\n따라서 이때에는 자식이 생기는 방식이 아니라 그냥 나 자신이 새로 태어나게 된다\n\n\n\nWait §\n\n\nwait() 은 별거 없다\n그냥 부모가 자식 끝날때까지 block 되어 기다리게 하는 시스템 콜이 wait() 이다\n\n그래서 wait() 이 호출되면 커널은 해당 프로세스를 block 시켰다가\n해당 프로세스의 자식 프로세스가 모두 종료되면 다시 ready 로 바꾼다\n\n\n위 그림은 그냥 예제고 → 읽어보면 걍 별거 없다\nwait() 을 이용한다고 할 수 있는 프로그램이 Shell 프로그램이다\n\n결국에는 쉘의 경우에도 입력한 프로그램을 시키는 것이기 때문에 해당 프로그램을 자식 프로세스호 실행시키고 wait 하다가 끝나면 다시 커서를 깜빡이게 하는 방식으로 활용한다.\n\n\n\nInter Process Conmunication (IPC) §\n\nIndependent Process: 프로세스는 기본적으로 각자 독립적으로 작동하고 다른 프로세스에 영향을 끼지지 않는다 (뭐 부모 - 자식 관계는 예외)\nCooperating Process: IPC 를 이용하면 다른 프로세스의 수행에 영향을 끼칠 수 있다\n\nMessage Passing §\n\n\nIPC 의 분류중에 Message Passing 은 일단 커널을 브로커로 해서 메시지를 전달하는 방법 (Message System)이다\n\n따라서 공유 메모리나 공유 변수 등을 사용하지 않는다\n\n\n뭐 인터페이스가 두가지 종류가 있다네\n\nDirect Communication\n\n\n얘는 수신 프로세스를 명확하게 명시하는 방식이랜다\n\n\nIndirect Communication\n\n\n그리고 얘는 수신 프로세스를 명시하지 않고 메일박스(?) 나 포트번호 등을 이용해서 메시지를 간접적으로 전달하는 방식이라네\n\n\n\n\n\nShared Memory §\n\n\n얘는 말 그대로 공유 메모리를 커널로부터 할당받아서 두 프로세스가 메모리에 존재하는 데이터를 공유하는 방법이다\n얘도 당연히 커널의 힘을 빌려야 하긴 하지만 Message Passing 의 경우에는 매번 커널에 의존하지만 얘는 공유 메모리를 처음 매핑할때만 커널에 의존한다는 차이점 정도가 존재한다\n\nThread §\n\n뭐 쓰레드는 프로세스가 아니기 때문에 IPC 라고 하기에는 좀 뭐하지만\nThread 끼리는 메모리를 공유하기 때문에 통신이 아주 간편맨하댄다\n"},"os.fall.2022.ewha.ac.kr/5.-CPU-Scheduling":{"title":"5. CPU Scheduling","links":[],"tags":[],"content":"CPU, IO Burst §\n(사진 사라짐)\n\n프로세스가 실행되는 것은 (일반적으로) CPU 를 연속적으로 사용하다가 IO 때문에 Block 되있거나 하는 것의 반복이라고 할 수 있는데 이때\nCPU 를 연속적을 사용하는 구간을 CPU Burst 라고 하고\nIO 때문에 Block 먹어있는 구간을 IO Burst 라고 한다\n\nCPU, IO Bound Job §\n(사진 사라짐)\n\n이 그래프는 한 CPU Burst 의 실행시간과 CPU Burst 의 빈도를 나타낸 그래프인데\n보면 왼쪽은 CPU Burst 의 기간이 아주 짧고 빠르게 반복된다\n\n이것은 잦은 IO 에 의해 CPU Burst 와 IO Burst 가 빈번하게 반복되는경우인데\n이러한 Job (== Process) 들을 IO Bound Job 이라고 한다\n일반적으로 IO 는 표준 입출력 등의 사람과 Interaction 하기 위한 것이 많기 때문에 사람과의 interaction 이 잦은 경우에 IO Bound Job 이 된다\n\n\n그리고 오른쪽의 Job 들은 한번 CPU 가 잡으면 오랫동안 사용하여 CPU Burst 의 기간이 길고 따라서 빈도는 낮아지는데 (당연히 한번 잡았을때 길게 쓰니까 빈도는 작아질 수 밖에 없다)\n\n이러한 Job 들을 CPU Bound Job 이라고 부르고 일반적으로 연구 등의 목적을 위해 복잡한 계산을 오랫동안 진행하는 Job 들인 경우가 많다\n\n\n뭐 그래서 IO Bound Job 이 사람과의 상호작용이 잦기 때문에 CPU Bound Job 이 너무 CPU 를 오래 잡고 있어 사용자 Response 가 늦어지는 일이 벌어지지 않게 하기 위해 CPU Scheduling 을 한다네\n\nScheduler, Dispatcher §\n\nCPU Scheduler: Ready 인 프로세스 중에 Running 상태가 될 프로세스를 고르는 커널 프로세스\n\nCPU Scheduling 이 발생하는 경우는 대표적으로 다음과 같다\n\n프로세스가 CPU Time 을 _자진 반납_하는 경우 (Non-preemptive)\n\nIO 등의 사유로 CPU Time 을 반납 (Running → Blocked)\nProcess Terminate 로 CPU 반납 (Running → Exit)\n\n\n프로세스가 CPU Time 을 빼앗기는 경우 (Preemptive)\n\nTimer interrupt (Running → Ready)\nIO 가 완료된 프로세스의 우선순위가 현재 프로세스보다 높을 때 (Blocked → Ready)\n\n\n\n\n\n\nDispatcher: 현재의 프로세스에서 CPU Scheduler 가 고른 프로세스로 Context switch 를 진행하는 커널 프로세스\n\nCPU Scheduling §\n고려사항들 §\n\nReady 상태인 (CPU Burst 에 진입한) 프로세스 중 누구한테 CPU 를 줄 것인가?\n한번 CPU 를 받았으면 끝날때까지 계속 쓰게 할 것인가 아니면 중간에 뺏을 것인가?\n\nPerformance Index (Measure, Criteria) §\n\nPerformance Index 는 성능을 측정하는 척도를 의미하는데 아래와 같이 두개로 나눌 수 있다\nSystem Performance: 얼마나 시스템의 자원을 효율적으로 굴리느냐\n\nCPU Utilization: 얘는 CPU 이용률을 의미한다\n\n“률” 이기 때문에 당연히 전체에서 부분이 차지하는 비율을 의미하는데\nCPU Utilization 에서는 “시간” 을 기준으로 측정한다 → 즉, 시스템이 작동하고 있는 전체 시간 중에서 CPU 가 일을 하고 있는 비율이 얼마냐\n\n\nThroughput: 얘는 처리량을 의미하는데\n\nCPU Utilization 이 시간에 대한 값이었다면 얘는 양을 나타내는 값이다\n즉, 단위시간동안 처리한 작업의 양을 의미하는 것\n\n\n\n\nProgram Performance: 사용자가 느끼는 프로세스의 빠릿빠릿함\n\nTurnaround Time: 한번의 CPU Burst 동안 걸린 시간의 총합\nWaiting Time: 한번의 CPU Burst 동안 CPU 가 할당되지 않고 기다린 시간의 총합\nResponse Time: 한번의 CPU Burst 동안 CPU 가 처음으로 할당되기까지 걸린 시간\n그냥 이렇게만 보면 멍게소리인가 싶을텐데 한번의 CPU Burst 에 어떤 일들이 일어나는지를 생각해보면 알기 쉽다\n\n먼저 IO Burst 가 끝나고 CPU Burst 에 들어온 시간이 0초라고 해보라\n그러고 바로 CPU 를 할당받을 수 있으면 기모찌하겠지만 인생이란게 그렇게 녹록하지 않아서 4초에 CPU 를 할당받아서 작업을 했다라고 치면\n첫 4초가 Response Time 이 되는 것\n\n즉, CPU Burst 가 시작된 이래로 얼마나 빨리 CPU 가 할당되었느냐 이다\n\n\n그리고 만일 Preemptive 로 스케줄링되어 6초에 CPU 를 빼앗겼다가 7초에 다시 받고 10초에 IO 가 생겨서 IO Burst 로 빠져나갔다고 치면\n일단 기다린 시간을 다 합쳐보면 맨 처음 4초에 중간에 1초 기다렸으니까 5초 → 이게 Waiting Time 이 된다.\n\n즉, Waiting Time 은 처음의 Response Time에다가 CPU Burst 중간중간에 쉬는시간까지 다 합친 값이다\n\n\n그리고 전체적으로는 10초가 걸렸으므로 이게 Turnaround Time 이 된다\n\n즉, Turnaround Time 은 IO Burst 사이의 시간 간격이라고 생각할 수도 있고\nWaiting Time 에다가 CPU Time 까지 합친 시간이라고 생각할 수도 있다\n\n\n\n\n\n\n\n스케줄링 알고리즘 분류 §\n\nPreemptive: 하나의 프로세스가 너무 오래 CPU 를 차지하지 못하도록 중간에 뺏는 알고리즘\nNon-preemptive: 하나의 프로세스가 CPU 를 먹으면 IO 등의 이슈가 없는 한 계속 들고 있게 하는 알고리즘\n\nPriority Scheduling §\n\n그냥 단순하게 생각해서 우선순위에 따라 다음 프로세스를 선택하는 방식인데\nPreemptive 의 경우에는 당연히 우선순위가 높은 놈이 들어오면 빼앗고 Non-preemptive 의 경우에는 높은놈이 들어와도 빼앗지 않았다가 그놈이 끝나면 그 다음 우선순위 높은놈에게 주는 방식\n주의할 점은 일반적으로 UNIX(Linux) 계열에서는 숫자가 낮을수록 우선순위가 높은 거다\n\nSyslog 생각해봐도 emerg 가 0 이잖여\n\n\n\nStarvation, Aging §\n\n이후에 등장하는 스케줄링 알고리즘에서 Starvation 이라는 말이 나오는데 이건 알고리즘의 부작용으로 특정 프로세스가 CPU 를 할당받지 못하는 상황을 의미한다\n\n만일 우선순위가 낮은 프로세스의 경우 해당 프로세스보다 우선순위가 높은 프로세스가 항상 존재한하면 해당 프로세스는 영원히 CPU 를 받지 못한다.\n\n\n이를 해결하기 위한 방법으로 Aging 이 있는데 이건 우선순위가 낮은 프로세스가 오랫동안 CPU 를 할당받지 못하면 자연스럽게 우선순위가 높아지게 하는 방법을 의미한다\n\nScheduling Algorithms §\nFCFS (First Come First Serve) §\n\n\n뭐 별거 없다 → 선입선출\n\n당연히 무지성 선입선출이기 때문에 Non-preemptive 이다\n\n\n\n얘의 문제점은 예상하시는 바와 같이 앞에 오래걸리는 놈이 하나 버티고 있으면 그 뒤에 있는 놈들은 다 지연된다는 거다\n\n\n예를 들어 아래의 두개 상황을 비교해봐라\n(사진 사라짐)\n\n첫번째의 경우는 앞에 오래걸리는 애가 있어서 평균 Waiting Time 이 17이나 되지만\n만일 앞에 짧은 애가 오면 평균 Waiting Time 은 3으로 거의 1/6 이 줄어든다\n이렇듯 FCFS 에서 앞에 오래걸리는 한놈때문에 나머지가 전부 지연되는 것을 Convoy effect 라고 하더라\n\n\n\nSJF (Shortest Job First) 혹은 SPN (Shortest Process Next) §\n\n\nFCFS 를 보면서 ‘그럼 제일 적게걸리는 놈한테 먼저 주면 되는거 아닌가’ 라고 생각했으면 이게 그거다\n\n\n즉, CPU Time 이 제일 적은 놈에게 우선적으로 CPU 를 주는 것\n\n\n얘는 이제 Non-preemptive 하고 Preemptive 두가지 버전이 있는데\n\n\nNon-preemptive SJF 은 일단 CPU 를 CPU Time 이 적은놈한테 주되 이걸 빼앗을 수는 없으므로 더 짧은 놈이 들어와도 일단은 현상유지하는 것이고\n\n\nPreemptive SJF 는 CPU Time 이 더 짧은 놈이 오면 CPU 를 빼앗아서 이놈한테 주는거다\n\n그런데 이때 CPU Time 은 지금 실행중인 놈의 남은 시간과 새로운 놈의 시간을 비교하기 때문에 SRTF (Shortest Remaining Time First 혹은 그냥 SRT) 라고도 부른다\n또한 이 경우는 평균 Waiting Time 이 최소가 되는 것으로 알려저 있다 (Waiting Time Optimal)\n\n똑똑이들이 증명해놨다네\n\n\n\n\n\n뭐 아주 좋아보이지만 아쉽게도 얘도 문제가 있다\n\nStarvation: 눈치챘겠지만 앞에 짧은 애들만 오면 긴놈은 절대로 CPU 를 받을 수 없다.\n그리고 CPU Time 는 사전에 알지 못하는 값이다\n\n\n\nCPU Time 을 예측하는 방법으로 Exponential Averaging 이라는게 있는데 다른 분야에도 등장하는 개념이라니까 간단하게 짚고 넘어가면\n\nt(n) 은 n 번째의 CPU Time 이고\n따우(n) 은 n 번째의 CPU Time 예측값일때\nExponential Averaging 의 공식은 다음과 같다\n\n(사진 사라짐)\n\n이 식을 전개해보면\n\n(사진 사라짐)\n\n가 되는데 상수 a 가 0 &lt; a &amp;&amp; a &lt; 1 이기 때문에 제곱할수록 작아진다\n즉, 제일 최근의 값은 1에 그나마 가까우므로 가중치가 높아지고 옛것으로 갈수록 0에 가까워지니까 가중치가 낮아지는 것으로도 생각할 수 있는 것\n찾아보니까 이 개념은 머신러닝에서도 사용되는듯\n\n\n\nRR (Round Robin) §\n\n지겹다 지겨워 그냥\n알다시피 무지성 돌라돌라골림판이다\n\n즉, 일정한 Time Quantum 으로 CPU Time 을 난도질해서 해당 시간이 끝나면 다른 프로세스에게 또 Time Quantum 만큼의 CPU Time 만 주는 방법이다\n\n\n얘는 다양한 CPU Time 을 가지는 프로세스들이 섞여있을 때 맛집이 된다\n\n스케줄링 할 때 CPU Time 을 예측할 필요도 없고\nCPU Time 크든 작든 돌아가며 CPU 가 할당되므로 Starvation 에 빠질 우려도 없다\n심지어 CPU Time 길수록 Waiting Time 도 늘어나는 합리성까지 보여준다\n\n\n하지만 CPU Time 이 전부 똑같을때는 똥된다\n\n단순히 FCFS 를 생각해도 100 짜리 4개가 들어오면 100, 200, 300, 400 의 시간에 프로세스가 종료되지만\nRR 로 돌리면 다같이 돌다가 전부 400에 프로세스가 종료되기 때문\n이렇듯 CPU Time 이 같은 경우에는 비효율적이나 일반적인 상황이 아니기 때문에 대부분 효율적이다\n\n\nTime Quantum 이 극단적이 되면 어찌되는가\n\nq 가 너무 커지면 FSFC 와 다를바가 없어서 비효율적이고\nq 가 너무 작아지면 Context Switching 의 오버헤드가 너무 커져 비효율적이 된다\n\n\n\nMulti-level Process Queueing §\n\n위에 소개된 알고리즘들은 전부 프로세스를 큐 하나에 때려박고 적당히 꺼내서 CPU 를 할당해주는 방식이었다면\n지금부터 소개되는 알고리즘들은 프로세스를 우선순위에 따라 여러 큐에 넣어서 관리하는 방법들이다\n이러한 방식은 일반적으로 큐마다 다른 스케줄링 알고리즘을 사용하고\n상위 우선순위의 큐가 비지 않아 Starvation 이 발생할 것을 방지하기 위해 CPU 를 차등 분배한다\n\n즉, 상위 우선순위의 큐가 비어야만 하위 큐로 가는게 아니고\n우선순위가 높은 큐에는 CPU 를 더 많이 할당해주고 낮은 큐에는 적게 할당하는 식으로 유도리있게\n\n\n\nMulti-level Queue §\n(사진 사라짐)\n\n얘는 프로세스의 특성에 따라 우선순위를 두고 우선순위에 따른 큐를 여러개 만들어 상위 우선순위의 큐가 비어야 그 아래 큐에 있는 프로세스에게 CPU 가 할당될 수 있도록 하는 Preemptive 한 방식이다\n\n위 그림은 그렇게 여러개의 큐를 나누어놓은 예시 그림임\n\n\n하지만 이러한 방식은 우선순위 변동의 유연함이 없어 문제가 있더라\n\nMulti-level Feedback Queue (Feedback Scheduling) §\n(사진 사라짐)\n\n얘는 RR 방식의 큐를 여러개 준비해놓고 아래로 내려갈수록 Quantum 값이 증가하게 해놓은 다음\n처음 들어온 프로세스는 제일 우선순위가 높은 큐에 넣고\nQuantum 내에 끝내지 못하면 그 아래 큐로 내려보내는 방식이다\n이 방식은 SJF 알고리즘에서 CPU Time 을 알 수 없다는 단점을 해결했다고 볼 수 있는데 왜냐면\n일단 처음에는 CPU Time 을 알 수 없으니까 Quantum 을 짧게 하는 대신 우선순위를 높여주고\n해당 Quantum 내에 끝내지 못했다면 Quantum 을 좀 더 오래 가져가는 대신 우선순위가 낮아지게 함으로써\n자연스럽게 빨리 끝나는 프로세스는 우선순위가 높아지고 오래걸리는 프로세스는 우선순위가 낮아지는 효과를 볼 수 있다\n\n그 외의 여러가지 CPU Scheduling 방식들 §\nMulti-processor Scheduling §\n\n프로세스들이 고만고만한 경우 (Homogeneous): 하나의 큐에 다 때려넣고 여러개의 CPU 들이 나눠먹거나\n\n반드시 특정 CPU 에서만 실행되어야 하는 경우에는 걔를 위해 CPU 하나를 할당해주고 나머지를 나눠먹거나\n\n\nCPU 부하 분산 (Load Sharing): 놀고 있는 CPU 가 없도록 하기 위해 공동 큐를 두거나 CPU 마다 큐를 구성\nSymmetric Multiprocessing: CPU 들이 동등한 자격으로 스스로 스케줄링 하는 방식\nAsymmetric Multiprocessing: 얘는 마스터를 선출하는거마냥 스케줄링 작업을 전담하는 CPU 를 하나 선출해서 나머지는 이놈이 스케줄링한거에 그냥 따르는 방식\n\nReal Time Scheduling §\n\n일반적으로 Real Time 이라고 하면 주어진 시간 내로 반드시 종료되야 하는 것을 의미하는데\nHard Real Time: 말 그대로 → 시간 내에 반드시 끝나야 함\nSoft Real Time: 얘는 시간 내에 끝나야 하긴 하지만 그렇지 못한다고 해서 큰 문제가 생기지 않는 경우를 의미하는데\n\n그냥 일반적인 스케줄링에서 우선순위를 좀 높여주는 방식으로 해결 가능하고\n동영상 재생이 대표적인 예시다 → 1초에 24프레임 이상을 로드해야되지만 그렇지 못했다고 해서 지구멸망은 아닌\n\n\n\nThread Scheduling §\n\nUser Thread 의 경우: Local Scheduling 이라고 부르는데 OS 는 이 쓰레드의 존재를 모르기 때문에 POSIX Thread 같은 라이브러리들이 직접 해준다\nKernel Thread 의 경우: Global Scheduling 이라고 부르는데 Short-term scheduler 가 프로세스 스케줄링하는것과 동일하게 해준다\n\nAlgorithm Evaluation §\n\n\nQueueing Model: 아래 그림처럼 입력 데이터(Arrival Rate) 를 확률분포로 주고 이때의 출력(Service Rate) 를 이용해 성능을 측정\n\n다분히 이론적이어서 많이는 사용하지 않는댄다\n\n(사진 사라짐)\n\n\nImplementation &amp; Measurement: 실제로 코드를 작성해 커널을 빌드하여 성능 측정\n\n\nSimulation: 커널 전체가 아닌 해당 알고리즘만 코드로 작성해 실제 OS에서의 작동 방식을 분석해 만든 입력 데이터 (Trace) 를 이용한 방법\n\n"},"os.fall.2022.ewha.ac.kr/6.-Process-Synchronize":{"title":"6. Process Synchronize","links":[],"tags":[],"content":"Concurrency, Race Condition §\n(사진 사라짐)\n\n일반적으로는 위 그림처럼 데이터를 저장하는 곳하고 연산하는 곳하고는 분리되어 있으며\n연산하는 곳에서 데이터를 읽어들여 연산한 다음 저장하는 방식으로 작동되는데\n\n(사진 사라짐)\n\n위 그림처럼 동일한 데이터에 여러 연산이 접근하게 되면 문제가 생길 수 있다\n이렇게 여러 연산이 하나의 데이터에 동시에 접근하는 문제를 Concurrency Problem, 동시성 문제 라 부르고\n동시성 문제가 발생하게 되는 상황을 연산간 경쟁한다는 의미로 Race Condition 이라고 부르더라\n이를 해결하기 위해서는 데이터의 접근 순서를 제어하는 로직이 필요하고 이런걸 Process Synchronization (프로세스 동기화) 라고 한다.\n\nCommon Race Condition Situations §\n\n커널 데이터\n\n\n일반 프로세스의 경우에는 자신만의 메모리 공간이 있기 때문에 동시성 문제 잘 발생하지 않지만\n\n\n커널의 경우에는 여러 프로세스가 Syscall 등을 이용해 공유할 수 있고\n(사진 사라짐)\n\n위 처럼 프로세스가 Syscall 을 해 커널모드에서 실행되다가 타임아웃이 난 후에 다른 프로세스로 넘어갔다가 여기서도 Syscall 을 걸어 커널 데이터를 변경하는 경우에 동시성 문제가 생길 수 있다\n이때는 커널모드일때는 CPU 를 Preempt 하지 못하게 하고 커널모드가 끝나야 빼앗을 수 있게 함으로써 해결할 수 있다\n\n\n\n커널모드에서 작업을 하다가 인터럽트가 걸리면 하던걸 멈추고 또 다른 커널 작업인 인터럽트 핸들링을 하게 되므로 이런 경우에도 문제가 생긴다\n(사진 사라짐)\n\n위 그림이 그 예시인데\n이러한 경우는 커널 모드 실행중일때는 인터럽트가 걸리지 않게 하는 방식으로 해결할 수 있다\n\n\n\n\n공유 메모리, 쓰레드\n\n일반 프로세스에서 동시성 문제가 발생하는 경우 중 제일 흔한거는\n프로세스 간 공유 메모리를 할당받았거나\n멀티쓰레드 프로그래밍을 할 때이다\n\n멀티쓰레드의 경우에는 쓰레드 간 메모리가 공유되기 때문에 동시성 문제가 생길 수 있다\n\n\n\n\n\nHandling Concurrency §\nCritical Section §\n(사진 사라짐)\n\n코드 상에서 공유 데이터 공간에 접근하는 부분을 Critical Section 이라고 한다.\n그리고 Entry / Exit Section 에서 Critical Section 에 들어가는 프로세스들을 Lock 을 거는것처럼 관리하게 된다.\n별로 중요한건 아니지만 공유데이터에 접근하지 않는 부분을 Remainder Section 이라고 한다\n\n충족해야 할 조건들 §\n\nMutual Exclusion: 상호 배제 → 하나의 프로세스가 Critical section 에 들어가 있으면 다른 프로세스는 들어가서는 안된다\nProgress: 현재 Critical section 에 들어가있는 프로세스가 없다면 Critical section 에 들어가고자 하는 프로세스는 거기 에 들어갈 수 있어야 한다.\nBounded Waiting: 다른 프로세스가 Critical section 에 들어가 있어서 나머지 프로세스가 대기해야 한다면, 대기 시간이 유한해야 한다.\n\n즉, 하나의 프로세스가 들어가서 빠져나오지 않는 상황이 발생하거나\n특정한 몇개의 프로세스만이 Critical section 에 접근하여 나머지 프로세스들은 들어갈 수 없는 상황 (뭐 예를 들면 두개의 프로세스가 번갈아가며 들어가 다른 프로세스가 접근할 수 없는 상황) 이 되면 안된다.\n\n\n\nAlgorithm 1 §\n\n프로세스 0 번의 코드가 다음과 같고\n\n// global variable: int turn = 0;\ndo {\n\twhile (turn != 0);\n\tcritical_section();\n\tturn = 1;\n\tremainder_section();\n} while (1);\n\n프로세스 1 번의 코드가 다음과 같다면\n\n// global variable: int turn = 0;\ndo {\n\twhile (turn != 1);\n\tcritical_section();\n\tturn = 0;\n\tremainder_section();\n} while (1);\n\n일단 Mutual Exclusion 은 달성할 수 있다\n\n0번 프로세스는 turn 이 0이 될 때까지 기다리고\n1번 프로세스는 turn 이 1이 될 때까지 기다리기 때문에\n두놈이 같이 들어가는 상황은 막을 수 있음\n\n\n하지만 Progess 는 안된다\n\n왜냐면 한놈이 Critical section 에 들어가는 것이 다른놈에게만 의존하기 때문에 한놈이 안드가게 되면 다른놈도 들어가지 못한다\n가령 1번이 들어가려면 turn 값이 1이어야 되는데 0번이 들어가지 않은 경우에는 turn 값이 0으로 남아있어 1번이 절대 들어가지 못하게 된다\n\n\n\nAlgorithm 2 §\n\n이번에는 프로세스 0 번의 코드가 다음과 같고\n\n// global variable: boolean flag[2] = {false, false};\ndo {\n\tflag[0] = true;\n\twhile (flag[1]);\n\tcritical_section();\n\tflag[0] = false;\n\tremainder_section();\n} while (true);\n\n프로세스 1 번의 코드가 다음과 같다면\n\n// global variable: boolean flag[2] = {0, 0};\ndo {\n\tflag[1] = true;\n\twhile (flag[0]);\n\tcritical_section();\n\tflag[1] = false;\n\tremainder_section();\n} while (true);\n\n이번에도 Mutual Exclusion 은 달성할 수 있다\n\n서로의 flag 가 올라가있는지 체크하면서 대기하기 때문에\ncritical_section() 에는 한번에 한놈만 드갈 수 있다.\n\n\n그리고 Algorithm 1 에서의 문제점도 해결할 수 있다\n\n프로세스가 연속해서 들어가고싶어할 경우에도 상대방의 flag 는 계속 false 이기 때문에 문제되지 않는다\n\n\n하지만 이 경우에도 Progress 가 해결되지는 않는다\n\n그건 Context switch 때문인데\n프로세스 0번이 flag[0] 을 true 로 바꾼 다음에 Contect switching 이 일어나서\n프로세스 1번이 flag[1] 을 true 로 바꾼다면\n지금 아무도 드가있지 않지만 둘 다 true 로 되어 있어 아무도 들어가지 못하는 상황이 됨\n\n\n\nAlgorithm 3 (Peterson’s algorithm) §\n\n이번에는 프로세스 0 번의 코드가 다음과 같고\n\n// global variable: int turn = 0;\n// global variable: boolean flag[2] = {false, false};\ndo {\n\tflag[0] = true;\n\tturn = 1;\n\twhile (flag[1] &amp;&amp; turn == 1);\n\tcritical_section();\n\tflag[0] = false;\n\tremainder_section();\n} while (true);\n\n프로세스 1 번의 코드가 다음과 같다면\n\n// global variable: int turn = 0;\n// global variable: boolean flag[2] = {0, 0};\ndo {\n\tflag[1] = true;\n\tturn = 0;\n\twhile (flag[0] &amp;&amp; turn == 0);\n\tcritical_section();\n\tflag[1] = false;\nremainder_section();\n} while (true);\n\n보면 Algorithm 1 과 Algorithm 2 를 합쳐놓은 느낌인데 이 경우에는 모든 경우의 수를 만족할 수 있다\n하나하나 따져보는 건 나중에 시간 많을때 해보고 그냥 느낌만 잡자면\nwhile 문에서 상대방의 flag 를 검사하기 때문에 일단 두명이 같이 드가는 것은 불가능하고\n만일 Algorithm 2 에서처럼 둘 다 flag 가 올라가있는 경우에는 turn 값을 이용해 한놈은 드갈 수 있게 해주는 방식이다\n하지만 이 방식은 작동은 하지만 다소 비효율적이다 → Busy Waiting 이기 때문\n\n어쨋든 while 문을 통해 계속 CPU 와 메모리를 먹으면서 기다리기 때문에\n불필요한 자원소모라고 할 수 있기 때문\nSpin lock 이라는 용어도 알아두라\n\n\n\nHardware approach (Atomic solution) §\n\n값을 읽는 작업과 쓰는 작업을 하나의 instruction 에서 처리할 수 있다면 동시성 문제가 좀 쉽게 해결될 수 있다\n간단하게 생각해서 아래와 같은 코드로 두 프로세스가 돌아간다고 할 때\n\n// global variable: boolean is_lock = false;\ndo {\n\twhile (is_lock);\n\tis_lock = true;\n\tcritical_section();\n\tis_lock = false;\n\tremainder_section();\n} while (1);\n\n\n두번째 줄에서 is_lock 값을 확인해서 false 가 나와 세번째 줄을 수행하려 할 때\n\nContext switch 가 일어나 다른 프로세스가 is_lock 값을 바꾸고 Critical section 으로 들어간다면\n다시 돌아왔을 때 is_lock 을 확인하지 않고 Critical section 으로 들어가기 때문에 두 프로세스가 모두 Critical section 에 진입하게 된다\n\n\n\n하지만 값을 읽는것과 쓰는 작업을 한번에 해주는 instruction 가 있다면 위와 같은 상황은 해결이 된다\n\n아래의 코드에서 test_and_set() 함수는 변수의 값을 읽는 것과 값을 true 로 바꾸는 작업을 한번에 한다고 가정하면\n\n(사진 사라짐)\n\n즉, test_and_set() 함수가 변수의 값을 읽고 false 라면 true 로 바꾸고 true 여도 true 로 바꾸는 작업을 한다면\n\n\n\n// global variable: boolean is_lock = false;\ndo {\n\twhile (test_and_set(is_lock));\n\tcritical_section();\n\tis_lock = false;\n\tremainder_section();\n} while (1);\n\n그럼 2번째 줄을 수행한 다음 Context switch 가 일어나도 is_lock 값이 이미 바뀌어있기 때문에 다른 프로세스는 Critical section 으로 드가지 못한다\n\nSemapore §\n\nSemapore 은 동시성 처리를 위한 추상 자료형이다\n\n즉, Semapore 는 Property 와 Method 만 정의되고 구현방식은 정의되지 않는다\n\n\nSemapore 의 Property 는 다음의 특징을 가져야 한다\n\nInteger: 셀 수 있는 정수값을 가진다\nSemapore 의 정수값은 자원에 접근할 수 있는 프로세스의 개수를 나타낸다\n즉, 0보다 클 경우에는 해당 프로세스가 자원에 접근할 수 있다는 것을 나타내고 그렇지 않다면 대기해야 한다는 것을 의미한다\n\n\n그리고 Method 는 다음과 같으며 해당 Method 들은 Atomic 하게 작동한다\n\nP: Semapore 의 값이 0보다 클 경우에는 1을 감소시키고 그렇지 않을 경우에는 대기한다.\n\nP 연산의 경우에는 Lock 을 거는 작업을 담당한다\n1을 감소시키기 때문에 접근할 수 있는 프로세스의 개수를 하나 감소시켜 한 자리를 차지하는 셈인 거고\n0 이하일 경우에는 대기하기 때문에 자리가 없을 경우 대기하는 것으로 해석할 수 있다\n\n\nV: Semapore 의 값을 1 증가시킨다\n\nV 연산의 경우에는 Lock 을 해제하는 작업을 담당한다\n즉, 1을 증가시키기 때문에 Lock 을 풀고 한 자리를 내어놓는 것으로 해석할 수 있다\n\n\n\n\n\nImplementation 1: Busy waiting (Spin lock) §\n\nGo 로 대충 수도코드 적어보자고\n일단 struct\n\ntype Semapore struct {\n\tcount int\n}\n\n그리고 method 두개\n\nfunc (s *Semapore) P() {\n\tfor s.count &lt;= 0 {}\n\ts.count--\n}\nfunc (s *Semapore) V() {\n\ts.count++\n}\n\n뭐 간단하죠?\n근데 위에서 언급한것처럼 이 경우에는 반복문이 돌면서 기다리기 때문에 CPU와 메모리의 낭비이다\n\nImplementation 2: Block wakeup (Sleep lock) §\n\n\n이번에는 대기할때 반복문을 도는게 아니고 아예 프로세스의 상태를 Blocked 상태로 바꿔버리는 방법이다\n(사진 사라짐)\n\n\n즉, 위 그림과 같이 IO 큐 등의 여러 큐들에 추가적으로 공유데이터에 접근하는 것을 기다리는 큐를 하나 더 둬서 대기시킨다\n\n\n그래서 보통 아래처럼 구현한다\n(사진 사라짐)\n\nPCB 큐를 둬서 하나의 세마포에 대기하도록 함\n\n\n\n간단히 수도코드 적어보자고\n\n\n세마포는 다음처럼 생각할 수 있음\n\n\ntype Semapore {\n\tvalue int\n\twait  []int\n}\n\n그리고 다음처럼 메소드들을 구현할 수 있을 것이다\n\nfunc (s *Semapore) P() {\n\tif s.value--; s.value &lt; 0 {\n\t\ts.wait = append(s.wait, os.Getpid())\n\t\tos.Block() // Pseudo method `Block()`\n\t}\n}\nfunc (s *Semapore) V() {\n\tif s.value++; s.value &lt;= 0 {\n\t\tos.WakeUp(s.wait[0]) // Pseudo method `WakeUp(pid int)`\n\t\ts.wait = s.wait[1:]\n\t}\n}\n\ns.value++; s.value &lt;= 0 의 이유: 일단 1을 더해줬는데도 0과 같거나 작다는 것은 1을 더해주기 전에는 0보다 작았었기 때문에 대기하던 프로세스가 있음을 의미\n\nBusy-wait vs Block-wakeup §\n\n일반적으로는 Block-wakeup 방식이 더 좋기는 하지만\nBlock-wakeup 방식의 Context switch 에 오버헤드가 존재하기 때문에 Critical section 이 아주 짧은 경우에는 Busy-wait 방식이 오히려 더 좋을 수 있다\n\nSemapore 종류 §\n\nCountable semapore: 값이 2 이상이 될 수 있는 세마포\n\n보통 자원의 수를 세는 용도로 사용됨\n\n\nBinary semapore(Mutex): 값이 0또는 1만이 되는 세마포\n\n프로세스의 Mutual exclusion 을 위해 사용됨\n\n\n\nDeadlock, Starvation §\n\nDeadlock 은 둘 이상의 프로세스가 서로의 이벤트 종료를 기다리고 있는 상황이라고 할 수 있다\n\n그니까 쉽게 말하면 내가 끝나려면 너가 끝나야되는데 너가 끝나려면 내가 끝나야되는 상황\n\n\nStarvation 은 둘 이상의 프로세스가 자기네들끼리만 우선권을 획득해서 일부 프로세스가 우선권을 영원히 획득할 수 없는 상태를 말한다\n이 둘은 그 다음에 나오는 굶주린 소크라테스 보면 딱 이해됨\n\nBounded-Buffer Problem §\n(사진 사라짐)\n\n이 문제는 다음과 같다:\n\n공유 메모리에 있는 버퍼에는 값을 넣을 수 있는 칸이 n 개가 있다 → Bounded-buffer, 유한 버퍼\n여러 Producer 가 값을 생산하여 버퍼의 한 칸에 채워넣는다\n여러 Consumer 는 Producer 가 생산하여 버퍼에 채워넣은 값을 가져가 비운다\n\n\n이 문제에는 다음과 같은 동시성 관리가 필요하다:\n\nProducer 혹은 Consumer 프로세스는 한번에 한놈만 공유 버퍼에 접근해야 한다\n\n만일 그렇지 않은 경우에는 두 Producer 가 한번에 같은 칸에 접근해서 하나의 값이 덮어씌워지거나\n두 Consumer 가 한번에 같은 칸에 접근해서 문제가 되거나 (뭐 같은 값을 두번 가져가거나 null 을 가져가거나 등등)\n\n\nProducer 는 비어있는 칸이 있어야 값을 쓸 수 있고 Consumer 는 채워져있는 칸이 있어야 값을 가져올 수 있다\n\n\n그래서 이 문제에는 세개의 세마포가 사용된다\n\n공유 버퍼에의 접근을 제어할 Mutex\nProducer 입장에서의 자원 관리\n\n즉, 비어있는 칸이 Producer 입장에서의 자원이므로 이것을 관리할 empty_sem 이 하나 필요하다\n\n\nConsumer 입장에서의 자원 관리\n\n즉, 채워져있는 칸이 Consumer 입장에서의 자원이므로 이것을 관리할 full_sem 이 하나 필요하다\n\n\n\n\n따라서 Producer 와 Consumer 는 다음의 과정을 거쳐 작업을 수행한다\n\nProducer\n\n비어있는 칸이 있는지 확인하고 없으면 기다림\n공유데이터에 Lock 을 걺\n데이터 입력\nLock 을 풂\n채워져 있는 칸의 개수를 1 증가시킴\n\n\nConsumer\n\n채워져 있는 칸이 있는지 확인하고 없으면 기다림\n공유데이터에 Lock 을 걺\n데이터를 가져감\nLock 을 풂\n비어있는 칸의 개수를 1 증가시킴\n\n\n\n\n이를 바탕으로 수도코드를 적어보면 다음과 같다\nProducer\n\n/**\n * Shared memory\n * var buf *bufio.ReadWriter\n *\n * Semapores\n * var mutex semapore_t = 1\n * var empty_sem semapore_t = n\n * var full_sem semapore_t = 0\n */\nfunc produce() []byte { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tvalue := produce()\n\t\tP(empty_sem)\n\t\tP(mutex)\n\t\tbuf.Write(value)\n\t\tV(mutex)\n\t\tV(full_sem)\n\t}\n}\n\nConsumer\n\n/**\n * Shared memory\n * var buf *bufio.ReadWriter\n *\n * Semapores\n * var mutex semapore_t = 1\n * var empty_sem semapore_t = n\n * var full_sem semapore_t = 0\n */\n \nfunc consume(value []byte) { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tP(full_sem)\n\t\tP(mutex)\n\t\tvar value []byte\n\t\tbuf.Read(value)\n\t\tV(mutex)\n\t\tV(empty_sem)\n\t\tconsume(value)\n\t}\n}\n\n세마포 값은 다음과 같은 이유이다\n\nmutex 의 경우에는 상보배제해야되므로 값이 1이고\nempty_sem 의 경우에는 처음에는 모두 비어있으니까 값이 n 이고\nfull_sem 의 경우에는 처음에는 채워져있는게 하나도 없으니까 값이 0이다\n\n\n그리고 과정을 차근차근 보면\n\n일단 Producer 는 empty_sem 을 하나 먹고 값을 쓰되\n릴리즈 과정에서 empty_sem 을 릴리즈하는게 아니고 full_sem 을 릴리즈해서 1을 증가시킨다\n그럼 Consumer 는 full_sem 을 먹고싶은데 일단은 full_sem 이 0이니까 기다리다가\nProducer 가 full_sem 을 1 증가시키면 그걸 낼름 먹어서 값을 가져온다\n그리고 이번에는 full_sem 을 릴리즈하는게 아니고 empty_sem 을 릴리즈해서 1을 증가시키는 방식\n\n\n\nReaders-Writers Problem §\n\n이 문제는 DB 에서의 동시성 문제에 대한 간략한 예시이다:\n\nDB 에서 값을 읽는 것은 여러개가 접근해도 된다\nDB 에 값을 쓰는 것은 한놈만 접근해야 된다\n\n\n이 문제에서는 다음의 세마포를 사용해 동시성을 관리할 수 있다:\n\nDB 에 배타적으로 값을 write 하기 위한 세마포\nReader 의 개수를 세어서 Reader 가 있는 경우에는 Writer 가 접근하지 못하도록 해야 하는데 이때 Reader 들의 개수를 세기 위한 공유 변수에의 세마포\n\n\n따라서 다음과 같이 수도코드를 작성할 수 있다\nWriter\n\n/**\n * Shared memory\n * var db *bufio.ReadWriter\n * var readCount int = 0\n *\n * Semapores\n * var db_sem semapore_t = 1\n * var rc_sem semapore_t = 1\n */\n \nfunc getValue() []byte { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tvalue := getValue()\n\t\tP(db_sem)\n\t\tdb.Write(value)\n\t\tV(db_sem)\n\t}\n}\n\nReader\n\n/**\n * Shared memory\n * var db *bufio.ReadWriter\n * var rc int = 0\n *\n * Semapores\n * var db_sem semapore_t = 1\n * var rc_sem semapore_t = 1\n */\n \nfunc useValue(value []byte) { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tP(rc_sem)\n\t\tif rc++; rc == 1 {\n\t\t\tP(db_sem)\n\t\t}\n\t\tV(rc_sem)\n \n\t\tvar value []byte\n\t\tdb.Read(value)\n \n\t\tP(rc_sem)\n\t\tif rc--; rc == 0 {\n\t\t\tV(db_sem)\n\t\t}\n\t\tV(rc_sem)\n \n\t\tuseValue(value)\n\t}\n}\n\n차근차근 보면\ndb_sem 하고 rc_sem 은 어차피 상호배제를 위한거니까 값이 1이고\n\nWriter 의 경우에는 db_sem 을 잠그는 것 밖에 할게 없다\n하지만 Reader 의 경우에는 rc 를 건들기 위해 아래위로 rc_sem 을 이용하여 한번에 한놈만 접근할 수 있게 하고\n첫 Reader 의 경우에만 db_sem 을 잠그고 마지막 Reader 만 db_sem 을 풀어 이것에 대한 상호배제를 하게 한다\n\n\n하지만 위의 코드는 Starvation 이 일어날 수 있다\n\n왜냐면 Reader 가 다 빠져나간 경우에만 db_sem 이 풀리기 때문에 Reader 가 계속 들어오면 Writer 가 들어올 수 없기 때문\n\n\n\nDining-Philosophers Problem §\n(사진 사라짐)\n\n이건 배부른 돼지보다는 나은 배고픈 소크라테스의 고분분투기를 다룬 문제다\n일단 상황은\n\n소크라테스들이 자리에 앉아 생각을 하다가\n배고프면 자신의 양쪽에 있는 젓가락을 둘 다 잡아 식사를 하고\n이후에 다시 내려놓고 생각을 하는 고달픈 인생이다\n\n\n이 상황을 타개할 수 있는 가장 간단한 해결법은 다음과 같다\n\n왼쪽에 Lock 을 걸고 오른쪽에 Lock 을 걸어서 식사를 하고 차례대로 Lock 을 푸는 것\n\n\n하지만 이것은 다음과 같은 문제가 생긴다\n\nDeadlock: 만약 모든 소크라테스가 왼쪽의 젓가락을 잡으면 아무도 식사하지 못한다\nStarvation: 만약 자신의 양옆에 있는애들이 번갈아서 식사하면 나는 굶어 죽어 배부른 돼지보다도 못하게 된다\n\n\n이것을 해결할 수 있는 방법은 대표적으로\n\n한번에 4명의 소크라테스만 앉게 한다\n옆의 소크라테스를 유심히 보다가 젓가락을 모두 잡을 수 있을 때에만 식사를 한다\n비대칭 → 짝수번째 소크라테스는 오른쪽부터, 홀수번째 소크라테스는 왼쪽부터\n\n\n\nMonitor §\n\n동시성문제는 실행시에 무조건 발생하는 것이 아니라 코드를 잘못 작성했을 때 특정 조건이 맞을때에만 발생하기 때문에\n세마포를 잘못 사용했을 때에 이것을 감지해내기 어렵다\n따라서 개발자 입장에서 실수를 줄일 수 있는 더 상위 추상화가 여러 프로그래밍 언어들에서 지원되는데 이것이 Monitor 이다\n\n(사진 사라짐)\n\n\n그래서 위처럼 구성됨\n\n\n모니터에서는 공유 데이터와 그것에 접근할 수 있는 유일한 방법인 메소드를 묶어 하나의 class 로 구현하게끔한다\n\n\n구현한 뒤에는 Monitor 에는 한번에 하나의 프로세스만이 접근할 수 있도록 알아서 제어되기 때문에 Mutex 의 사용이 불필요하다\n\n즉, 명시적으로 공유데이터를 잠그거나 푸는 로직을 작성하지 않아도 된다는 소리임\n모니터에 접근한 프로세스가 종료되거나\n뒤에 나오는 Condition 에 의해 Block 되는 등의 방식으로 모니터 사용이 끝나면 다른 프로세스가 모니터에 들어와서 사용하게 된다\n\n\n\n그리고 모니터에는 Condition 기능도 제공되는데 이것은 Countable semapore 를 대체하는 기능이다\n\nBinary semapore(Mutex) 의 경우에는 모니터에서 알아서 해주니까 별다른 로직이 필요 없었지만\n상호배제가 아닌 자원 개수 관리를 위한 Countable semapore 를 위해서 Condition 이 제공된다는 것이다\n\n\n\nCondition 은 다음과 같은 두가지 기능을 가진다\n\nCondition.wait(): 얘는 현재의 프로세스를 Block 시키고 해당 Condition의 큐에 추가한다\nCondition.signal(): 얘는 해당 Condition의 큐에서 프로세스 하나를 꺼내 Ready 로 바꾼다\n\n자고 있는 프로세스가 없을 경우에는 아무 작업도 하지 않는 로직도 signal() 에 내부적으로 구현되어 있다\n\n\n즉, 하나의 Condition 변수는 하나의 줄을 의미하고 두가지 기능으로 프로세스를 줄세우거나 줄에서 꺼내는 작업을 할 수 있는 것이라 생각하면 된다\n다만 세마포의 P와 V는 자원의 개수를 값으로 가지고 필요한 자원이 있는지 없는지는 내부적으로 확인하는 대신\nCondition 을 사용할 때에는 필요한 자원이 있는지 없는지에 대한 로직은 개발자가 알아서 작성하고 재우거나 깨우는 것만 Condition 변수를 이용한다는 차이점이 있다\n\n\n\n즉, Condition 을 통해 자원이 존재하지 않을 때 프로세스를 재우고 자원이 생기면 깨우는 로직을 손쉽게 구현할 수 있다\n(사진 사라짐)\n\n그래서 위에서 살펴본 Bounded-Buffer 문제를 Monitor 를 이용해 살펴보면 위처럼 됨\nBounded-Buffer 가 Property 로 드가있고\n여기에 접근할 수 있는 produce 와 consume 이 Method 로 드가있으며\nMonitor 자체에서 Mutex 가 지원되므로 Mutex 에 관련한 로직은 삭제되었고\n자원 개수 관리에 대한 부분만 Condition 으로 대체된 것을 확인할 수 있다\n\n그리고 Condition 으로 full 과 empty 두개의 줄을 생성하고\n조건에 따라 적절하게 프로세스를 해당 줄에서 대기하게 하거나 줄에서 꺼내는 등의 작업을 하게 됨\n\n\n\n\n\nMonitor vs Semapore §\n\n모니터와 세마포는 다음과 같은 방식으로 (거의) 1:1 변환된다\n\n모니터 하나당 Mutex 를 위한 세마포를 선언한다\n모니터의 Condition 하나당 Countable semapore 를 선언한다\n모니터 메소드의 로직 중 자원 체크 &amp; wait 혹은 signal 부분을 P 혹은 V 로 대체한다\n\n\n"},"os.fall.2022.ewha.ac.kr/7.-Deadlocks":{"title":"7. Deadlocks","links":[],"tags":[],"content":"(원문 사라짐)"},"os.fall.2022.ewha.ac.kr/8-1.-Memory-Address":{"title":"8-1. Memory Address","links":[],"tags":[],"content":"Logical, Physical, Symbolic Address §\n\n\nLogical Address (Virtual Address): 프로세스 각각이 가지는 가상 주소 공간 속의 주소\n\n즉 메모리 전체에 이 프로세스 하나만 올라가있다고 상상했을 때의 주소를 의미한다\n따라서 메모리 주소는 0번부터 시작\n이제부터는 별다줄로다가 LA라 표현해보자고\n\n\nPhysical Address: 실제 메모리의 주소\n\n실제 메모리의 주소이기 때문에 하위 주소에는 커널이 들어가고 상위 주소에 유저 프로세스들이 올라가게 된다\n얘는 PA 라 표현해보자고\n\n\nSymbolic Address 라는 것은 코드 작성시에의 변수를 의미하는 것\n\n즉, 코드에는 메모리 주소가 아닌 사람이 읽을 수 있는 형태의 문자열인 변수를 사용하게 되는데 이것을 Symbolic Address 라고 하는 것\n\n\n\nAddress Binding §\n\nAddress Binding: LA 를 PA 로 바꾸는 과정\n\n메모리에 접근하기 위해서는 LA 가 아니라 PA 가 필요한데 이를 위해 주소 변환 과정이 필요하게 된다\n\n\n\nBinding 시점에 따른 분류 §\n\nBinding 시점에 따라 종류를 세 가지로 나눠볼 수 있다\n\n\n\nCompile Time Binding: 컴파일 시점에 PA 까지 결정되는 것\n\n컴파일 시점에는 SA 가 LA 로 바뀌기 때문에 이때의 주소를 PA로 사용한다는 것은\n항상 LA와 PA 가 같고\n프로세스는 항상 (별도의 조치가 없는 한) PA 0번부터 적재되게 된다\n뭐 당연히 현대의 컴퓨터에서는 사용되지 않았지만 옛날에 컴퓨터에서 하나의 프로세스만 작동되던 시절에는 이런 방식의 바인딩을 사용했다더라\nLA 와 PA 가 같기 때문에 이러한 코드를 Absolute Code(절대 코드) 라고 부르고 컴파일러는 이것을 생성하게 된다\n\n\nLoad Time Binding: 프로그램이 프로세스가 되어 메모리에 적재되는 시점에 PA 를 결정하는 것\n\n얘는 위에놈보다 좀 더 합리적이제\n메모리 사용 현황은 계속해서 바뀌어서 컴파일 시점에는 메모리의 어느 부분에 적재할지 알기 힘들기 때문에 메모리에 적재할때 LA 와 PA 를 바인딩하자는 개념\n이때에는 컴파일러가 Relocatable Code (재배치 가능 코드) 를 생성한다\n\n\nRuntime Binding: Load Time Binding 과 유사하나 최초에 메모리에 적재된 이후에도 새롭게 바인딩이 될 수 있는 방법\n\n이것은 이제 프로세스의 Swapping 을 지원하기 위해 나온 것이다\n왜냐면 프로세스가 Swap out 되면 디스크로 쫒겨나게 되는데 이후에 다시 Swap in 할 때 기존의 PA 가 아닌 새로운 PA 에 바인딩될 수 있도록 해야 하기 때문\n당연히 요즘의 운영체제에서는 이 방법을 사용한다\n프로세스가 시작되고 종료되기 전까지 PA 가 계속 바뀔 수 있으므로 주소 변환 과정을 CPU 가 아닌 MMU 라는 별도의 하드웨어를 이용해 처리한다\n\n\n\nCPU 입장에서 §\n\n위 그림을 자세히 보면\n코드가 적재되는 위치만 바뀌고 코드에 작성되어 있는 주소는 바뀌지 않잖어\n따라서 CPU가 사용하는 (바라보는) 주소는 LA 이다\n왜냐하면 코드에 작성되어 있는 주소를 바꾸기 위해서는 컴파일을 새로 해야 되는데 Compile Time Binding 이 아닌 이상 불가능 하기 때문에 코드에 작성되어 있는 주소는 LA 로 놔두고 적재 위치만 바꾸게 되는 것\n\nMemory Management Unit (MMU) §\n\n\nMMU 는 주소 변환을 해주는 하드웨어 유닛인데\n다음과 같은 방식으로 작동한다\n\n일단 CPU 가 LA 를 이용해 주소를 달라고 요청\nLA 는 무적권 0번부터 시작하기 때문에 LA 가 곧 프로세스 주소 공간의 시작점으로부터의 Offset 을 나타냄 → 프로세스가 적재되어 있는 실제 메모리 상의 시작점의 주소만 알면 여기에 LA 를 더함으로써 PA 를 구할 수 있다\n\n이 시작점의 주소는 MMU 내의 Base Register (BA) 혹은 Relocation Register 에 저장된다\n\n\nPA 를 알아낸 이후에는 여기에 저장되어 있던 것을 읽어 CPU 로 전달\n\n\n\n\n\n위의 그림이 MMU 의 작동 과정을 나타내는 그림인데\nMMU가 주소 변환을 할 때에는 LA 가 유효한지를 먼저 검사하게 된다\n왜냐면 만약 프로세스의 주소 공간의 크기가 3000일 때 이것보다 큰 LA 요청이 들어오게 된다면 프로세스 바깥의 주소 공간을 참조하게 되는 것 이므로 다른 프로세스의 주소공간에 무단 침입하는 셈이기 때문이다\n따라서 MMU 에서는 Limit Register 라는 또 다른 레지스터를 이용해서 프로세스 주소 공간의 크기를 저장해 놓고 이것보다 큰 LA 요청이 들어오면 트랩을 걸어 기각시키게 된다\n\nDynamic Loading, Overlay §\n\n일단 Dynamic Loading 이라는 것은 프로세스의 전체가 메모리에 올라가는 것이 아닌 필요한 부분만 올라가는 기법을 의미한다\n이렇게 하는 이유는 당연히 메모리 효율을 올리기 위함 → 프로그램에는 자주 사용되지 않는 오류 처리 루틴이 많이 포함되어 있기 때문에 프로세스 전체를 올리는 것은 자주 사용하지 않는 부분까지 모두 올리는 것이어서 비효율적이다\nDynamic Loading 의 정확한 정의는 OS의 힘을 빌리지 않고 메모리에 동적으로 적재되는 것을 뜻한다\n\n현대의 OS 에서는 뒤에 나올 페이징 기법을 이용해서 프로세스를 동적으로 메모리에 올리게 되는데 이것은 Dynamic Loading 이 아님\n하지만 이 용어를 딱히 구별해서 사용하지는 않는다 → 정확한 정의와는 무관하게 페이징 기법을 사용하는 것도 Dynamic Loading 이라고 부르긴 한다\n\n\nOverlay 라는 것은 Dynamic Loading 과 유사하지만 용어가 등장한 배경이 좀 다르다\n\n일단 Overlay 도 프로세스를 쪼개서 메모리에 올리는 방법이지만\nOverlay 는 메모리의 크기가 너무 작아 프로세스 하나조차 올릴 수 없는 시절에 프로그램을 작성할 때 어느부분을 올릴지 수작업으로 프로그래밍하는 방법을 의미한다\n하지만 Dynamic Loading 의 경우에는 메모리의 크기는 넉넉하지만 사용율을 높이기 위해 라이브러리의 힘을 빌려서 동적으로 적재하는 것을 일컫는다\n\n\n\nSwapping §\n\n\n일단 Swapping 이라는 것은 프로세스 전체를 디스크 등의 Backing store 로 쫒아내는 것을 말한다\n앞선 강의에서 잠깐 언급되었던 것 처럼 Swapping 은 중기 스케줄러 (Mid-term Scheduler, Swapper) 에 의해 어떤 놈이 방출될지 결정된다\n\n당연히 우선순위가 높은 놈 보다는 낮은 놈을 방출시키는게 좋겠제 → 이것을 Swapper 가 결정하게 되는 것\n\n\n이 Swapping 은 Runtime Binding 이 필수적이다\n\nCompile Time Binding 이나 Load Time Binding 의 경우에는 Swap out 되었어도 원래 위치로 되돌아 와야 하기 때문에 비효율적\nRuntime Binding 이 되어야 Swap in 될 때 비어있는 공간으로 쓱 드갈 수 있기 때문에 필수적이다\n\n\nSwapping 에서는 읽어들여야 할 데이터의 양이 많기 때문에 대부분 Transfer Time 이 차지한다고 한다\n\n이놈은 뒤에 디스크 부분에서 배울거라는데\n디스크가 데이터를 읽어들일 때는 디스크 헤드가 움직이는 Search Time 하고\n데이터를 읽어서 보내는 Transfer Time 이 있는데\n\n파일입출력같은 경우에는 Transfer Time 보다는 Search Time 이 더 오래 걸리는 반면\nSwapping 의 경우에는 보내야 할 데이터의 양이 많아 Transfer Time 이 더 오래걸린다고 하더라\n\n\n\n\n이놈도 페이징 기법과 연루되면서 용어가 좀 모호하게 쓰인다\n\n원래는 프로세스 전체가 디스크로 쫒겨나는 것을 의미하지만\n정확한 정의와 다르게 페이징 기법에 따라 페이지가 쫒겨나는 것도 Swapping 이라고들 하더라\n\n\n\nDynamic Linking §\n\n일단 Static Linking 이라는 용어부터 알 필요가 있다\n\ngcc 로 컴파일 할때 보면 라이브러리들을 오브젝트 파일로 만들어서 링크시켜주는 과정을 통해 라이브러리 내에 있던 코드가 내 코드에 포함되도록 하자네\n이렇게 라이브러리에 있던 코드를 내 코드에 포함시키는 것을 Static Linking 이라고 한다\n\n\n반면에 Dynamic Linking 은 라이브러리 코드를 내 코드에 포함시키지 않고 필요에 따라 불러오는 것을 의미한다\n\nDynamic Linking 을 하면 라이브러리 코드는 별도의 코드로 존재하고\n내가 해당 코드를 사용할 때에는 코드 전체를 가져오는 것이 아니라 해당 코드를 참조할 수 있는 작은 코드 조각 (해당 코드를 가리키는 포인터라고 생각하면 됨 → Stub 이라고 부르더라)을 코드에 넣어서 실행시점에 링크시켜 주는 것을 의미한다\n리눅스에서 .so 파일 본적 있제? 이것이 Dynamic Linking 을 위한 코드이다 → Shared Object 의 약자임\n윈도우에서는 .dll 파일 본 적 있을텐데 이것이 Dynamic Linking Library 의 약자이다\n\n\n"},"os.fall.2022.ewha.ac.kr/8-2.-Physical-Memory-Allocation":{"title":"8-2. Physical Memory Allocation","links":[],"tags":[],"content":"Memory Section §\n\n앞서 배운것 처럼\n메모리의 하위 주소는 OS 영역으로 커널 코드가 드가게 되고\n상위 주소는 사용자 프로세스 영역으로 사용자 프로세스들이 적재된다\n\nContiguous Allocation §\n\nContiguous Allocation 은 프로세스 전체를 그냥 메모리에 때려박는 것을 의미한다\n\nFixed Partition (고정 분할 방식) §\n\n\n_고정 분할 방식_은 메모리 공간을 사이즈별로 미리 분할해놓고 프로세스를 나눠놓은 공간에 집어넣는 것을 의미한다\n사이즈가 작은 것부터 시작해서 나눠 놓은 공간에 프로세스가 드갈 수 있으면 거기 넣고 아차 싶으면 다음 공간 따라서 찾은 다음에 드갈 수 있는 데에다가 넣는 방식\n이때 프로세스들 사이사이에 사용되지 않은 부분을 External Fragmentation (외부 조각) 이라 하고\n하나의 분할 내에서 사용되지 않은 부분을 Internal Fragmentation (내부 조각) 이라 한다\n\nVariable Partition (가변 분할 방식) §\n\n\n솔직히 분할을 미리 나눠놓고 넣는 방식은 너무 비효율적이자네\n그래서 공간을 분할하지 않고 일단 프로세스를 차례차례 넣어놓는 방식을 _가변 분할 방식_이라 한다\n이때에는 External Fragmentation 만 발생한다 → 분할이 따로 존재하지 않기 때문에 프로세스가 종료되면 사이사이에 빈공간이 남게 되는 것\n가변 분할 방식에서 External Fragmentation 을 Hole 이라고도 한다\n\n\n\n운영체제는 프로세스가 할당되어 있는 공간과 비어있는 공간인 Hole 들에 대한 정보를 관리하고 프로세스를 적재할 때 활용하게 된다\n\n즉, 프로세스가 종료되면 Hole 에 포함시키고 프로세스가 적재될 때에는 드갈 수 있는 Hole 을 하나 골라서 적재하게 되는 것\n\n\n\nDynamic Storage Allocation Problem §\n\n이건 Hole 들 중에서 어떤 Hole 에 프로세스를 적재시킬지 결정하는 알고리즘들을 일컫는다\n\n\nFirst Fit: Hole 들을 순차탐색하다가 프로세스가 드갈 수 있는 첫번째 Hole 에다가 넣음\n\n장점: Hole 을 탐색하는 시간이 적게 걸림\n단점: 해당 Hole 이 최선의 선택이 아닐 수 있음\n\n\nBest Fit: 프로세스가 드갈 수 있는 Hole 들 중에 가장 작은 Hole 에 넣음\n\n가장 작은 Hole 에 넣기 때문에 더 작은 Hole 이 생길 수 있으므로 작은 Hole 들이 많이 생긴다\n장점: 최적의 Hole 에 넣을 수 있음\n단점: Hole 을 탐색하는 시간이 오래걸림\n\n\nWorst Fit: 프로세스가 드갈 수 있는 Hole 들 중에 가장 큰 Hole 에 넣음\n\n가장 큰 Hole 에 넣기 때문에 큰 Hole 들이 많이 생긴다\n얘는 단점이 많다\n\nHole 을 탐색하는 시간이 오래 걸림\n큰 Hole 에는 더 큰 프로세스가 들어갈 수 있지만 굳이 여기 넣어서 더 작은 Hole 로 만들어버림\n\n\n\n\n\n\n실험 결과 First Fit 과 Best Fit 에 비해 Worst Fit 의 효율성이 더 안좋은 것으로 알려져 있다\n\nCompaction §\n\nCompaction 은 External Fragmentation 을 없애기 위해 프로세스의 위치를 이동시켜 Hole 들을 하나로 모으는 것을 의미한다\n당연하게도 바인딩을 체크하는 등의 아주 많은 작업이 필요하기 때문에 오버헤드가 크다\n따라서 이것을 효율적으로 하기 위해 모든 프로세스를 옮기는 것이 아닌 최소한의 프로세스만을 움직여서 Hole 들을 모으는 방법이 필요한데 이것도 만만치 않다더라\n\nNon-contiguous Allocation §\n\n얘는 프로세스를 잘라 메모리에 적재하는 방식인데\n동일한 크기로 자르는 방식인 Paging 기법과\n코드의 의미 단위 (뭐 Code, Data, Stack 이랄지 함수별로 나누던지) 에 따라 가변크기로 자르는 방법인 Segmentation 기법\n이 둘을 합친 Paged segmentaion 기법이 있더라\n"},"os.fall.2022.ewha.ac.kr/9.-Virtual-Memory":{"title":"9. Virtual Memory","links":[],"tags":[],"content":"Demand Paging §\n\n\n얘는 페이지를 모두 메모리에 올리는 것이 페이지가 필요한 시점에 메모리에 올리는 방법을 의미한다\n\n\n장점은\n\nIO 감소\n\n한번 올릴때 페이지 단위로 올리니까\n\n\nMemory 사용량 감소\n\n필요한 페이지만 올리니까 예외처리코드같은 자주 실행되지 않는 코드들이 메모리에 불필요하게 올라가지 않음\n\n\n빠른 응답시간\n\n여러개의 프로세스가 작동하는 경우에 하나의 프로세스 전체가 메모리에 올라가고 나머지는 아주 일부분만 올라간다면 모두 올라와있는 놈은 빠르지만 나머지는 IO 가 많아져 느림\n하지만 Demand Paging 을 사용하면 각 프로세스의 필요한 부분만 올라와있기 때문에 프로세스 전체가 메모리에 올라와있는 것보다는 느릴 수 있겠지만 전체적인 응답시간은 빨라진다\n\n\n더 많은 사용자 수용\n\n프로세스당 실시간으로 사용하는 메모리의 양이 적으므로\n\n\n\n\n\n그래서 프로세스가 메모리에 올라가게 되는 전체적인 모습을 보면 아래와 같다\n(사진 사라짐)\n\n제일 왼쪽은 가상 메모리 공간을 할당받고 프로세스가 페이지별로 나뉘어진 모습이다\n\nA ~ F 까지는 가상 메모리 공간에서 프로세스가 실제로 차지하는 페이지들이고\nG ~ H 는 프로세스가 차지하지 않는 빈 페이지임\n\n\n그리고 오른쪽의 두 그림처럼 메모리에 적재되었다고 한다면\n\n페이지 A, C, F 만 Demand Paging 에 의해 실제 메모리에 적재되었고\n나머지 페이지들은 디스크에 스왑되어있는 상황\n\n\n그때 Page Table 은 왼쪽 두번째와 같다\n\n실제 메모리에 적재되어있는 페이지는 프레임 번호가 적히고 Valid 로 표시된다\n그리고 적재되어있지 않는 페이지는 Invalid 로 표시된다\n가상 메모리 공간에서 프로세스가 차지하지 않는 빈 페이지도 Invalid 로 표시됨\n\n\n당연한 이야기지만 프로세스가 처음 생성되었을때에는 Page Table 이 전부 Invalid 로 표시되어 있고 프로세스가 실행됨에 따라 필요한 페이지가 차츰 올라가며 Valid 로 바뀌게 된다\n\n\n\nPage Fault §\n\n\n근데 Demand Paging 을 하려면 어떤 페이지가 필요해서 OS 에 올려달라고 요청할 수 있어야 되는데 이를 위한 것이 바로 Page Fault 이다\n\n\n간단히 말하면 MMU 가 주소를 바꿀때 해당 주소가 Invalid 한 페이지에 있다면 트랩을 걸어 OS 로 하여금 해당 페이지를 적재할 수 있도록 하는 것\n\n\nPage Fault 의 처리 과정은 다음과 같다\n(사진 사라짐)\n\nInvalid 페이지를 참조\n\nMMU 는 이때 유효한 주소인지, Protection Violation 등이 없는지 추가적으로 체크한다\n\n\n(MMU 에 의해) Page Fault Trap 이 걸려서 OS 로 CPU가 넘어감\n\n\n\n실제 메모리에서 비어있는 프레임 (Free Frame) 을 할당함 → 이미 모든 프레임이 하나 사용중이면 하나를 디스크로 스왑시켜서 빈 프레임을 만들어낸다\n\n디스크에서 해당 페이지를 가져오고\n빈 프레임에다가 페이지를 채움\n\n3, 4번 과정은 Disk IO 과정이기 때문에 당연히 해당 프로세스는 Block 되어 다른 프로세스로 CPU 가 넘어간다\n\n\nPage Table 에다가 Frame 번호 및 Valid/Invalid 를 업데이트함\nReady 상태로 있다가 CPU 를 받으면 멈췄던 Instruction 부터 다시 실행\n\n\n\nPage Fault Rate §\n(사진 사라짐)\n\nPage Fault Rate p 를 위와 같이 정의한다면\n\n즉, 0이면 Page Fault 가 절대 나지 않음\n1이면 모든 참조에서 Page Fault 가 발생\n\n\np 는 실제 시스템에서 0.01 정도로 아주 낮게 나온다 → Page Fault 가 앵간하면 일어나지 않는다는 의미\n\nPage Replacement §\n\n위에서 Page Fault 루틴 설명할 때 빈 프레임이 없으면 기존의 프레임에 있는 페이지를 swap out 시켜서 빈 프레임을 만들어낸다고 했는데 그것을 Page Replacement 라고 한다\n\n(사진 사라짐)\n\n위 그림이 Page Replacement 의 과정인데\n\n희생양을 정하고 Swap out 한다\n\n이때는 페이지에 변화가 없을 때에는 그냥 냅둬서 Overwrite 되게 할 수 있지만\n만일 페이지 내용에 변화가 있을 때에는 변화된 내용을 디스크에 반영해주는 IO 가 필요하다\n\n\nPage Table 에서 Swap out 한 페이지의 Validity 를 업데이트한다\n요청된 페이지를 Swap in 한다\nPage Table 에서 Swap in 한 페이지의 Validity 를 업데이트한다\n\n\n당연히 Page Replacement 를 할 때에는 Page Fault Rate 가 최소화되도록 프레임을 선택해야 되는데\n이것을 위한 알고리즘이 Replacement Algorithm 이다\n\nOptimal Algorithm (Belady’s Algorithm) §\n\n\n다시는 참조되지 않거나 가장 먼 미래에 참조될 페이지를 Replace 하자는 생각\n\n\n하지만 미래의 일은 알 수 없기 때문에 비현실적이다 → 이에 따라 Optimal Offline Algorithm 이라고도 불림\n\n\n다만, 이 알고리즘이 Page Fault 를 최소화한다는 것이 증명되어 있으므로 다른 알고리즘들의 성능에 대한 척도를 제공해주는 역할을 한다\n\n\n아래의 예제를 보면\n(사진 사라짐)\n\n위 시나리오에서 일단 첫 4번은 어쩔 수 없다 → 페이지가 없으니 어쩔 수 없이 Page Fault 가 발생\n5번째 Page Fault 에서는 4번 페이지가 가장 나중에 사용되므로 4번이 5번으로 Replace\n6번째 Page Fault 에서는 5번만 나중에 사용되므로 사용되지 않는 페이지 아무거나 Replace\n\n\n\nFIFO (First In First Out) Algorithm §\n\n\n선입선출이다\n\n\n얘는 FIFO (혹은 Belady’s) Anomaly 라는게 있는데 이게 뭐냐면\n\n일반적으로 Frame 수가 늘어나면 Page Fault 는 줄어드는 것이 일반적인데\nFIFO 방식을 사용하면 Frame 수가 늘어났을 때 Page Fault 가 늘어날 수도 있다는 것이다\n아래 예시 보면 됨\n\n(사진 사라짐)\n\n\nLRU, LFU Algorithm §\nLRU (Least Recently Used) Algorithm §\n\n\n가장 오래전에 참조된 것을 지우는 것\n\n\n최근에 참조된 것이 다시 참조될 가능성이 높다는 성질을 이용\n\n\nFIFO 와의 차이점은 FIFO 의 경우 가장 오래전에 입장한놈을 지운다면 LRU 는 가장 오래전에 마지막으로 참조된 것을 지운다\n(사진 사라짐)\n\n\nLFU (Least Frequently Used) Algorithm §\n\n가장 덜 빈번하게 참조된 것을 지우는 것\n빈번하게 참조된 것이 다시 참조될 가능성이 높다는 성질을 이용\n\nLRU vs LFU §\n(사진 사라짐)\n\nLRU 랑 LFU 의 장단점을 극단적으로 보여주기 위한 예시인데 누가 개같이 쫒겨날지는 직접 해보면 알 수 있음\n이걸 토대로 LRU 랑 LFU 를 비교해보면\nLRU 는 제일 나중에 참조된 것을 내쫒긴 하지만 그놈이 제일 많이 참조된 놈이어서 참조 빈도에 대한 고려는 안된다는 단점이 있고\nLFU 는 제일 적게 참도된 놈을 내쫒았는데 마지막 참조 시점의 고려가 되지 않는다는 단점이 있다\n\n위의 예시에서는 하필 그놈이 제일 최근에 들어온 놈이어서 연속 참조에 장애가 걸리는 문제가 발생한다\n\n\n\n구현 §\n(사진 사라짐)\n\nLRU: 얘는 Linked List 형태로 구현한다\n\n즉, 참조되면 그놈을 제일 아래로 내려 제일 높은 우선순위를 갖게 하고\n내쫒을때는 제일 위에 있는 제일 낮은 우선순위를 내쫒음\n따라서 시간복잡도는 O(1) 이 됨\n\n\nLFU: 얘는 Heap 을 이용하여 구현한다\n\n참조 시점이 아니라 빈도가 중요하므로 다른 놈들과의 비교를 해야되는데\n비교할때는 Linked List 를 이용해 일렬로 비교하며 따라가는 것 보다는 Heap 을 이용해 Leaf 까지 따라가며 비교횟수를 줄이는 것이 좋기 때문\n\n\n\n한계 §\n\n실제로는 LRU, LFU 알고리즘을 이용해 Page Replacement 를 할 수는 없다\n왜냐하면 MMU 가 하드웨어 유닛이기 때문에 Page Reference 는 OS 의 관여 없이 기계적으로 일어나기 때문\nOS 가 관여하는 부분은 Page Fault 가 발생했을 당시이므로 어떤 페이지가 언제 혹은 얼마나 참조되었는지는 OS 가 알 수 없다\n\nClock Algorithm §\n\n\n위에서 제시한 LRU, LFU 알고리즘의 한계를 극복하기 위해 등장한 알고리즘\n\n\n다음과 같이 작동한다\n(사진 사라짐)\n\n일단 시계에서 네모는 각 페이지를 의미한다\n그리고 숫자는 Reference Bit 으로, 최근에 해당 페이지가 참조되었음을 나타낸다\n\nReference Bit 은 MMU 에 의해 1로 바뀌고 OS 에 의해 0으로 바뀐다\n\n\nPage Fault 가 발생하면 OS 는 시계방향으로 Reference Bit 가 0인 페이지를 찾는다\n\nReference Bit 가 1이라면 OS 가 0으로 바꾸고 다음 페이지로 넘어간다\n\n\nReference Bit 이 0인 페이지를 찾으면 해당 페이지를 Swap out 한다\n\n\n\n이렇게 하면 다음과 같은 효과가 난다\n\nPage Fault 가 일어나지 않는 동안은 MMU 가 Reference Bit 을 관리하며 참조되었던 페이지들을 표시한다\nPage Fault 가 일어나면 OS 가 MMU 가 표시한 Reference Bit 을 이용해 참조되지 않았던 페이지를 찾아 swap out 한다\n이때 swap out 되는 페이지는 OS 에 의해 0으로 바뀐 뒤에 시침이 한바퀴를 돌아 다시 돌아올 때 까지 한번도 참조되지 않았던 것이 보장되므로 충분히 옛날에 마지막으로 참조되었던 것으로 생각할 수 있다\n\n따라서 이것은 LRU 와 비슷하다고 할 수 있다\n즉, LRU 의 근사 (approximation) 알고리즘\n공통점 → 마지막 참조 시점을 기준으로 페이지를 고름\n차이점 → 마지막 참조 시점이 가장 오래된 놈이라고 할 수는 없음\n\n\n\n\n\n이놈은 다음과 같은 이름으로도 불린다\n\nSecond Chance Algorithm: Reference Bit 이 1이면 한번 봐주고 다음 페이지로 넘어감\nNUR(Not Used Recently) 혹은 NRU(Not Recently Used): LRU 에서 Least 가 Not 으로 바뀜\n\n\n\nReference Bit 이외에도 Modified Bit 을 이용해 더욱 개선할 수도 있다\n\nModified Bit (Dirty Bit) 을 이용해 페이지가 변경되지 않았으면 IO 없이 swap out 하여 Overwrite 되게 함\n\n\n\nPage Frame Allocation §\n\n이것은 프로세스 하나에게 몇개의 Frame 을 할당할 것이냐인데\n이것이 중요한 이유는 다음과 같다\n\n프로세스는 실행코드 말고도 데이터와 협력해야되는 경우가 많으므로 여러 페이지에 동시에 참조할 일이 빈번하다\n또한 Loop 의 경우에는 해당 코드를 담은 페이지가 전부 올라와 있어야 Page Fault 가 안난다\n\n만약 Frame Allocation 이 2개인데 Loop 의 코드가 3 frame 을 필요로 한다면 1개의 페이지가 계속해서 Page Fault 가 날 것이기 때문\n\n\n\n\n다음과 같은 방법으로 할당할 수 있다\n\nEqual Allocation: 모두 똑같은 개수 할당\nProportional Allocation: 프로세스 크기에 따라 할당\nPriority Allocation: CPU 우선순위에 따라 할당\n\n\n이렇게 할당해 놓고 Replace 를 할때에는 해당 프로세스의 페이지 내에서만 Replace 되게 하는 방법을 Local Replacement 라고 한다\n하지만 프레임의 개수를 할당하지 않고 Replace Algorithm 에 따라 프로세스간 프레임을 경쟁하도록 하여 프레임 할당을 유동적으로 관리하는 것을 Global Replacement 라고 한다\n\n이렇게 하면 자연스레 프레임을 많이 필요로 하는 프로세스는 다른 프로세스의 페이지를 방출시켜 많이 차지하게 하고 해당 프로세스가 종료되면 자연스레 방출되어 다른 프로세스가 프레임을 차지할 수 있도록 할 수 있다\n\n\n\nThrashing §\n(사진 사라짐)\n\n일반적으로 메모리에 많은 프로세스가 올라오면 (= Degree of Multiprogramming 이 증가하면) CPU Utilization 은 올라간다\n하지만 어느 수준이 되면 프로세스 하나당 충분한 프레임이 확보되지 않아 Page Fault 가 너무 빈번하게 일어나 CPU Utilization 이 떨어지게 된다 → 이 시점을 Thrashing 이라고 한다\n\n이 구간에는 CPU Utilization 이 낮아 OS 가 더 많은 프로세스를 메모리에 올리려고 하고, 그러면 Page Fault 가 더 빈번하게 일어나는 악순환이 계속됨\n\n\n따라서 이것을 막기 위해서는 Degree of Multiprogramming 을 조절할 필요가 있다\n\nWorking Set Algorithm §\n\n\n페이지를 참조할때는 특정 시점에 빈번하게 참조하는 페이지가 한정되어있다는 Locality 에 착안해서\n\n\n빈번하게 참조하는 페이지들의 집합을 Working Set 이라고 부르고 WS 의 크기가 할당된 프레임의 개수보다 크면 그냥 해당 프로세스 전체를 Swap out 시켜버리는 알고리즘이다\n(사진 사라짐)\n\n\n저 WS 를 구하기 위해 Working Set Window 라는 것을 이용하는 데 이것은 페이지 참조 시퀀스에서 특정 시점의 최근 n 개의 참조 페이지를 의미한다\n\n위 그림의 예시로는 n 이 10이라고 할 수 있는 것\n이 Working Set Window 만큼의 페이지들을 집합으로 만들어 그의 개수를 기준으로 프로세스를 방출할지 말지 결정하는 알고리즘\n\n\n\nPFF (Page-Fault Frequency) Scheme §\n(사진 사라짐)\n\n얘는 Page Fault Frequency 를 추적해서 Page Fault Rate 가 일정 수준이 유지될 수 있도록 하는 것이다\n그래서 위 그림에서 보이는 것 처럼 상한 (Upper Bound) 와 하한 (Lower Bound) 를 정해놓고 상한보다 올라가면 프레임 할당을 더 증가시키고 하한보다 내려가면 프레임 할당을 줄여주는 방식\n\nPage Size §\n\nPage 사이즈가 너무 작다면\n\n장점\n\nInternal Fragmentation 의 감소\n필요한 정보만 메모리에 올라옴\n\n\n단점\n\n페이지 테이블 크기가 증가\nDisk Transfer 의 효율성 감소 (디스크에서 데이터를 찾는 것에서의 효율성)\n\n\n\n\n요즘 트랜드는 Page 사이즈를 크게 하는 것이랜다 (현재는 4Kb 정도)\n"},"os.spring.2021.cnu.ac.kr/(충남대)-운영체제-강의록":{"title":"(충남대) 운영체제 강의록","links":["os.spring.2021.cnu.ac.kr/1.-인터럽트,-타임쉐어링","os.spring.2021.cnu.ac.kr/2.-프로세스","os.spring.2021.cnu.ac.kr/3.-쓰레드","os.spring.2021.cnu.ac.kr/4.-Concurrency","os.spring.2021.cnu.ac.kr/5.-Semaphore","os.spring.2021.cnu.ac.kr/6.-Deadlock-&-Starvation","os.spring.2021.cnu.ac.kr/7.-메모리-관리","os.spring.2021.cnu.ac.kr/8.-가상메모리","os.spring.2021.cnu.ac.kr/9.-Segmentation","os.spring.2021.cnu.ac.kr/10.-CPU-Scheduling","os.spring.2021.cnu.ac.kr/11.-Multicore-Scheduling","os.spring.2021.cnu.ac.kr/12.-IO-&-Disk-Scheduling","os.spring.2021.cnu.ac.kr/13.-File-Management"],"tags":[],"content":"Table of Contents §\n\n1. 인터럽트, 타임쉐어링\n2. 프로세스\n3. 쓰레드\n4. Concurrency\n5. Semaphore\n6. Deadlock &amp; Starvation\n7. 메모리 관리\n8. 가상메모리\n9. Segmentation\n10. CPU Scheduling\n11. Multicore Scheduling\n12. IO &amp; Disk Scheduling\n13. File Management\n"},"os.spring.2021.cnu.ac.kr/1.-인터럽트,-타임쉐어링":{"title":"1. 인터럽트, 타임쉐어링","links":[],"tags":[],"content":"DMA §\n\nDirect Memory Access : IO모듈을 따로 두어서(IO 전담 프로세서) 이 과정을 책임짐 - cpu가 IO작업을 하지 않는다\nIO : 입출력받는 모든 일 - 키보드 모니터 프린터 등 - IO모듈이 하는 일은 이 중에서도 필요한 데이터를 하드디스크에서 갖고오는 일을 한다\n이전에는 원하는 데이터가 메인메모리에 없으면 cpu가 하드디스크로 갖고왔음 - cpu가 직접 갖고오는 것을 Programmed IO라고 한다)\nSystem bus : 컴퓨터 내에서 데이터들이 아동하는 통로(전선)\nIO module안에는 buffer가 있어서 하드디스크로부터 가져온 데이터를 cpu가 가져가기 전까지 임시로 보관하게 된다\n\nInterrupt §\n\nIO Interrupt : IO모듈이 제대로 된 데이터를 갖고왔는지 cpu가 확인해야하기 때문에 IO모듈이 interrupt를 거는 것 - 이러한 IO방식을 Interrupt driven IO라고 한다\nInterrupt라는 것은 어떤 중요한 이벤트가 발생해 cpu가 지금 하던일을 멈추고 새로운 이벤트에 대응해야 된다고 cpu에 알려주는 것을 의미한다\n\nMemory hierachy §\n\nMemory hierarchy : 하드디스크 → 메인메모리 → 캐쉬 → 레지스터 계층구조를 의미함\n가격, 속도, 유지 등의 요소를 고려해 적절한 메모리 계층구조를 가지게 된다\n\nProcessor §\n\nProcess : 프로그램이 OS로 오면 실행가능한 프로그램을 process라고 부름\n이 process들을 실행하는게 processor\n\nCPU, GPU, DSP §\n\nCPU 는 명령어를 빠르게 처리하지만\nGPU 는 수학적 계산을 빠르게 처리하기 위해 나온 프로세서\nDSP(Digital Signal Processor) 로 음악이나 비디오 등의 시그널 처리를 담당한다\nCCP(Crypto Co-Processor) 로 암호처리를 담당한다\n\n프로세스의 처리 과정 §\n몇가지 레지스터들 용어정리 §\n\n기억안날까봐 다시 한번 설명해준다\nPC(Program Counter) : 다음으로 실행할 instruction이 들어있는 주소를 저장하는 레지스터\nIR(Instruction Register) : PC에 담긴 주소로 가서 가져온 instruction을 저장하는 레지스터\nAC(accumulator) : 임시저장소\n\nFetch §\n\nPC에서 주소를 읽어 메모리의 해당 주소로 간다\n거기 저장되어있던 instruction을 IR에 load한다\n\nExecute §\n\nIR에 load된 instruction을 실행하고 다시 Fetch를 반복한다\n\nInterrupt의 종류 §\n\nProgram : overflow, division by zero등의 상황이 일어났을 때\nTimer : 타임쉐어링 시스템에 의해 프로세스가 할당받은 시간이 만료되었을때\nIO : IO module이 데이터를 하드디스크로부터 갖고왔을 때\nHardware : memory parity failure등의 하드웨어적 이벤트가 일어났을 떄\n\nInterrupt가 발생했을 때 §\n\n기존 프로세스는 멈춰서 기다리고 interrupt handler가 interrupt를 해결하고 그 다음 줄로 넘어와 계속 코드를 실행하게 된다\nIDT : Interrupt Descriptor Table / IVT : Interrupt Vector Table : error, interrupt를 해결할 수 있는 코드의 위치(주소)를 정리한 표가 있는데 이제 interrupt handler는 이 표에 가서 지금 일어난 interrupt를 해결할 수 있는 코드가 어디에 있는지를 알아내 실행하게 된다\nSystem Call Table : 이것은 시스템 콜을 처리하는 코드의 위치(주소)를 정리한 표인데 이 표가 저장된 주소도 IDT의 마지막에 들어있다\n따라서 하나의 instruction을 execute다음에는 &lt;반드시&gt; interrupt가 일어나는지 검토하는 작업이 이루어진다\n\nMultiple interrupt §\n\n여러개의 interrupt가 일어났을 때 처리하는 방식은 두가지가 있다\nDisable/sequential : interrupt가 일어난 순서대로 처리하는 것 - 하나의 interrupt를 다 처리하고 나서 다음것이 실행됨 - interrupt를 처리하는 중간에 또다른 interrupt가 발생해도 처리하던 interrupt를 계속 처리한다\nNested : priority를 정해서 처리하는 것 - interrupt가 처리되는 와중에 새로운 interrupt가 발생했을 때 우선순위를 따져서 높은걸 먼저 처리하고 낮은걸 나중에 처리한다 - 낮은 interrupt가 발생하면 disable처럼 하던거 계속 하고 높은게 발생하면 중단하고 높은거 처리한 다음에 넘어와서 계속 처리 하는 구조이다\n\nOS §\n\nOS : 이러한 하드웨어들이 제대로 굴러가도록 관리하는 소프트웨어\n\nOS가 제공하는 서비스들 §\n\n프로그램 개발\n프로세스 실행 - process management - 프로세서와 연관\nIO기능 을 사용할 수 있게 함 - IO managemant\n파일들에 접근 할 수 있도록 해줌 - 리눅스의 경우 file discriptor를 통해서 파일들에 접근할 수 있게 해주는거 알쥬? - file management - 하드디스크와 연관\n시스템에 접근 / 다른 프로세스의 자원 등에 함부로 접근하지 못하게 하는 등의 protection - Memory protection이라고 한다 - memory management - 메인메모리와 연관\n에러에 대한 대응\n컴퓨터의 사용자가 여러명일 경우 누가 얼마나 썼는지를 계산 - 보통 클라우드에서 중요하다\n\nKernel §\n\nKernel은 OS의 핵심부분을 일컫는 말이다\nOS는 아주 사이즈가 크기 때문에 kernel이라는 핵심만 메모리에 상주하게 된다\n요즘은 컴퓨터의 성능이 놓기 때문에 커널의 사이즈를 점차 줄여나가는 microkernel이 추세이다\n\nProcess §\n\n프로그램이 실행되기 위해서는 메모리에 공간을 할당받아야 하고 또 그자리에 load되어야 하고 cpu time도 체크해야 되고 등등의 여러 데이터 구조와 여건이 갖춰져야 한다\n이런 여건들을 갖춰 os가 관리할 수 있는 실행 가능한 상태가 된 프로그램을 process라고 한다 - program in execution\n프로그램은 그냥 자료의 단위이고, 프로세스가 되어야 실행의 단위가 된다\n\n프로세스 실행의 종류 §\n\nBatch processing : 유사한 프로그램들을 한꺼번에 처리하는 것\nMulti programming(Concurrent Programming) : IO 등의 인터럽트가 일어나서 CPU가 기다리는동안 놀지 않고 다른 프로세스를 가동하는 것 - time sharing도 인터럽트를 발생시키지만 time sharing에 의한 인터럽트는 multi programming 이라고 하지 않는다 &lt;-&gt; 반대개념으로는 uniprogramming이 있다\nMulti processing(Symmetric Multi Processing - SMP) : 여러개의 코어를 갖는 CPU를 이용해 말 그대로 프로세스를 여러개 가동시키는것 - Multi programming과 헷갈리지 말아야 한다 - Multi programming의 경우에는 코어가 한개여도 가능하다 &lt;-&gt; 반대개념은 uniprocessing이다(싱글코어인 것)\nDistributed computing : 컴퓨터 여러개를 하나로 묶어 마치 하나의 컴퓨터처럼 움직이게 하는 개념\n\nTime sharing system §\n\nIO가 안일어나서 cpu가 쉬는경우가 안일어나면 하나의 프로그램이 cpu를 계속 사용하는 일이 일어나게 된다 - monopolize라고 한다\n이것을 방지하기 위해 각각의 프로세스에 시간을 할당하는 time sharing system이 나오게 된다\n\nUser mode vs Kernel mode §\n\nuser mode : 일반적인 사용자 모드. 일반적인 instruction들을 사용하고 접근이 제한된 메모리 공간에는 접근하지 못한다\nkernel mode : 관리자 모드 같은것. 시스템의 중요한 부분을 변경하는 privileged instructions들과 제한된 메모리 공간에 접근하는 것도 가능하다\nprivileged instructions나 제한된 메모리 공간에 무분별하게 접근해 시스템이 오작동하는 것을 막기 위해 os는 프로세스의 실행 모드가 유저인지 커널인지를 확인하게 된다\n\nUNIX 시스템 작동 순서 §\n\n\nUser → (command) → Command interpreter → (system call) → OS → (instructions) → Hardware\nsystem call은 OS와 밀접한 함수를 뜻하며 privileged instruction의 바로 상위 레벨 언어라고도 할 수 있다\n"},"os.spring.2021.cnu.ac.kr/10.-CPU-Scheduling":{"title":"10. CPU Scheduling","links":[],"tags":[],"content":"Short, mid, long - term Schedule §\n\n\n일단 Ready Queue에 있다가 Dispatch가 되어서 CPU를 할당받는 작업이나 Timeout이 걸려 Ready Queue로 내려가는 것, IO등의 이벤트로 인해 Block되는 작업 은 가장 빈번하게 일어나기 때문에 이것에 관련된 정책을 Short-term Schedule 이라고 한다\n그리고 메모리에 자리가 없어서 Ready상태에 있던 놈이 swap-out되는 Ready, Suspend나 Block된 놈이 Swap-out되는 Blocked, Suspend의 경우에는 적당히 일어나기 때문에 이것에 관련된 정책을 Mid-term Schedule라고 한다\n또한 프로세스가 folk되어 new state에 있다가 자원을 모두 할당받으면 Ready state가 되는데 너무 많은 프로세스가 Ready queue에 있으면 시스템에 부담이 되기 때문에 new state에서 자원을 할당받는거를 기다리게 되는데 이러한 과정은 잘 일어나지 않기 때문에 이것에 관련된 정책을 Long-term Schedule이라고 한다\n\n\n\n따라서 new, exit과 관련된 작업은 Long-term Schedule, suspend와 관련된 작업은 Mid-term Schedule, Running, Ready, Blocked랑 관련된 작업은 Short-term Schedule이라고 할 수 있다\nMid-term Scheduling과 Long-term Scheduling은 메인메모리에 올라가는 프로세스의 갯수와 연관된다는 점에서 Multiprogramming Level을 조절해주는 역할을 하게 된다\n\nShort-term Scheduling §\n\nDispatcher, Short-term Scheduling, CPU-time Scheduling 다 비슷한 말이다\n자주 일어나기 때문에 이 과정이 빠르게 일어날 수 있도록 알고리즘을 짜야되고\n빠른것 뿐만 아니라 모든 프로세스에게 공평하게 자원이 돌아갈 수 있도록 알고리즘을을 짜야 된다\n\nCriteria §\n\nShort-term Scheduling의 알고리즘을 선택하는 기준(Criteria)\nTurnaround Time : 어떤 프로세스가 생성되고(new) 종료(exit)될때까지 걸린 시간\n\n프로세스가 생성된 후에는 여러번의 wait과 running을 거치기 때문에 Trunaround Time은 총 Service Time(Running Time)과 총 Waiting Time의 합이다\n일단 프로세스가 생성된 후에 일을 마치고 종료되는 시간이 짧으면 좋기 때문에 Turnaround Time이 짧으면 좋은데\n프로세서가 같다면 저 프로세스가 실행되는데 걸리는 시간은 동일하기 때문에 Service Time은 동일하다\n따라서 Waiting Time을 줄이는 것이 관건이며 이것들의 평균인 Average Waiting Time 혹은 Service Time까지 합쳐서 Average Turnaround Time이 낮은 Scheduling Algorithm을 선택하는 것이 효율적이다\n\n\nResponse Time : 얘는 프로세스의 실행 후 첫번째로 결과물이 나오는(뭐 printf로 뭔가가 출력되게 한다던지)데까지 걸리는 시간을 의미한다\n\n얘도 당연히 적을수록 좋지만 결과물을 출력하는 지점을 어디에 설정하느냐에 따라 값이 달라지기 떄문에 CPU Scheduling Algorithm을 선택하는 데에는 별로 중요한 척도가 되지 못한다\n하지만 사용자 편의성의 관점에서 보자면 매우 중요 - 일례로 여러 클라이언트가 접속하는 서버의 경우에는 첫번째로 받게되는 결과물이 완성된 html파일이기 때문에 이 response time이 이러한 경우에는 아주 중요한 척도가 된다\n\n\nDeadlines : 얘는 이제 반드시 이 시간 내로는 프로새스가 완전히 실행되어 종료되어야 한다라는 뜻을 가지고 있다 - 특히 아주 중요한 실시간 프로그램의 경우\nThroughput : 얘는 단위시간 내에 몇개의 프로세스가 종료되는지이다 - service time이 얼마나 걸리는지와 scheduling algorithm에 따라 많이 달라지더라 - 얘도 당연히 많이 끝내면 좋은거이기 때문에 클수록 좋은거다\nProcessor Utilization : CPU 이용률을 의미 - CPU를 많이 이용할수록 더 좋다\n\n알고리즘측면에서는 높으면 높을수록 좋기는 하지만 실제로는 100퍼센트까지 올라가면 시스템이 다운될수도 있기 때문에 대략 50-60퍼센트정도로 유지시킨다\n\n\nEnforcing Priority : 프로세스들에게 우선순위를 주어서 우선순위가 높은 프로세스를 먼저 CPU에게 할당하는 알고리즘\n\nPriority Queuing §\n\n\n커널 프로세스같은 중요한 프로세스는 fixed priority를 가질수도 있지만 유저 프로세스 대부분은 우선순위가 바뀌는 dynamic priority를 가지게 된다\nCPU time(timeout과 관련된 시간이 아니고 지금까지 총 할당받은 시간)이 많은 놈은 우선순위를 좀 낮추고 총 waiting time이 많은놈의 경우에는 우선순위를 높여서 빈부격차를 줄인다\n저 RQ가 프로세스 우선순위에 따른 큐 이고 상위계층의 큐가 다 비어야 그 다음의 큐에 들어있던 프로세스가 실행되게 된다\nPre-emptive라는 것은 낮은 우선순위를 가진프로세스가 실행되다가 높은 우선순위의 프로세스가 들어오면 낮은 우선순위의 프로세스를 중단시키고 높은 우선순위의 프로세스로 문맥을 교체시키는 것을 의미하고 Non Pre-emptive라는 것은 데드락에서 배운거처럼 반대로 높은 우선순위의 프로세스가 들어와도 현재 프로세스를 중단시키지 않는 것을 의미한다\n\nSelection Function(Algorithm) §\n\nw는 waiting time을 뜻하는 기호\ne는 execution time을 뜻하는 기호\ns는 service time 을 뜻하는 기호\n\n여기서 e과 s의 차이는 s는 프로세스가 종료되기까지 필요로 하는 CPU time 총 시간을 의미하고 e는 지금까지 얼마만큼의 CPU time을 할당받았냐를 의미\n따라서 e = s가 될때 프로세스가 종료되게 된다\nTurnaround time은 w + s가 되는 것\n\n\n\nAlgorithm §\n\n\n위처럼 프로세스 5개의 도착시간(Arrival Time)과 종료되기까지 필요로 하는 시간(Service Time)이 있다고 할 때\nFirst Come First Served(FCFS) 알고리즘\n\n\n\n얘는 무적권 먼저 도착한놈한테 먼저 CPU 를 할당해주는 것을 의미\n\n\n\n이때의 Turnaround time은 위와 같다\n이 표를 읽는 방법은 우선\nFinish time은 말 그래도 끝난 시간을 의미하고\nTurnaround time은 Finish time에서 Arrival time을 뺀 시작에서부터 종료되기까지 걸린 시간\n그리고 Tr / Ts 는 Turnaround time / Service time 이다 - 즉, 총 걸린 시간을 실제 작동한 시간으로 나눈 것을 의미\n\nTr / Ts 가 1이라는 것은 waiting time이 하나도 없었다는 것을 의미하고 1보다 크다는 것은 waiting time이 존재했다는 뜻으로도 생각할 수 있음\n그리고 이 값이 클수록 waiting time의 비율이 높은거이기도 하다\n\n\n위의 그래프를 Gantt chart라고 하고 저런 표들이나 이 차트를 주고 w, s, 등등을 구하는 문제 나온댄다\nFCFS의 경우에는 프로세스가 종료되기 전까지 CPU를 뺏지 않으므로 No Pre-emptive라고 할 수 있다\n하지만 만약 제수없게 실행시간이 엄청 긴 프로세스가 먼저 오면 w가 엄청 커지게 되는 단점이 있는데 이것을Convoy effect라고 한다\nRound Robin(RR)\n\n\n\n얘는 q 단위시간마다 프로세스를 교체시키는 알고리즘이다\ntime quantum(q) 는 얼마의 단위시간마다 프로세스를 교체할건지를 의미한다\n위의 차트는 q = 1인 상황으로 1 단위시간마다 프로세스가 교체되는 것을 알 수 있으며\n처음에 A프로세스의 경우에는 1 단위시간을 실행하고 난 다음에도 아무 프로세스도 들어오지 않았기 때문에 1단위시간을 더 실행하게 되는 것\n그리고 할당된 시간이 끝나고 누구에게 넘겨줄 것인가를 결정하는 것을 Tie Break Rule이라고 하는데 위의 그래프에서는 FCFS방식으로 넘겨줬기 때문에 먼저 들어온놈에게 프로세스가 넘어가는 것\n하지만 Tie Break Rule을 execution time이 적은놈이라고 정하면 또 차트가 달라질 수도 있다\nRound Robin의 경우에는 q를 너무 짧게 잡으면 context switch가 자주 일어나기 때문에 별로 좋지 않다 - 어쨋든 context switch가 일어난다는 것도 추가적인 시간을 잡아먹는 일이기 때문\n이렇듯 q를 너무 짧게 잡으면 context switch가 너무 자주 일어나게 되고 너무 길게 잡으면 FCFS와 다를바가 없기 때문에 보통 q 시간 내에 80퍼센트의 프로세스들이 종료될 수 있도록 q값을 설정해준다\nRound Robin은 같은시간동안 순서대로 프로세스들에게 CPU를 할당해주기 때문에 interactive program에서 자주 쓰인다\nRound Robin의 경우에는 정해진 시간이 지나면 CPU를 뻇으므로 Pre-emptive라고 할 수 있다\nShortest Process Next(SPN)\n\n\n\n얘는 프로세스가 종료되고 난 후에 가장 Service time이 적은 프로세스로 옮겨가는 알고리즘이다\n얘도 프로세스가 종료되기 전까지는 CPU를 뺏지 않으므로 Non Pre-emptive라고 할 수 있다\n이 알고리즘은 waiting time의 평균이 다른 알고리즘들보다 작다 - 프로세스가 필요로 하는 총 Service time을 알기 어렵다는 점에서 현실적으로는 구현하기 힘들고 어떤 알고리즘의 효율을 비교하는데 사용하는 이론적인 알고리즘이다\n즉, 어떤 알고리즘이 있을 때 waiting time이 SPN에 근접하면 좋은 알고리즘인거고 너무 차이가 많이 나면 안좋은 알고리즘인 셈\nShortest Remaining Time(SRT)\n\n\n\n얘는 SPN의 Pre-emptive 버전 이다\n작동방식은 새로운 프로세스가 들어왔을 때 지금 실행하고있는것의 남은시간(Remaining time)과 새로 들어온놈의 Service time을 비교해 짧은놈이 실행되게 하는 것\n위의 예시로 보자면 일단 2시에 B가 들어왔는데 A는 1시간만 있으면 종료되므로 그대로 A를 실행한거고\n그다음 B를 실행하다가 4시에 C가 들어왔는데 B는 종료되려면 5시간이 남았고 C는 4시간이면 종료되기 때문에 C로 프로세스를 교체한 것을 알 수 있다\n얘는 SPN보다도 더 waiting time이 짧으나 SPN과 마찬가지로 service time과 remaining time을 알 수 없기 때문에 이론적으로만 존재하는 알고리즘이다\n따라서 마찬가지로 어떤 알고리즘의 효율성을 비교할때 사용되는 기준점을 제시해주는 역할을 함\nHighest Response Ratio Next(HRRN) : 얘는 다음과 같은 수치를 이용해 다음 실행될 프로세스를 결정한다\n\n\n\n여기서 일단 aging이라는 용어가 나온다 - 오래 기다려서 folk된지 오래된 프로세스를 나이가 드는것에 빗대어 waiting time이 긴 프로세스일수록 age가 많다고 판단 - 이런 프로세스에게 우선권이 넘어가도록 한다\n그래서 위 수식을 보면 일단 waiting time이 길수록 저 ratio가 커지게 되고\n그리고 service time적을수록 ratio가 커지게 되어 - SPN과 SRT를 생각해보면 service time이 적은 프로세스를 먼저 실행시키는 것이 waiting time을 줄이는 방법이므로\n종합적으로 ratio가 크다는 말은 waiting time이 크거나 service time이 작다는 말이므로 ratio가 큰 프로세스를 선택하는 것\n하지만 이 역시도 service time을 알아야 하기 때문에 구현하기에는 어려움이 많은 알고리즘이다\nFeedback Scheduling : 얘는 이제 waiting time을 줄이려면 service time을 알아야 가능하다는 생각에서부터 출발한 알고리즘이다\n\n\n\n일단 이 알고리즘은 우선순위에 따라 여러개의 큐가 존재하는데\n예를 들어서 n이 2까지 있어서 3단계로 우선순위를 나눈다고 해보자\n이때 첫번째 큐(RQ0)의 경우 RR로 작동하고 q를 1로 두고\n두번째 큐(RQ1)도 RR로 작동하는 대신 q를 2로 두고\n세번째 큐(RQ2)는 FCFS로 작동한다고 해보자\n이때 프로세스가 생성되면 전부 RQ0로 집어넣은 다음\n프로세스를 실행시켜 RQ0에서 1 단위시간 내에 끝나면 그냥 끝나는거지만\n만약에 1 단위시간 내에 안끝내면 RQ1으로 내려보내고 RQ0이 비기 전까지는 RQ1을 실행하지 않게 된다\n그리고 RQ0이 비게 되면 그제서야 RQ1를 실행하게 되는데\nRQ1에서 2 단위시간 내로 프로세스가 종료되면 그냥 끝나는거지만 만약에 2 단위시간 내로 끝나지 않으면 이제 RQ2로 내려보내고\n마찬가지로 RQ1이 비기 전까지는 RQ2를 실행시키지 않는다\nRQ1까지 비게 되면 이제 RQ2를 실행시키는데 얘는 FCFS이기 때문에 들어온 순서대로 프로세스가 종료될때까지 실행되게 된다\n대신 새로운 프로세스가 실행되어 RQ0으로 들어오면 지금 하던일을 멈추고 RQ0으로 가서 실행시킴 - 따라서 Pre-emptive 하게 작동한다고 할 수 있다\n이런식으로 우선순위마다 큐를 여러개 두고 각 큐마다 다른 알고리즘을 적용시키되 각 큐들의 Quantum Time을 다르게 두어서 먼저 끝나는 프로세스를 먼저 실행시킬 수 있게 하는 것이다\nservice time을 실행시키는 당시에는 알 수 없기 때문에 시간제한을 두고 일단 실행시켜서 시간제한 내에 종료되면 service time이 짧은 놈을 먼저 실행시킨 꼴이므로 waiting time을 줄이는 효과를 가져오고\n그리고 제한시간 내에서 끝내지 못했으면 일단 service time이 제일 적은놈은 아니라는 것이 증명되므로 우선순위를 낮춰 나중에 실행되게 하는 꼴이고\n마지막 우선순위에 도달할때까지 종료되지 못했으면 service time이 아주 오래걸린다는 소리이므로 제일 나중에 FCFS같은 Non-preemptive한 알고리즘으로 실행시켜 나머지 과정을 마무리 짓는것\n즉, 시간제한을 여러개를 두어서 service time을 직접 실행시키면서 추론하는 방식으로 service time이 짧은 프로세스를 먼저 실행시키는 효과를 내어 waiting time을 줄이고하 하는 알고리즘이 Feedback Scheduling이다 - 상위 우선순위에서 끝마치지 못해 하위 우선순위로 내리는 것을 Feedback이라고 한다\n이 알고리즘이 요즘의 많은 OS에서 채택하고 있는 Scheduling 방식이다\nFair Share Scheduling(FSS) : 이게 현재 UNIX시스템에서 채택하고있는 Scheduling 방식이다\n\n\n\n일단 위의 수식을 이해할 필요가 있다\n일단 **CPUj(I)**는 현재의 CPU time을 나타낸다 - 그럼 **CPUj(I - 1)**은 바로 이전의 CPU time을 나타내것제\n그리고 Base랑 nice는 일단은 그냥 상수값으로 생각해래이\n그럼 위의 수식에 따라 현재의 CPU time은 이전의 CPU time의 절반이 되고\n그걸 또 Priority(위의 수식에서는 Pj(I))를 계산할때는 현재의 CPU time에서 절반을 나누므로 결과적으로는 이전의 CPU time에서 4를 나눈 값으로 계산하게 된다\n그리고 다음의 예시를 이해해보면\n\n\n\n일단 먼저 프로세스 A, B, C가 동일한 시간에 들어왔다고 해보자\n그리고 여기에서 Base랑 nice의 합은 60이라고 가정해보자\n일단 셋이 같이 들어왔고 CPU time도 0이므로 Priority는 60이 되어 셋 다 동일한 상태이다\n어차피 차이가 없으므로 A를 먼저 선택했을 경우\n보면 1 단위시간동안 CPU time동안 CPU time이 60씩 증가하게 된다 - 따라서 프로세스 A가 실행되는 0 ~ 1의 시간에는 CPU time이 60이 된다\n근데 다음 1 ~ 2의 기간에는 A의 경우 이전의 CPU time이 60이었으므로 4로 나눠 15가 되기 때문에 이것을 Base와 nice에 더해 Priority가 75가 된다 - 그리고 현재의 CPU time의 경우에는 절반을 나누기 때문에 1 ~ 2에서의 CPU time은 30이 되는 것\n그럼 A는 75이고 B와 C는 60이기 때문에 B와 C중 하나를 고르게 된다 - 여기서는 P가 낮을수록 우선순위가 높은거임\n만약 B를 선택했다면 0 ~ 1에서의 A와 마찬가지로 2 ~ 3에서의 B의 Priority는 75가 된다\n근데 A의 경우에는 이전의 CPU time이 30이었기 때문에 이것을 4로 나눠 계산한 Priority는 67.5로 재조정되고 현재의 CPU time은 15가 되는 것\nC는 아직 1 ~ 2에서는 실행되지 않았기 때문에 Priority가 60으로 그대로 유지된다\n그럼 2~3에서의 우선순위는 순서대로 67, 75, 60이 되기 때문에 가장 낮은 C가 선택되게 된다\n이제 그럼 3 ~ 4에서의 A를 보면 이전의 CPU time이 15였기 때문에 현재의 CPU time은 7.5가 되고 따라서 Priority는 63.75가 되는것이고\nB를 보면 2 ~ 3에서의 A처럼 67.5가 되며 C는 방금 실행되었기 때문에 75가 된다 - 따라서 A가 다시 선택되게 되는 것 - 이런식으로 돌아가게 된다\n따라서 종합해보면 프로세스가 1 time quantum만 실행되고 교체되기 때문에 RR의 성격을 가진다고할 수 있고 CPU를 할당받지 못한 동안에는 CPU time이 점차 감소되어 재조정되는 방식을 통해 aging도 반영되게 된다\nSPN도 반영된다는데 이거까지는 아직 잘 모르겠다\n"},"os.spring.2021.cnu.ac.kr/11.-Multicore-Scheduling":{"title":"11. Multicore Scheduling","links":[],"tags":[],"content":"Multiprocessor System의 구조 §\nLoosley Coupled Multiprocessor §\n\n코어가 자신의 메인 메모리를 따로 갖고있는 코어들로 구성된 것\nDistributed혹은 Cluster라고도 불린다\n\nTightly Coupled Multiprocessor §\n\n모든 코어가 하나의 메인 메모리를 공유하는 구조\n대부분의 컴퓨터가 이와 같은 구조를 가진다\n이번 강의에서는 이 시스템을 가지고 Multiprocessor의 작동방식을 설명한다\n\nFunctionally Specialized Processors §\n\nmaster processor가 하나 있고 그것의 지배를 받는 IO전담 프로세서 등 slave processor가 존재하는 구조\n\nReady Queue의 구성 §\n\n\n일단 통합된 하나의 ready queue를 두고 여기에서 프로세스가 하나씩 빠져 프로세서로 들어가는 방식을 Dynamic이라고 한다\n\n왜 Dynamic이라고 하냐면 만약 하나의 프로세스가 실행되다가 timeout이 걸리든 block을 먹든 해서 빠져나왔다가 다시 Ready queue로 들어가면 기존에 실행되던 프로세서에 다시 할당되리라는 보장은 없기 때문에 하나의 프로세스가 여러개의 프로세서를 거쳐 실행된다는 뜻이다\n\n\n하지만 각 코어마다 ready queue를 두고 프로세스가 이 큐들로 분배되는 방식을 Static이라고 한다\n\n얘같은 경우에는 프로세스가 실행되다가 다시 내려와도 어차피 원래 실행되던 프로세서의 큐로 가기 때문에 이놈은 처음 할당받은 프로세서에서만 실행되다가 종료된다\n\n\n\n프로세스 선택 알고리즘 §\n\nUniprocessor일때는 FCFS를 선택했을 때 Convoy effect가 일어나서 average waiting time이 길어질 수가 있었는데\nMultiprocessor일때는 어차피 남는 CPU에 할당해주면 되기 때문에 Convoy effect에 대해 크게 신경쓰지 않는다\n따라서 FCFS가 알고리즘중에는 가장 공평하므로 FCFS도 많이 이용하게 되는 것\n\nThread Scheduling §\n\n쓰레드의 경우에 어떻게 할 것인가 - 쓰레드도 각각의 독립적인 개체로 보고 여러 프로세스에게 할당할 수도 있는데 이때 한 프로세스에서 파생된 쓰레드들 중 일부만 프로세서를 잡고 실행되게 되면 쓰레드들 간의 통신이 원활하지 않기 때문에 하나의 프로세스에서 파생된 쓰레드들을 한정된 프로세서들에게만 할당해주는 것도 가능하다?\nLoad Sharing : 쓰레드들을 Dynamic 시스템을 이용해 처리 - 하나의 Ready queue에 넣어서 처리함으로 정해진 프로세서에게만 처리되는 형식이 아닌 것\nGang Scheduling : 한개의 프로세스에서 파생된 쓰레드들에게 하나씩 프로세서를 할당하는 구조\n\n하지만 얘도 하나의 쓰레드가 하나의 프로세서에서만 돌아가지는 않는다\n말그대로 쓰레드들이 동시에 실행되기 때문에 게임같은 프로세스를 돌릴때 많이 사용되었다\n하지만 쓰레드의 갯수를 세야되고 하는 절차가 존재하기 때문에 옛날에 컴퓨터가 안좋았을 시절에는 많이 사용했지만 요즘은 컴퓨터가 좋아 리소스가 풍부하기 때문에 알고리즘을 단순화시키자는 생각으로 Load sharing을 더 사용한댄다\n\n\nDedicated Processor Assignment : Gang Scheduling과 비슷하지만 이제는 하나의 프로세서가 하나의 쓰레드를 전담하는 구조이다\nDynamic Scheduling : 얘는 프로세스의 쓰레드 갯수가 동적으로 바뀌는 상황에 대응하기 위해 만들어진 알고리즘이다\n\nReal-time Systems §\n\nReal-Time System은 실시간 시스템을 의미한다\nHard Real-Time : 얘는 앞에서 배운 Deadline이 존재하고 반드시 그걸 지켜야 되는 시스템 을 의미하고\nSoft Real-Time : 얘는 Deadline이 존재하지만 권장사항일 뿐 반드시 지켜야되는건 아닌 시스템을 의미한다\n\n얘는 의무사항은 아니어도 Deadline을 되도록이면 지켜야 하기 때문에 deadline이 걸린 프로세스는 메모리에 상주하고 우선순위를 높이게 된다\n\n\n\nReal-Time Scheduling §\n\n\n보면 맨 위에가 프로세스들이 언제 들어오고 얼마만큼의 시간을 필요로 하고 deadline이 언제까지인지를 나타내는 그림이고(편의를 위해 uniprocessor를 기준으로 한다)\n두번째는 A프로세스에게 우선권이 있을때의 그림, 세번째는 B프로세스에게 우선권이 있을때의 그림이다\n우선순위가 존재할때를 살펴보면 deadline을 지키지 못해 miss가 일어나는 것을 볼 수 있다 - deadline이 존재하는 경우에는 특정 프로세스에게 우선권을 주는 식으로 실행을 하면 miss가 자주 일어나므로 잘 사용하지 않는다\n네번째 그림인 Earliest Deadline Scheduling은 deadline이 가장 빠른것(=마감일이 얼마 안남은 것)을 먼저 실행시키는 알고리즘이다 - 이경우에는 miss가 안나는 것을 알 수 있다\n이 알고리즘은 프로세스가 하나밖에 없으면 그냥 그걸 실행시키고, 다른 프로세스가 들어오면 둘중에 deadline이 더 빠른놈을 선택하여 실행한다. 만약 deadline이 동일하다면 기존에 실행시키던 것을 계속 실행시키는 식으로 작동한다\n"},"os.spring.2021.cnu.ac.kr/12.-IO-&-Disk-Scheduling":{"title":"12. IO & Disk Scheduling","links":[],"tags":[],"content":"IO Device §\n\nHuman Reachable : 키보드나 모니터, 마우스같은거\nMachine Reachable : USB, 센서같은거\nCommunication : 통신을 위한 장비\nIO장비는 하드웨어면으로나 소프트웨어 면으로나 장비마다 다양하기 때문에 이쪽을 개발하는 것은 전문성을 요구하는 쉽지 않은 일이다\n\nIO Techniques §\n구분 §\n\n\n보면\nProgrammed IO는 IO 처리를 구현한 프로그램이 있어서 프로세서가 직접 이 프로세스를 실행시키며 디스크에서 파일을 읽어오는 것을 의미한다\nInterrupt-Driven IO는 블락이 먹기 전까지 실행하다 IO가 필요해져서 블락을 먹으면 다른 프로세스를 실행하고 IO가 완료되면 인터럽트를 걸어서 다시 복귀하는 형태를 의미한다\nDirect Memory Access는 Interrupt Driven IO의 진화버전으로써 프로세서가 아닌 IO처리 담당 프로세서가 별도로 존재해서 걔가 IO를 처리하고 끝나면 인터럽트를 거는 일을 의미한다\nProgrammed IO와 나머지 둘의 가장 큰 차이점은 Busy Waiting이다 - Programmed IO는 프로세서가 직접 IO처리 프로세스를 실행시키며 IO처리를 해 기존의 프로세스가 기다리는 와중에도 프로세서를 사용하지만 Interrupt-Driven IO나 Direct Memory Access 는 IO처리를 프로세서가 직접 하지 않아 프로세서는 다른 프로세스를 돌릴 수 있게 한다\n\n발전과정 §\n\n\nProgrammed IO형태에서\nIO 전용의 IO module / Controller가 등장한다\n\nIO module / Controller는 한가지 형태의 IO를 전담하는 것이라고 생각하면 된다\n\n\n하지만 Interrupt 기능은 없어서 CPU가 수시로 IO가 종료되었는지 확인해줘야 되는 Busy Waiting이 여전히 존재했기 때문에 IO Interrupt가 추가된다 - 얘가 추가되고 나서는 Busy Waiting을 하지 않음\nIO module / Controller가 하드와 메모리를 직접적으로 제어하는 DMA가 추가됨\n\nDMA가 IO와 관련된 모든 일을 전담하는 것으로 생각하면 될거같다\nIO Module / Controller들을 DMA가 관리하게 되는 것\nCPU가 DMA에게 IO를 맡기기만 하면 얘가 알아서 다 처리하는 형태\n\n\nIO module / Controller가 별도의 프로세서로 분리됨 - IO만을 위한 특별한 Instruction을 실행시키며 IO를 처리한다\n\n4, 5번에서 하드와 메모리를 직접적으로 제어하는 프로세서를 별도로 분리한 것을 IO Channel이라고도 표현한다\n\n\n이전까지는 DMA도 메인메모리를 공유했지만 이제는 DMA전용의 메모리가 별도로 분리되어서 더 빠르게 작동할 수 있게 됐다\n\n\n\n옛날에는 데이터를 주고받는 Bus가 하나여서 여기에 DMA나 IO Module / Controller들이 전부 연결되어있었지만 - Single Bus, Detached DMA\nbus에는 DMA만 붙고 그 아래 IO Module / Controller들이 있는 형태로 바뀌었다가 - Single Bus, Integrated DMA\n이제는 System bus에는 DMA하나만 붙고 그 아래 IO Bus가 별도로 존재해 IO Module / Controller가 사용하는 Bus가 별도로 분리되게 된다\n\nIO 설계 §\n\nEfficiency : IO들은 프로세서나 메모리보다 처리속도가 더 늦기 때문에 이런 처리속도가 느린 IO 하드웨어들을 어떻게 효율적으로 관리하는가\nGenerality : IO의 인터페이스가 다 제각각이어서 그것을 이용하려는 프로그래머가 IO에 따라 다른 방법을 사용해야한다면 매우 불편 - IO의 사용법(인터페이스)을 통일시켜서 간편하게 사용할 수 있게끔 하는 것\n\n\n\n위 그림은 세 IO를 예시로 든건데\n보면 맨 아래 3개가 하드웨어로 구현된 IO 이다\n그리고 그 위에가 OS 레벨 이며 맨 위의 user process에서는 OS가 제공해주는 API들을 이용해 사용자가 프로그램을 짜게 되는 것\n우선 Logical Peripheral Device를 보면\n\nLogical IO에서 open, read, write, close등의 API등을 사용자에게 제공한다\n그리고 이런 API를 사용해 명령을 내리면 Logical IO에서 그것을 처리해 표준화된 인터페이스를 제공하는 Device IO로 전달하게 된다\nDevice IO가 이런 표준화된 인터페이스를 제공하기 때문에 우리는 HW레벨의 지식 없이 간편하게 HW를 제어할 수 있는 것이다\n\n\nCommunication Port에서도 동일하게 Communication Architecture을 이용해 사용자에게 API를 제공하고, 그것을 처리해 Device IO로 넘겨주게 된다\nFile System에서는\n\n일단 Directory Management는 우리가 문자열 형태로 전달한 파일의 경로를 File Descriptor로 바꾸는 역할을 한다\n\nFile Descriptor 별거 아니다 - 프로세스는 고유한 pid를 갖고있듯이 파일도 File Descriptor 라는 고유한 번호를 갖게 된다\n\n\n그리고 File System에서 파일에 대한 Open, Read, Write, Close 명령어를 제공해준다\n그리고 Physical Organization에서는 Virtual Address를 Physical Address로 변환하는 등의 일을 하게 된다\n\n\n\nBuffering §\nData IO size §\n\n일단 Device는 IO로 갖고오는 데이터의 크기에 따라 두가지로 나눌 수 있다\nBlock Oriented Device - 얘는 블럭(IO에서는 페이지를 블럭이라고 표현한다)단위로 IO를 처리하는 Device를 말한다\n\n보통 Machine Reachable Device가 블럭단위로 IO처리하므로 이놈이 여기에 들어간다\n\n\nStream Oriented Device - 예는 바이트나 워드 단위로 IO를 처리하는 Device를 의미한다\n\n보통 Human Reachable Device가 바이트나 워드 단위로 IO를 처리하므로 이놈이 여기에 들어간다\n\n\n따라서 Block Oriented Device가 블럭단위로 갖고오므로 Stream Oriented Device보다 갖고오는 양이 많다\n\nBuffer §\n\n\n일단 Buffer라는 것은 IO를 통해 가져온 데이터를 메인메모리의 OS파트에 잠깐 저장하기 위한 용도로의 공간을 의미한다.\n버퍼라는게 존재하지 않을 때 어떤일이 벌어지는지 보자\n유져 프로세스가 page fault가 일어나서 OS에게 특정 페이지를 요청했다고 해보자\n그럼 OS는 IO에게 해당 페이지를 가져오라고 시킨 뒤 다른 프로세스를 실행시키게 되는데\nIO가 끝나게 되면 버퍼가 없기 때문에 가져온 페이지가 메인메모리의 유저 프로세스 영역으로 들어가게 된다\n근데 만약에 유저 프로세스가 블락을 먹은 동안 메모리에 공간이 부족해져서 이놈이 Swap-out당하면 유저 프로세스가 메인메모리에 없기 때문에 IO는 가져온 데이터를 둘 곳이 없어지게 된다\n따라서 유저 프로세스는 IO가 완료되지 않았기 때문에 블락이 풀리지 않고 IO입장에서는 데이터를 갖고와도 둘곳이 없기 때문에 IO를 완료하지 못해 계속 블락을 먹은 상태로 있게 된다 - 이것을 Single Process Deadlock이라고 한다\n\n즉, 프로세스가 한개여도 버퍼가 없다면 데드락에 걸릴 수 있게 되는 것이다\n\n\n\n\n\n따라서 메모리의 OS파트에 버퍼라는 공간을 두어서 유저 프로세스가 Swap-out을 당하더라도 IO가 완료될 수 있도록 하는 것이다.\n그리고 이렇게 함으로써 Write에도 좀 더 이점을 가질 수 있다 - 유저 프로세스에서 Write가 일어났을 때 하드디스크를 바로바로 변경시키면 처리량이 많기 때문에 Write가 일어나면 일단 Buffer에 있는 페이지를 변경하고 나중에 하드에 한번에 업데이트 시킬 수 있게 한다\n또한 IO의 성능에 대해서도 이점이 있다 - Page Fault가 일어나면 하드디스크로 가기 전에 버퍼를 먼저 찾아서 여기에 이미 내가 원하는 페이지가 존재하는지 찾아보게 된다 - 만약에 있으면 하드에 갈 필요가 없으므로 훨씬 빠르게 Page Fault가 해결됨\n\n\n\n근데 버퍼를 여러개 갖게 되면 하나의 버퍼에 하드에서 가져온 페이지를 쓰는 것과 동시에 다른 프로세스가 다른 버퍼레 접근하여 데이터를 가져갈 수 있으므로\n요즘은 OS파트 안에 버퍼를 여러개 두고 여러개의 유저 프로세스가 버퍼들을 나눠서 사용하는 구조인 Circular Buffering 으로 운영된다\n\nDisk Performance §\n\n\n일단 디스크는 LP판처럼 생겼고 이와 유사하게 작동한다\n먼저 디스크의 한 표면(Surface)에는 여러개의 Track이 존재한다\n\n하나의 디스크는 앞면, 뒷면 두개의 Surface를 갖게 된다\n\n\n그리고 일정한 각도로 Surface를 잘라 만들어진 Track의 한 부분을 Sector 라고 한다\n또한 Sector는 여러개의 Block들로 구성되어 있고 어느 Sector든 같은 수의 Block으로 구성되어 있다\n\n그 각속도 기억나제? - 디스크 판은 같은 속도로 회전하기 때문에 한 섹터에서 같은 양의 블럭을 가져오기 위해서는 바깥쪽의 블럭은 좀 더 듬성듬성하게 위치하게 된다\n\n\n그리고 Disk Arm이 있어서 이놈이 Surface를 읽으며 데이터를 읽게 되는 것\n따라서 디스크에서 특정 블럭을 찾는 과정은 다음과 같은 세가지의 단계를 거치게 된다\n\n일단 Disk Arm이 특정 Track으로 움직이는 작업을 한다 - 이것을 Seek이라고 한다\n그리고 Track으로 간 뒤에는 디스크가 회전하며 해당 Sector를 찾는다 - 이것을 Rotational Delay라고 한다\n마지막으로 디스크에서 비트들을 읽어 전송하는 Data Transfer과정이 있다\n\n\n여기에 걸리는 시간을 보면\n\nData Transfer는 그냥 읽어서 전송하는 것이기 때문에 시간을 별로 잡아먹지 않는다\n하지만 Seek의 경우에는 Disk Arm이 물리적으로 움직여야 되므로 가장 오래 걸리게 되고\nRotational Delay도 디스크를 회전시켜야 되기 때문에 적지 않은 시간이 걸린다\n즉, Seek &gt; Rotational Delay &gt; Data Transfer 의 순서대로 시간이 소요된다\n\n\n특정 주소를 이용해 디스크의 위치를 알아내는 과정은 다음과 같다\n\n일단 Logical Address를 이용해 Page# 을 알아낸다\n그리고 그 Page# 를 Block# 로 바꾸게 된다\n그리고 Block# 을 이용해 해당 Block이 어느 Track에 있는지 알아낸다\n\n\n이 과정이 정확히 어떻게 이루어지는지는 안알랴줌\n\n\n근데 이제 Seek이 제일 오래 걸리기 때문에 이 시간을 줄여야 되고 따라서 일련의 Track# 들이 주어졌을 때 Disk Arm을 어떻게 움직여서 어떤 순서로 Track을 읽어야 할지가 Disk Scheduling이다\n\nDisk Scheduling §\n\n\n\nFIFO : 말그대로 들어온 순서대로 처리하는 것\n\nTrack# 이 Arm이 효율적으로 움직일 수 있는 동선대로 들어오는게 아니기 때문에 가장 최악의 시간이 걸린다\n\n\nSSTF(Shortest Serve Time First) : 얘는 지금 현재의 위치에서 가장 가까이 있는 놈을 처리한다\n\n보면 가장 효율적으로 움직이기 때문에 Seek가 제일 적게 걸리는 것을 알 수 있다\n하지만 매번 Queue를 전부 확인해서 나랑 가장 가까운 놈을 찾아야 하기 때문에 실제로 사용하기에는 무리가 있다\n\n\nSCAN : 얘는 엘리베이터마냥 한방향으로 가면서 그 방향에 있는애들 다 처리하고, 끝나면 다시 방향을 틀어 그 방향에 있는애들 다 처리하는 방식이다\nC-SCAN : SCAN은 양방향으로 움직이며 해당 방향에 있는 애들을 다 처리하는 반면, 얘는 한방향으로만 움직인다 - 한방향으로 움직이며 애들을 다 처리하고, 처리가 끝나면 다시 0번으로 복귀해 한방향으로 움직이게 되는 것\n\n즉, 0번으로 복귀할때에는 처리를 안한다\n이것은 하드웨어적 관점에서 봤을 때 한뱡향으로만 움직이는게 더 좋을수도 있기 때문에 이런 알고리즘을 채택하는 것\n\n\n\n\n\nN-Step SCAN : 이전의 SCAN에서는 큐를 하나만 두고 이 큐 안에 있는 애들을 처리하는 방식이었는데\n\n근데 SCAN방식은 요청순서와는 전혀 무관하게 작동하므로 약간 형평성의 문제가 있을 수 있다\n따라서 이러한 요청순서를 어느정도 반영하여 SCAN을 돌리는 것이 N-Step SCAN이다\n얘는 일단 크기가 N인 큐를 여러개 갖고 여기에 들어온 순서대로 넣는다 - 큐 하나가 다 차면 그다음 큐로 가서 채우는 방식으로\n그리고 하나의 큐 안에서는 SCAN방식으로 작동하게 함으로 일찍 들어온놈이 재수없게 나중에 처리되는 일을 줄인다\n따라서 N = 1이면 그냥 FIFO와 다를바가 없고 N이 엄청 크다면 SCAN과 다를바가 없는 방식이 된다\n\n\n\n\n\nFSCAN은 큐를 단 두개만 갖는 N-Step이라고 할 수 있다\n즉, 큐를 두개 가지고 하나를 채운 뒤 SCAN으로 처리하고, 그동안 다른 하나를 채워 SCAN처리하고 앞선 큐가 다 처리되어 비워졌으므로 다시 여기에 채우는 식으로 작동한다\n\nRAID §\n\nRAID(Redundant Array of Independent Disk) 라는 것은 별도의 디스크를 두어 디스크의 속도를 빠르게 함과 동시에 디스크가 손상되는 것을 막는(Fault Tolerant) 7가지 기법을 의미한다\n\nLevel 0 §\n\n\n일단 Strip이라는 것은 Session이랑 같은말이다 - 일련의 블럭들\n여러개의 블럭으로 구성된 파일을 하나의 디스크에 넣으면 하나의 IO에 의해 처리되므로 블럭들을 Serial하게 처리할 수 밖에 없다\n따라서 파일의 여러 블락들을 여러 디스크에 나눠 담아 여러개의 IO에 의해 처리되게 함으로 Parallel하게 처리되게 한다\nLevel 0에서는 그냥 이렇게 나눠담는 방법만 사용하여 속도에만 집중한 방법이다\nError에 대한 대비책은 고려하지 않으므로(Non-redundant) 진정한 의미의 RAID와는 좀 거리가 있다\n\nLevel 1 §\n\n\n얘는 이제 Level 0과 동일하게 하되, 동일한 Level 0구성을 두개를 놓아 하나에서 문제가 생겼을 때 다른 하나로 바로 이동해 처리하는 구조이다\n마치 like 백업을 두는 구조 - 이중화(Mirrored)\n요즘은 이 방법을 많이 사용하지만 Disk가 많이 필요하다는 단점이 존재한다\n\nLevel 2 §\n\n\n얘는 똑같은거 두개를 놓는게 아니라 Hamming Code라는 Error Correction Code를 별도의 디스크에 저장해 디스크의 갯수를 좀 줄이는 방법이다\n\nLevel 3 §\n\n\n얘는 Hamming Code 가 아닌 비트 단위(Bit-Interleaved)의 Parity bit을 이용해 Error Correction에서는 한계가 있지만 디스크의 갯수를 더욱더 줄이는 방법\nParity Bit은 Single Bit Error에 대해서는 Correction이 가능하지만 Double Bit Error에 대해서는 Detection만 가능하다는 점에 있어서 한계가 있다\n\nLevel 4 §\n\n\n얘는 비트 단위가 아닌 블럭 단위(Block-Level)로 Parity Bit을 구성해 Parity Bit를 더 줄이고 Error Detection연산도 줄이는 방법이다\n\nLevel 5 §\n\n\nLevel 3이나 4같은 경우에는 Parity Bit이 디스크 하나에 몰려있기 때문에 해당 디스크를 너무 많이 참조하고 Write가 발생할때마다 해당 디스크에 가서 Parity Bit를 다시 계산해줘야 하므로 Bottleneck현상(트래픽이 몰리는 것)이 일어날 수 있다 - 몰린다는 뜻\n따라서 Parity Bit을 분산하여 배치해 이러한 문제를 막는 기법이 Level 5 이다 - Distributed Parity\n\nLevel 6 §\n\n\n얘는 Parity Bit을 두개를 계산하여 저장(Dual Redundancy)하여 더 Error Correction의 정확성을 높이는 방법이다\n"},"os.spring.2021.cnu.ac.kr/13.-File-Management":{"title":"13. File Management","links":[],"tags":[],"content":"Files §\n\nFile : 사용자가 만든 비트들의 모음\n\n성질 §\n\nLong-term Existence : 오랫동안 보관되어야 함\nShareable between Processes : 프로세스들이 공유할 수 있어야 함\nStructure : 확장자 얘기하는듯 - 여러 구조의 파일들을 잘 관리할 수 있어야 함\n\n구성 요소 §\n\nName : 파일의 이름\n\n유닉스 시스템에서는 inode# 라는 정수형태로 파일의 이름을 저장한다\n\n\nType : 확장자\nLocation : 위치 - Block# 로 디스크에서의 위치가 저장된다\nSize : 파일의 크기\nProtection : 파일의 Log\n\nCreation : 생성\nLast Modification : 마지막 변경\nLast Use : 마지막 사용\n위 세가지에 대해 Time, Date, *UID(User ID)*를 로그로 저장한다\n\n\n\nOperation §\n\nCreate : 파일의 생성\nDelete : 파일의 삭제\nOpen : 파일 열기\nClose : 파일 닫기\nRead : 파일 읽기\nWrite : 파일 쓰기\nC언어에서는 open system call 이 create와 open 을 모두 책임진다\n사용자가 파일 하나를 open하면 파일의 이름을 inode로 변환하고 그것을 이용해 Block# 를 알아낸 다음 메인 메모리로 갖고 올라와 read 혹은 write의 연산을 하고 끝나면 close를 통해 파일이 닫히는 구조이다\n\nStructure - Database와 File System 의 차이점 §\n\nOS의 File System에서는 위에서 명시한 파일을 생성하고 삭제하고 열고쓰는 등의 Rough한 연산들만 지원한다\n반면에 Database에서는 File의 내용, 즉, File의 Field(데이터베이스에서 Column을 말하는듯)와 Record(데이터베이스에서의 Row를 말하는듯)등의 File의 세부적인 내용을 관리하는 역할을 한다\n\nUNIX File System §\n\n\n일단 디스크의 구조가 저렇게 n개의 블락으로 구성되어있다고 할 때\n첫번째 블록을 Boot Block이라고 한다 - 얘는 처음 부팅할때 메인메모리에 들어가서 OS초기화하고 부팅작업을 하는데에 사용된다\n그리고 두번째 블록을 Super Block이라고 한다 - 얘는 부팅 이후 메인메모리로 들어가서 전체적인 File System에 대한 정보를 OS에 제공해준다\n그 이후 위의 예시에서 2~m-1까지를 inode list라고 한다\n\ninode list에는 inode들이 저장되고 블록보다는 사이즈가 작기 때문에 한 블록에 여러개의 inode가 저장되게 된다\n따라서 하나의 시스템 안에 저장될 수 있는 파일의 갯수는 저 m에 달려있는 것이다\n\n\n그 다음 m부터 n-1까지는 data block이라고 한다\n\ndata block 은 파일의 실질적인 내용이 블럭단위로 잘려서 저장되게 된다\n\n\ninode는 파일 하나에 대한 정보를 저장하게 된다 - 프로세스에 PCB가 있었듯이 파일에는 inode가 존재하는 셈이다\n\ninode에는 다양한 정보들이 저장되는데 일단\n위에서 말한 파일의 구성 요소인 name, type, size, location, protection과 파일의 주인인 owner가 들어간다\n그리고 index table이 들어가게 되는데 이놈이 하나의 파일에 대한 내용을 블럭단위로 쪼개서 data block에 저장하게 되므로 그 블럭들이 data block의 어디에 존재하는지를 나타내는 테이블이다\n위의 예시에서는 327, 15, 216이라고 돼있으므로 파일의 첫번째 블럭은 data block의 327에 가면 있다는 거고 두번째 블럭은 15, 마지막 블럭은 216에 가면 있다는 소리이다\n따라서 파일 하나가 가질 수 있는 최대 크기는 index table에 달려있게 된다\n\n\n그리고 한 파일이 열리면 그 파일에 대한 inode가 메인메모리로 올라가고, index table을 이용해 data block들도 하나씩 차례로 올라가게 된다\n\nIndex table §\n\nindex table의 구조를 조금 더 자세히 살펴보면 다음과 같다\n\n\n\n일단 index table의 일정부분은 바로 파일의 내용이 저장된 data block의 블럭으로 연결된다 - 여기를 direct block이라고 함\n위의 예시에서는 10까지는 따라가보면 바로 파일의 내용이 나오게 된다는 소리이다\n그리고 그 다음부터는 계층구조를 가지게 된다\n이게 뭔말이냐면, index table에 적혀있는 block# 으로 가보면 해당 블럭에 들어있는 내용은 파일의 내용이 아니라 또다른 index table이 존재하는 것이다\n즉, data block에 저장되어있는 블럭은 파일의 내용을 저장하는 블럭일 뿐만 아니라 index table일 수도 있다는 소리이다\n따라서 인덱스 테이블에서 다시 또다른 인텍스 테이블로 움직이고, 거기서 파일의 내용이 저장된 블럭으로 이동하는 계층구조를 가진다\n최상위 index table은 이렇게 일정구간은 바로 파일 내용 블럭으로 가지만 나머지는 차수가 점차 늘어나는 계층구조를 갖도록 되어 있다 - 이부분을 indirect block이라고 한다\n즉, 위의 예시에서는 11번째 칸에는 또다른 index table의 위치가 저장되어있고, 그 index table에는 파일 내용 블럭의 위치가 저장된 1중 계층구조였다면,\n12번째 칸에는 2중 계층구조, 13번째 칸에는 3중 계층구조로 되어있는 것이다\n이때 data block에 저장된 index table의 크기가 256이라면, 하나의 파일은 10 + 256 + 256^2 + 256^3 개의 블럭에 나뉘어져 저장되는 셈인거다\n보통 블럭 10개를 direct block으로 갖고 3개를 indirect block 로 1-Level, 2-Level, 3-Level 을 갖는 식으로 inode의 index table이 구성된댄다\n\nDirectory §\n\n일단 유닉스 시스템에서는 directory도 하나의 file로 취급한다\n\n\n\n일단 현재 디렉토리(current directory)가 inode 300번이라고 해보자\n그럼 거기의 index table을 통해 data block으로 간 결과가 그 옆의 column두개짜리 테이블이다\n디렉토리이기 때문에 파일의 내용이 저렇게 2 column table로 나타나게 되고\n이 2 column table에는 위의 예시에서는 오른쪽에는 해당 디렉토리에 들어있는 파일의 이름, 그리고 왼쪽에는 그 파일의 index# 가 저장된다\n그리고 만약 내가 A라는 디렉토리로 가고 싶으면 A 옆의 inode로 들어가게 된다\nA의 inode가 766이라고 했을 때 해당 inode list의 원소로 가면 동일하게 A의 정보와 A의 내용을 볼 수 있다(index table을 이용해서)\nA의 내용을 보면 A 또한 디렉토리이기 때문에 2 column table을 볼 수 있고, A에는 f1이 들어있기 때문에 f1과 f1의 inode# 가 2 column table에 저장되게 된다\n마찬가지로 f1의 inode# 인 111로 가면 거기에서 마찬가지로 index table을 이용해 f1의 내용을 볼 수 있는 것이다\n따라서 핵심은 유닉스에서는 디렉토리도 file로 관리되어 inode가 존재하고, 디렉토리의 inode에 저장된 index table을 이용해 내용 블럭으로 가면 거기에는 해당 디렉토리의 하위 디렉토리 / 파일에 대한 ( 이름, inode# ) 들이 저장되어 있는 것이다 - 따라서 해당 inode# 을 쫒아가면 하위 디렉토리 / 폴더로 접근하게 되는 구조이다\n\nFile Directory Structure §\n\nSingle Level Directory : 한명의 유저와 하나의 current directory만을 지원해 모든 파일들이 다 같은 곳에 unique한 이름들을 가지며 존재하는 것\n\n\n\nTwo Level Directory : 이제는 여러명의 유저와 하나의 current directory만을 지원해 파일들이 하나의 유저한테 속하여 존재하는 구조 - 한 유저 안에서는 unique한 이름을 가져야 되지만 유저가 다르다면 이름이 중복되어도 된다\n\n\n\nTree Structured Directory : 일반적으로 우리가 생각하는 디렉토리의 구조 여러명의 유저가 있고 한 유저 안에서도 여러개의 디렉토리, 디렉토리 안의 디렉토리를 생성해 트리구조로 디렉토리들이 형성되는 것\n\n\n\nAcyclic Graph Directory : 얘도 동일하게 트리구조를 갖지만 트리구조에서는 할 수 없는 공유의 개념이 가능한 구조이다 - 파일 하나를 여러명의 유저가 공유할 수 있는 구조\n\n\nFile Sharing System §\n\n\nHard Link : 공유파일에 대해 하나의 inode와 data block을 두 디렉토리 / 유저가 공유하는 형태이다\n\ninode와 data block을 하나씩 사용하기 때문에 resource를 적게 사용한다는 장점이 있다\n\n\nSymbolic Link : 얘는 두 디렉토리 / 유저가 각각 하나씩 공유파일에 대한 inode와 data block을 갖고있고 둘 중 하나의 data block에 나머지 하나의 inode의 경로가 적혀있는 형태이다\n\n얘는 inode와 data block이 더 필요하므로 resource를 더 많이 먹는다는 단점은 있지만, network를 사용해서 파일을 공유한다거나 하는 등의 더 강력한 파일 공유를 지원할 수 있다 - 그냥 파일의 경로만 data block에 적어주면 되므로\n\n\n\nFile Allocation §\n\ninode에서 쓰는 index table방식 말고 다른 방식의 data block을 찾아가는 방식들\n\nContiguous File Allocation §\n\n\nContiguous File Allocation : 얘는 data block을 연속적으로 디스크에 배치한 뒤, 시작블럭과 갯수를 File Allocation Table에 저장하는 방식이다\n이놈의 단점은 일단\n\n마지막 data block 뒤에 다른 파일의 data block이 들어있으면 그자리를 사용하지 못하므로 파일의 크기가 커졌을 때 대처할 수 없다는 것과\n파일이 삭제되어 data block들을 삭제했을 때에 External Fragmentation이 일어난다는 것이다\n옛날 windows xp가 이런 방식으로 작동해 external fragmentation 들을 모으는 조각 모음(compaction) 이 있었던 것이다\n\n\n\nChained Allocation §\n\n\nChained Allocation은 Linked List마냥 다음 data block의 위치를 data block의 마지막에다 저장해서 찾아가도록 하는 구조이다\n단점은 당연히\n\npointer를 잃어버리면 파일이 날라가는 문제가 발생한다는 것과\n파일의 특정 지점을 읽으려면 그곳까지 datablock을 차례로 들러야 하기 때문에 오래걸린다는 것이다\n이것을 해결하기 위해 FAT(File Allocation Table) 라는 것을 이용한다.\n\n\n\n\n\n얘는 여기저기 흩어져있는 포인터를 하나의 테이블에 모은 것으로, ( Block# , next Block# )을 저장하는 테이블이다\n포인터를 잃어버리지 않는다는 것과 이것이 특정 위치로 갈때 블락들을 찾는게 아닌 이 테이블만 읽으면 되니까 훨씬 더 빠르다는 장점이 있지만\n디스크의 사이즈가 커지면 FAT도 너무 커진다는 단점도 존재한다\n\nIndex Allocation with Variable-Length Portions §\n\n\nIndex Allocation with Variable-Length Portion은 index table개념과 contiguous allocation 개념을 합친거다\n즉, index table을 사용하되 연속된 블럭을 하나의 행에 저장하는 방법 - (start block, lengh)를 저장한다\n\nFree Block Management §\n\n비어있는 블럭을 관리하는 방법\n\nBit table §\n\n\nBit Table은 모든 Block# 에 하나씩 비트를 할당한 테이블로 이 비트를 이용해 해당 블럭이 비었는지 아닌지를 표시하는 방법이다\n\nChained Free Portions §\n\n\nChained Free Portions는 Free block들을 Linked List처럼 이어놓은 형태이다\n\nIndexing §\n\n\nIndexing은 table 하나를 만들어서 거기에 free block의 block# 를 다 저장하는 방법이다\n얘는 크기가 디스크의 블락의 갯수랑 같을 필요는 없다\n\nfree block의 갯수가 table의 갯수보다 클때는 일단 table을 다 채워놓고서 table에 들어있는 free block들이 다 사용되고 나면 다시 하드를 조사해 free block들을 채우면 되기 때문\n즉, 디스크의 모든 free block을 아는것이 중요한게 아니기 때문에 몇개를 채워놓고 다쓰면 다시 채우고 하는 방식으로 작동하게 된다\n\n\n"},"os.spring.2021.cnu.ac.kr/2.-프로세스":{"title":"2. 프로세스","links":[],"tags":[],"content":"프로그램 실행에서의 OS의 역할 §\n\n자원들(메모리 등)을 여러 프로세스들에게 적절하게 분배하고 관리함\n프로세스가 계속 변경되며 실행되어 동시에 실행되는것처럼 보이게 한다\n이렇게 프로세스와 IO디바이스들을 관리하는것이 OS가 하는 일이다\n\n프로세스 §\n\n실행의 단위, OS의 관리의 단위, 실행됐지만 아직 죽지는 않은 것\n프로그램 코드 와 그 코드와 연결된 여러개의 데이터로 구성된다\n코드(text) : 내가 짠 프로그램 소스파일\n코드에 연동되는 데이터는 구체적으로 global 변수는 data에, local변수와 함수는 stack에, 동적할당을 위한 공간은 heap에(단 heap은 data와 합쳐 그냥 data로 하나로 퉁쳐서 부르기도 한다), 그리고 나머지 필요한 자료들은 PCB에 저장된다\nOS는 프로세스 단위로 메모리를 할당하고 관리한다\n\nPCB에 저장되는 정보들 §\n\nPCB = Process Control Block : 프로세스의 정보들을 담은 구역(자료구조). 프로그램이 프로세스가 되기 위해서는 이 공간을 반드시 할당받아야 한다\nidentifier : 유닉스에서 PID같은놈. 프로세스들의 고유 번호이다\nstate : 프로세스의 현재 상태. 현재 실행중인건지, 기다리는 것인지 등등의 상태들이 저당된다\npriority : 프로세스들 간의 우선순위. 시스템 프로세스 같은 중요한 것들이 먼저 구동될 있도록 우선순위가 매겨져있다. 하지만 하나의 프로세스가 cpu를 monopolize하는것을 막기 위해 우선순위는 계속 바뀌게 된다\n그리고 cpu로 들어갈때 레지스터에 쓸 값들 - program counter(다름 실행할 명령어의 주소), memory pointer(이 프로세스가 저장되어있는 메모리의 주소) 등등의 정보들이 저장되게 된다\n\nSystem, Kernel, User Process §\n\nOS도 하나의 프로그램이므로 OS의 여러 기능들도 프로세스화되어 구동되게 된다\n이 OS의 프로세스를 system process라고 하며 그 중에서도 중요한 애들인 커널이 프로세스화 된 것이 **kernel process(daemon)**이다. Kernel process같은 중요한 기능들은 항상 메모리에 상주한다 &lt;-&gt; 반대로 우리가 만든 프로그램들이 프로세스화되면 user process라고 하는 것\n\nDispatch, Context switch §\n\nDispatch : ready상태인 프로세스들 중 가장 우선순위가 높은놈을 running상태로 바꿔 cpu를 할당하는 일을 말함\nContext switch : 프로세스가 전환 후 새로운 프로세스가 실행되는것을 의미함\nDispatcher : 새로운 프로세스를 Dispatch하여 Context switch하는 일을 전담하는 kernel process\n여기서 중요한점은 새로운 프로세스가 Dispatch된 이후 새 프로세스가 실행되는것을 보고 Context switch가 일어났다라고 말한다 - 새로운 프로세스로 교체하는 “과정”을 Context switch라고 하는게 아니다 이말이야 - 따라서 Dispatch이후 Context Switch가 일어나는게 맞는거다\n\nProcess 실행과정 - 2 state process model §\n\n\n프로세스가 생성되면(Enter / Creation) 먼저 **Not Running(Ready)**상태가 된다 - Dispatch를 기다리는 상태\n이제 이 프로세스가 Dispatch되면 Running상태가 된다 - 실행되는 상태\n그리고 또 이놈이 실행되다가 타임아웃 등의 인터럽트를 받으면 다시 Not Running의 상태로 간다 - pause된다\n또 Dispatch되면 Running상태로 가고 이 과정을 반복하가 종료 (Exit / Termination)된다\n따라서 프로그램이 fork()되어 프로세스로 creation이 됐다가 exit()되어 다시 프로그램의 상태로 termination될때까지 수많은 pause와 dispatch를 거친다\n하지만 system process들은 잘 terminate되지 않는다 - 중요하므로\n우리가 코딩할때도. system call을 이용해 creation, dispatch, pause, terminate를 직접적으로 명령할 수도 있다 - fork(), exec(), wait(), exit()\nNot Running중인 프로세스들은 queue로 관리된다→ dispatch되면 queue에서 빠지고 pause되면 다시 queue로 들어간다\n\nsys call : fork()함수 §\n\n프로세스가 실행되다가 fork()가 실행되면 새로 프로세스가 하나 더 만들어지는데 이때 fork()를 호출한놈이 parent이고 만들어진 놈이 child이다\nfork()를 호출하면 parent와 동일한 놈이 하나더 child로 만들어지게 된다\n나머지는 전부 같으나 다른점이 몇가지 있다\n\nPID(identifier) 가 다르다 - 부모자식은 구별할 수 있어야 하므로\nfork()함수의 리턴값은 부모의 경우 자식의 PID, 자식의 경우 0을 리턴한다\n\n\nchild프로세스가 끝나기 전에 parent가 끝나면 좀 골치아파진다 - 원칙적으로 child가 끝나야 parent를 끝낸다 - cascade termination이라고 한다\n하지만 부득이하게 parent가 끝나면 parent의 parent가 child의 parent로 바뀌게 된다\n\nTermination condition §\n\nNormal completion : 정상종료\ntimeout과는 별개로 cpu를 차지하는 총 시간도 중요하다 - 무한루프에 빠졌을 가능성이 있으므로 - cpu를 차지하는 총 시간이 너무 긴 경우에도 강제로 termination하게 된다 - timeout과는 별개의 개념이다 - timeout의 경우에는 cpu를 연속적으로 사용하는 시간을 말하고 이때에는 이 cpu를 잡고있는 총 시간을 말하는거 -무한루프가 아닌 원래 시간을 많이 잡아먹는 일이면 작업관리자에 승인을 요청하는 작업을 해줘야 된다\nMemory unavailable : 더이상 가용 가능한 메모리가 없을 경우\n\nProcess 실행과정 - 5 state process model §\n\n\nNew : 새로 들어와서 프로세스로 바꾸는 과정 - 여러 resource들을 할당받는 상태 - 프로세스화가 끝나면 admit되어 다음 단계로 간다\nReady : 프로세스화가 끝난 상태 - dispatch되어 running되기만 기다리는 상태이다\nRunning : dispatch후 실행중인 상태 - 실행이 끝나면 release되어 다음 단계로 간다\n\n다만 timeout이 발생하면 다시 ready로 가게 된다 - timeout의 경우에는 어떤 이벤트가 일어나 지금 당장 실행할 수 없는 상태가 아니므로\nready 상태에 있는 놈들은 queue에서 기다리게 된다\n\n\nBlocked : 키보드 입력이라거나 그러한 이벤트로 인해 잠깐 멈춘 상태 - event wait\n\n얘네는 지금 바로 다시 실행할 수 있는 상태가 아니기 때문에 ready로는 가지 못하게 되는거다 - 따라서 이벤트가 처리되어(event occurs) 다시 running 가능해지면 running되는게 아니라 ready 단게로 가게 된다\nevent queue라는 것이 존재해서 event가 처리될때까지 queue에 머문다 - 그리고 event가 끝나면 ready queue로 옮겨져 또 기다리게 된다\n\n\nExit : 프로세스가 종료되어 new에서의 역순으로 처리되는 과정 - resource를 전부 반납하게 된다\n\nProcess Swapping - 7 state process model §\n\n\n중요한 이벤트가 발생해서 당장 실행해야 되는데 메모리에 공간이 없으면 덜 중요한 애들이 메모리를 양보하고 하드디스크로 내려간다 - swap-out\n이벤트가 종료되어 얘네들이 다시 메모리로 올라오는 것을 swap-in 이라고 한다\n이렇게 프로세스가 잠깐 하드로 내려가게 되는 것을 suspend라고 한다\n이런 suspend를 관리하기 위해 suspend state가 존재한다 - ready상태에서 swap-out를 먹으면 ready / suspend로 가고 blocked 상태에서 swap-out를 먹으면 blocked / suspend로 간다\n그리고 얘네들이 다시 swap-in을 먹으면. 원래의 상태로 돌아오게 된다 - 무조건 ready로 올라오는게 아니다!!\n당연하게도 일단 메모리에 있어야(ready 혹은 blocked여야) running 상태로 갈 수 있다 - suspend에서 바로 running으로 가지는 못한다\n하지만 running에서 suspend를 먹어서 내려갈 수는 있다\n또한 지금 메모리가 부족한 경우에는 프로세스가 만들어지자마자 ready / suspend로 갈 수도 있다\n\nFigure 3.11 §\n\n\nprocesses에 process table의 시작주소가 들어있고 그 테이블에 process들의 주소들이 들어있다\n여기서 process table이 PCB table이다 - 실제로는 프로세스를 구성하는 PCB, 데이터 등등이 어느 한곳에 같이 모여있는게 아니다 이말이야 - 그림에서의 process image에는 PCB는 안들어있고 그 나머지인 text, data, heap등이 저장되어 있는 구조이다\nprocess table은 pointer를 이용해서 가변길이로 할 수도 있지만 중간에 포인터를 잃어버리면 나가리기 때문에 불변길이로 선언하는 경우가 많다 - 다만 n이 시스템에 존재할 수 있는 process들의 총 갯수이기 때문에 n을 적당한 크기로 정하는 것이 중요하다 - n이 너무 크면 메모리를 너무 많이 먹고 n이 너무 작으면 process가 생성되기 힘들다 - 이 table의 일부가 비어있어야 process가 생성될 수 있기 때문\n뭐 나머지 memory table, io table 등등도 다 비슷하다\n그리고 이 table들의 주소를 담고 있는 structure가 존재하는 형태이다\nprocess table은 메모리에 상주하게 되는데 보통 이 n값이 굉장히 크기 때문에 메모리의 많은 부분을 차지하게 된다 - 그래서 PCB의 중요한 부분만 남기고 나머지 PCB중 덜 중요한 정보들은 하드디스크로 넘기게 되는데 이 부분이 u-area이다 - 다만 running 상태가 되면 이 u-area는 메모리로 다시 올라오게 된다 - state에 따라 어디 있을지 결정되는 것\n\nProcess creation 과정 §\n\ncreation : Id 만들기 → process를 위한 공간 할당 → PCB 생성 → 필요한 포인터들 연결 → 다른 자료구조들 생성\nterminate : 이것의 역순이다\n\nReady, Blocked Queue의 구현 §\n\n\n보면 큐라고 해서 이 프로세스들이 물리적으로 막 움직이는게 아니다 - 이렇게 linked-list형태로 구성되게 된다\n루트 노드에는 첫번째 프로세스의 PCB.state의 주소가 담기고 이 PCB.state에는 다음 프로세스의 PCB.state의 주소가 담기는 식으로 다음 프로세스를 계속 가리키는 식으로 큐가 구현되어있더라 이말이야\n\nInterrupt vs trap §\n\nInterrupt : 프로세스의 외부에서 이벤트가 발생해서 멈추는 것\n\ninterrupt가 발생하면 실행 모드가 user → kernel mode로 바뀐다\nuser의 process가 멈추고 kernel의 interrupt handler가 실행되게 된다 - 다음 실행할 instruction의 주소가 interrupt handler의 첫주소로 설정되는 것\ninterrupt가 끝나면 다시 원래의 instruction 주소로 돌아오며 실행모드도 user mode 로 바뀌게 된다\n\n\nTrap : 프로세스의 내부에서 이벤트가 일어나 멈추는 것\n\nContext switching이 일어나기까지의 과정 §\n\n중단된 시점의 레지스터 값을 전부 진행중인 프로세스의 메모리로 옮긴다(stop &amp; save)\nstate를 바꾼다(running → ready나 다른 상태들)\nqueue에 추가한다\n다음 process를 선택한다(select)\n그 process의 state를 변경한다(ready → running)\nprocess의 메모리에서 레지스터 값들을 다 가져오는 등 새 프로세스의 중단지점으로 다 restore한다(restore)\n바뀐 process를 진행한다\n"},"os.spring.2021.cnu.ac.kr/3.-쓰레드":{"title":"3. 쓰레드","links":[],"tags":[],"content":"쓰레드가 필요한 이유 §\n\nfork()를 하면 프로세스가 pid만 다르고 그대로 복제되는데 그러면 이 resource들을 공유하면 어떨까 하는 생각에서 나옴\n왜냐하면 fork를 통해 매번 복사를 해 메모리에 할당되면 메모리도 많이 잡아먹고 복사하는데 시간이 걸리므로 오래 걸린다 이말이야\n그래서 resource는 공유하고 dispatch만 다르게 해 시간과 메모리를 절약하자는 생각이다\ntext와 data는 공유하면서 스택만 여러개로 복제되는 구조 - 이 하나하나의 스택들을 Thread라고 한다\n그래서 이제는 실행의 단위가 프로세스가 아니라 프로세스 내의 Thread가 된다\n그리고 이 thread들의 정보를 저장하는 놈이 TCB이다 - PCB와 별개로 쓰레드들마다 자신의 정보를 담고 있는 TCB가 생기게 된다\n그래서 이제는 fork를 할때 프로세스 전체에 대한 공간을 확보하는게 아니고 스택이랑 TCB로 이루어진 thread만 확보하면 된다\n이 때문에 thread를 light-weight process라고 부른다\ndispatch의 단위는 thread가 되고 resource의 단위(resource ownership이라 한다)는 process가 되는 것이다\n하지만 process는 여전히 protection의 단위가 된다 - 어차피 thread는 데이터를 공유하므로 protection할 필요가 없더라\n그래서 이제는 execution state도 thread단위로 일어나게 되고 context change가 일어나는 것도 thread단위로 일어나게 되며 실행되다가 cpu에서 물러날때 문맥저장도 쓰레드 단위로하게 된다\n쓰레드의 장접은 다음과 같다\n\n가볍기 때문에 fork, terminate, context-change가 빠르다 - context-change가 빠르기 때문에 concurrent processing에서도 이점이 있다\n그리고 같은 프로세스여도 여러 thread를 가질 수 있기 때문에 하나의 프로세스가 실행되다 block을 먹어 기다려야 되는 상황에서도 process change없이 thread change를 통해 하나의 프로세스를 계속 이어나갈 수 있다\n또한 정보를 공유하기 때문에 IPC에서도 이점이 있다\n\n\n\n예시 - 웹 서버에서의 쓰레드 §\n\n서버에서는 클라이언트의 리퀘스트가 들어오면 이 이것을 처리하는 프로세스로 처리하는게 아니라 자식 프로세스를 fork해서 처리하게 한다\n이렇게 하는 이유는 자기가 직접 처리해버리면 이것을 처리하는 동안에는 다른 클라이언트의 리퀘스트를 받지 못하기 때문\n근데 쓰레드 없이 fork하는 것은 프로세스 전체를 다 복사해야 하므로 오래걸린다 - 이것을 thread로 처리하면 작업속도를 많이 올릴 수 있게 된다\n\n예시 - 함수 병행 처리 §\n\n함수를 호출하는거를 RPC(Remote Procedure Call) 이라고 하는데 이렇게 RPC를 하게 되면 그 callee가 처리되고 처리되는동안 caller는 놀게 된다\n근데 이제 쓰레드를 이용하면 하나의 함수를 call해서 처리하는 동안 다른 함수를 다른 쓰레드로 실행시키면 이 둘이 context switch되며 평행하게 실행되게 된다\n\nThread의 상태 §\n\nSpawn : fork에 대응\nBlock : 프로세스에서의 Block과 같다\nUnblock : ready에 대응\nFinish : terminate에 대응\n\nUser-level thread(ULT), Kernel-level thread(KLT) §\n\nUser-level thread(ULT) : 쓰레드의 생성이 user mode에서 일어나는 것 - 리눅스 POSIX표준의 p_thread가 여기에 해당한다\nKernel-level thread(KLT) : 쓰레드의 생성이 kernel mode에서 일어나는 것 - 윈도우계열 쓰레드들이 여기에 해당한다\nULT 는 실행되다가 block을 먹으면 ULT의 경우에는 user mode에서 라이브러리의 도움을 받아 생성된 것 이므로 kernel에서 보기에는 그냥 하나의 프로세스처럼 보인다 - 때문에 그냥 process를 block시켜버린다\n하지만 KLT는 block을 먹어도 kernel-level에서 실행되기 때문에 이놈이 thread인것을 알고 thread 하나만 block을 먹인다\n따라서 ULT는 block을 먹으면 그 process내에 있는 thread전부가 block을 먹게 되고, KLT는 block을 먹어도 그 thread하나만 block을 먹게 된다*\n이렇게 KLT의 경우 process전체가 block을 먹으면 thread가 가지는 concurrent의 이점을 가질 수 없기 때문에 상대적으로 느리다 - multi-thread로 짜나 uni-thread로 짜나 별반 차이가 없으니까 IO request가 많은 등의 블락을 많이 먹을거같으면 process가 dispatch의 단위가 되도록 프로그래밍 하는 것이 나을 때도 있다\n하지만 대신 ULT의 경우 kernel과 무관하게 실행될 수 있으므로 os에 자유롭게 구동된다 - multi-platform하게 구동될 수 있다\nKLT는 kernel mode로 들어가서 구동해야 하므로 실행시간이 느리다는 단점이 있다 - 하지만 ULT와는 다르게 쓰레드 하나만 블락을 먹는다는 multi-thread의 장점때문에 결과적으로는 더 빠르게 구동된다\n"},"os.spring.2021.cnu.ac.kr/4.-Concurrency":{"title":"4. Concurrency","links":[],"tags":[],"content":"Synchronize 문제의 발생 §\n\n프로세스가 concurrence하게 실행될 경우 발생하게 되는 문제이다 - concurrency 문제라고도 부른다\n프로세스 여러개가 공유하는 변수의 경우 이 프로세스들의 실행 순서에 따라 결과가 다르게 나올 수 있는 것을 의미한다\n이러한 문제의 경우 os딴에서는 절대 이 문제를 캐치해 낼 수 없다 → 프로그래머는 이러한 문제가 생길 수 있다는 것을 반드시 고려하고 대처할 수 있어야 한다\n\nmulti-thread로 프로그래밍을 하는 경우\nmultiprogramming, multiprocessing도중 공유변수를 사용하는 경우\nOS자체도 공유변수를 많이 사용하기 때문에 OS를 개발하는 경우\n\n\n이 경우에 프로세스들 간에 동기화가 되어 있지 않으면 문제가 생길 수 있다\n\n동기화 문제를 해결하기 위해서 §\n\n이것을 해결해주는 system call 이 존재한다\n이렇게 공유공간 존재하는 경우를 이 공간를 특별히 관리해야된다는 의미에서 critical section이라고 한다\n이때 mutual exclusion - 상호배제이 중요하다 - 누군가 이 변수를 사용하고 있으면 사용하면 안되고 사용하는 프로세스가 없어야 사용 가능한 것\n어떤 프로세스가 사용하고 있다는 것은 entry code와 exit code 를 통해 알아냄 - mutex나 semaphore등이 여기에 해당한다고 볼 수 있다\n변수가 사용중이면 entry code를 통해 이미 사용중이라는 것이라는 것을 알 수 있고 그럼 이 변수를 사용하는 다른 프로세스는 이 변수를 사용하지 못하고 wait상태에 들어가게 된다 - 이러한 과정을 synchronize한다고 한다\n그리고 기존에 이 변수를 사용하던 프로세스가 변수 사용을 끝내면 exit code가 실행되고 그럼 이 변수는 critical section을 빠져 나오게 된다 → 그러면 다른 프로세스가 접근해서 entry code를 확인했을 때 이 변수는 critical section에 들어있지 않다는 것을 알 수 있고 그럼 다른 프로세스에서 이 변수를 사용할 수 있게 된다\n또한 progress라는 것도 만족해야 한다 → entry / exit code를 잘못 짜면 critical section에 아무도 없는데 있는것으로 착각하고 waiting상태로 들어갈 수도 있다는 것\n\n이 progress에는 deadlock라는 케이스가 있다\n\n\nBounded waiting이라는 것도 만족해야 한다 → 변수가 critical section에 빠져서 다른 프로세스가 waiting에 들어가면 이 기다리는 시간은 무기한 기다림이 아니라 정해진 시간동안만 기다리게 된다는 것\n만약에 이런 bounded waiting 이라는게 없으면 starvation - 기아상태상태에 빠질 수도 있다 → 프로세스가 cpu할당을 오랫동안 받지 못하는것을 굶주리는 데에 비유한 것\n이렇게 mutual exclusion, progress, bounded waiting을 만족시킬 수 있는 entry code와 exit code를 짜야 concurrency의 문제가 발생하지 않는다\n\nRace Condition §\n\n여러개의 프로세스가 공유변수에 접근하고\n이 프로세스 들 간의 순서에 따라 결과가 달라진다면\n이때 프로세스들이 공규공간을 경쟁적으로 사용하려고 한다는 의미에서 Race Condition이라고 한다\n이렇게 race condition이 일어나는 구간을 critical section이라고 하는거고 변수가 이 구간에 포함되게 되면 뭐 mutual exclusion에 의해서 다른 프로세스가 기다리게 되고 뭐 이런거다\n\nOS가 해야 되는 것 §\n\n여러개의 프로세스들을 추적하고 있어야 한다 - 이놈이 critical section에 들어갔는지, 아니면 빠져나왔는지, 그리고 또 누가 critical section에 들어갈 수 있는지를 파악하고 있어야 한다\n프로세스들한테 자원을 할당하고 해제해야함\n공유변수 이외의 것은 다른 프로세스가 침범하지 못하게 보호해야 함\n프로세서의 속도에 따라서도 동기화 문제가 발생할 수도 있고 아닐 수도 있는데 프로세서의 속도(CPU의 처리속도)와 무관하게 동기화 문제가 발생하지 않도록해야 함\n\nMutual Exclusion 의 원칙 §\n\n모든 프로세스가 따라야 한다\n프로세스들간의 순서를 지정해 주는 거지 프로세스들 간에 간섭이 일어나게 해서는 안된다\ndeadlock이나 starvation이 일어나게 해서는 안된다 - progress, bounded waiting하게 실행되어야 한다\n프로세서의 속도나 실행되는 프로세스의 숫자와 무관해야 한다\n\n하드웨어적으로 해결법 §\nInterrupt disabling §\n\n인터럽트가 없다면 실행되는 중간에 다른 프로세스가 끼어드는 일이 없기 때문에 상호배제가 가능하다\n하지만 이렇게 되면 multiprogram이 아닌 uniprogram이 되어서 context change에 대한 이점을 얻지 못하게 된다\n\nAtomic operation §\n\n동기화의 문제가 발생할 수 있는 부분을 atomic operation으로 만들어보자는 것\natomic operation이라는 것은 해당 부분을 하드웨어적으로 구현해놓아 이 함수를 하나의 instruction으로 만들겠다는 것\n당연히 하나의 instruction을 실행할 때는 inturrupt가 걸리지 않으므로 동기화의 문제도 발생하지 않는다\n이렇게 atomic opration을 적극 활용하면 동기화의 문제를 막을 수 있다\n이놈을 잘 살펴볼 것 - compare_and_swap과 exchange라는 atomic operation을 이용해 mutual exclusion하게 코드를 짠 예시이다\n\n\n하지만 위의 코드는 문제가 있다\n\n다른 프로세스가 기다리는 동안 while(keyi != 0)이라는 조건을 계속 체크해야 되므로 기다리는 와중에도 cpu를 차지하게 된다 → busy waiting이라고 한다\n그리고 다음 실행 순서가 랜덤이다 → 이렇게 되면 운없는 어떤 프로세스는 starvation에 빠질 수도 있게 된다\n그리고 deadlock도 막지 못한댄다\n\nSemaphore §\n\n동기화의 문제점을 해결하기 위한 하나의 방법 - 제일 널리 사용된단다\n위의 코드와는 다르게 기다리는 중에는 cpu를 먹지 않아 busy waiting하지 않는다\n그리고 다음 실행 순서가 랜덤하지 않고 대기 큐에 들어가 FIFO하게 빠져나온다 - 그래서 starvation의 문제를 막을 수 있음\n\nMonitor §\n\n동기화의 문제를 해결하기 위해 프로그래밍 언어 차원에서 자동으로 해주는 것들도 있는데 얘네들을 monitor라고 한다\n"},"os.spring.2021.cnu.ac.kr/5.-Semaphore":{"title":"5. Semaphore","links":[],"tags":[],"content":"Semaphore란? §\n\n자료형이다\n0이상의 정수로 초기화되는 것, 1을 빼는 것(sem_wait), 1을 더하는 것(sem_signal, sem_post) 세개의 연산만 가능하다\nsem_wait가 값을 1 뺀다는 것은 프로세스 하나가 critical section에 들어가서 공유변수에 접근할 수 있는 프로세스의 갯수가 하나 줄어들었다는 의미를 가진다\n반대로 sem_signal가 값을 1 추가시킨다는 것은 프로세스 하나가 critical section에서 나와서 공유변수에 접근할 수 있는 프로세스 하나가 더 늘었다는 의미를 가진다\ncritical section을 넓게 잡으면 굳이 concurrency문제가 발생하지 않는데도 다른 프로세스들이 블락을 먹으므로 최대한 좁게 잡아서 context change가 원활하게 이루어지게 하는 것이 중요하다\n세마포 변수가 0일 경우에 다른 프로세스가 sem_wait()함수를 실행시키게 되면 이 프로세스에서의 세마포 변수는 음의 값을 갖고 이 경우에 이 프로세스는 waiting queue에 들어가게 된다\n따라서 세마포 변수가 음의 값을 가질 때 이것의 절대값은 큐에서 대기하는 프로세스의 갯수를 의미하게 된다\n그리고 sem_signal()함수가 호출되면 세마포 변수를 하나 증가시키고 큐에서 한놈을 wait에서 깨운다 - 즉, critical section에 들어있던 프로세스가 하나 사라져 가장 처음에 큐에 들어온(FIFO)프로세스를 깨워 critical section에 넣게 되는 것이다\n공유변수에 접근하는 것을 제한하는 용도로의 세마포는 당연히 0과 1의 값만 가져야 되므로 binary semaphore를 사용한다\n근데 좀 더 사용처를 넓혀서 예를 들면 10명 이하의 유저가 게임에 접속하는 것만을 허용한다 뭐 이런 경우에는 세마포 변수의 초깃값을 10으로 잡아서 활용하는것도 가능하다\n그리고 초깃값을 0으로 잡아주면 실행순서를 조절하는 것도 가능하다 - 초깃값이 0이면 이 세마포를 sem_signal()해주는 프로세스가 반드시 선행되어야 해당 세마포를 sem_wait()해주는 프로세스가 동작할 수 있는것 - 하나의 세마포가 반드시 하나의 프로세스에서 semWait, semSignal돼야되는건 아니다\nsem_signal시에 깨우는 순서를 FIFO로 하는 경우를 strong semaphore이라고 하고 깨우는 순서를 랜덤하게 하는 경우를 weak semaphore라고 한다\n여기서 주의할 점은 critical section을 공유하는 애들 중 여기에 들어가는 프로세스의 갯수가 제한되어 있는 거지 normal execution의 경우에는 critical section과 parallel하게 작동할 수 있다\n\nProducer &amp; Consumer(Bounded Buffer) §\n\n세마포를 이용해 해결할 수 있는 대표적인 예시\n봐봐라\n\n제한된 갯수의 버퍼가 있고\n제한된 갯수의 producer 프로세스, 하나의 consumer 프로세스가 존재한다\n그리고 버퍼공간 통틀어 한번에 하나의 프로세스만 접근할 수 있다\n빈 버퍼에만 producer가 접근할 수 있다\n비지 않은 버퍼에만 consumer가 접근할 수 있다 - consumer는 destructive read작업(읽으면 자동으로 지워지는)을 수행한다\n\n\n다음은 이 문제의 해결법이다\n\n\n\n근데 봐봐라\n만약에 semWait 두개의 순서가 바뀌면 어떤일이 일어나느냐\nproducer의 경우에는 만약 버퍼가 다 차있는 상태라면 semWait(s)를 통해 s를 0으로 만들었는데 마침 semWait(e)를 했더니 e가 -1이 되게 된다\n그러면 얘가 이상태로 자게 되는데 그럼 입이 돌아간다\n왜냐면 얘가 s를 하나 먹고 자므로 e를 올려줄 수 있는 consumer도 접근을 못하게 돼 둘 다 자게 되는 것이다\n이러한 경우를 deadlock이라고 한다\nconsumer의 경우에도 semWait의 순서를 바꾸면 둘 다 입돌아가게 된다\n이렇듯 semWait의 경우에는 순서가 아주 중요하다 - 약간 보니까 실행순서나 참여 프로세스 갯수 제한이 아닌 상호배제의 용도로의 semaphore는 다른 용도로의 semaphore보다 늦게 - 딱 그 공유공간에 접근하기 바로 직전에만 - lock을 걸어줘야 되는듯\n하지만 semSignal의 경우에는 잠에서 깨워주는 역할을 하므로 순서가 바뀌어도 된다\n\nMassage Passing §\n\n얘는 그냥 프로세스들 간에 메세지를 주고받으며 동기화를 하는 방법이랜다\n"},"os.spring.2021.cnu.ac.kr/6.-Deadlock-&-Starvation":{"title":"6. Deadlock & Starvation","links":[],"tags":[],"content":"Deadlock §\n\n일련의 프로세스가 영원히 블락먹는 상태를 의미한다\n어떤 프로세스의 블락상태가 풀리는것이 다른 프로세스의 실행에 달려있는데 이 다른 프로세스조차 블락을 먹어 둘다 영원히 블락을 먹게 되는 경우 이다\n예를 들면 이런 상황이다 - 프로세스 P가 D → T의 순서로 리소스를 먹고 Q는 T → D의 순서로 리소스를 먹을때 만약에 P가 D를 먹고 Q로 context change가 일어나 얘가 T를 먹으면 P도 자원을 먹지 못해 블락먹고 Q도 자원을 먹지 못해 블락을 먹으므로 둘 다 블락을 먹게 된다 - 이러한 경우에는 무조건 deadlock을 먹는건 아니므로 deadlock possible이라고 표현한다 - 즉, 무조건 deadlock이 발생하는건 아니지만 아다리가 맞으면 deadlock이 발생하게 되는 경우를 말한다\n이러한 경우에 첫번째로는 먹는 순서를 일치시킴으로 해결할 수 있다 - Q도 D → T의 순으로 자원을 먹으면 P가 D를 먹고 context change가 일어나도 Q는 D를 먹지 못하므로 T도 먹을 수 없어 Q는 블락을 먹어도 P는 블락을 안먹어 P가 자원을 뱉은 후 Q가 실행될 수 있게 되는 것이다\n\nConsumable 리소스의 deadlock §\nReusable, Consumable §\n\nreusable : 프로세스 하나가 먹고 뱉으면 다른 프로세스도 사용할 수 있는 자원 - 대표적으로 cpu가 여기에 해당한다\nconsumable : 하나의 프로세스가 먹고 나면 뱉어도 없어지기 때문에 다른 프로세스가 이용할 수 없는 자원 - interrupt처럼 처리하고 나면 없어지는 자원을 얘기한다\n\nDeadlock of Consumable resources §\n\n메세지 송수신에서의 deadlock\n\n\n\n보면 서로 메세지를 받아서 자신의 메세지를 보내는 과정을 거치는데 순서가 동일하다면 둘 다 메세지를 받아야 전송을 하므로 둘 다 블락을 먹게 된다 - 송신을 해야 반대편이 블락을 안먹는데 송신을 하려면 수신을 해야되고 그건 상대방도 동일하므로\n\nDeadlock of reusable resources §\n\n메모리 공간 할당에서의 deadlock\n\n\n\n예를들어서 메모리 총 공간이 200일때 프로세스 P는 80 → 60의 순서로 메모리 할당을 요청하고 프로세스 Q는 70 → 80의 순서로 메모리 할당을 요청할때 만약 P가 80을 먹고 context change가 일어나서 Q가 70을 먹으면 남은 공간은 50이므로 둘 다 원하는 메모리를 전부 먹지 못해 블락을 먹게 된다\n이렇듯 deadlock은 context change가 일어나지 않으면 일어나지 않지만 재수없게 context change가 일어나게 되면 일어나게 되는 경우가 많다\n프로세스 둘 중 하나의 자원을 뺏던가 아예 kill해버리는 방법으로 자원을 뱉게 하면 해결될 수 있다\n\n그림으로 deadlock 이해하기 - Resource Allocation Graph §\n\n\n동그라미가 프로세스, 네모가 자원, 네모 안의 검은 점이 이용할 수 있는 자원이다\n그리고 동그라미로부터 뻗어나오는 화살표가 자원 요청이고, 점으로부터 뻗어나오는 화살표는 자원 할당을 나타낸 것 이다\n왼쪽의 경우를 보면 P1이 Ra의 자원을 요청하나 이미 P2가 먹은 상태이다. 반면에 P2는 Rb의 자원을 요청하나 얘는 이미 P1이 먹은 상태이다. 따라서 계속 waiting하므로 deadlock이 걸리게 되는 것이다 - 이런식으로 리소스를 일부 먹고 기다리는걸 hold &amp; wait라고 한다\n반면에 오른쪽의 경우 P1은 Ra의 자원을 요청하는데 이용가능한 자원이 있으므로 문제없이 먹을 수 있다. 그리고 P2의 경우에도 Rb의 자원을 요청할때 이용가능한 자원이 있으므로 먹을 수 있다. 따라서 이 경우에는 deadlock이 걸리지 않게 된다\n\nDeadlock의 필요조건 §\n\nMutual Exclusion : 자원이 상호 배타적으로 접근해야만 정상적으로 작동할 때어떤 자원이 mutual exclusion하지 않으면 그냥 다 먹을 수 있으므로 deadlock이 걸리지 않는다\nHold &amp; wait : 프로세스가 자원을 하나 먹고 다른 자원을 먹으려고 기다릴 때 - 어떤 프로세스가 먹고 기다리는게 아닌 먹고 다시 뱉으면 다른 프로세스가 와서 사용할 수 있으므로 deadlock이 걸리지 않는다\nCircular wait : 자원의 요청, 할당관계 그래프가 화살표를 따라가봤더니 원형으로 그어질 때 - 원형으로 그어지지 않고 프로세스가 전혀 다른 리소스를 요청하는 그런 경우에는 한 프로세스가 블락을 먹어도 그걸 풀어줄 다른 프로세스가 다른 자원을 이용해 블락을 먹지 않게 되므로 블락먹은 프로세스도 풀리게 된다\nNo pre-emption : 프로세스들이 우선순위가 동일해 우선순위에 의한 작동순서를 정할 수 없고 프로세스의 자원을 뺏어오는것도 불가능할때 - 프로세스 두개가 deadlock을 먹었는데 하나의 우선순위가 높아 나머지 하나를 죽여버리면 deadlock이 풀리기 된다\n이 넷중에 하나만 만족하지 않아도 deadlock이 걸리지 않는다 - 즉, 이중에. 일부만 만족하는 것이 무조건적으로 deadlock을 야기하는건 아니다 - Circular wait의 상태여도 deadlock이 무조건 걸리는건 아니다 이말이야 - 원이 있어도 Mutual exclusion하지 않다던지 하는 연유로 프로세스 종료 시나리오가 완성된다면 deadlock이 아닌 것이다\n반면에 circular wait이면 반드시 deadlock이 되는 상황이 있다 - 연관되어 있는 모든 자원이 mutual exclusion, 즉, 한번에 한놈만 접근할 수 있을 때에는 circular wait이 일어나면 반드시 deadlock이 걸리게 된다\n\nDeadlock의 해결 §\n정보가 있는 경우 §\n\n여기서의 정보라는 것은 프로세스가 미래에 어떤 자원을 요청할지에 대한 정보나 자원이 mutual exclusion하다 등의 정보를 말한다. 나중에 프로세스가 어떤 자원을 요청할지를 미리 안다면 지금 내가 누구한테 자원을 줬을때 이것이 결국에는 deadlock을 야기할지 안할지를 알 수 있기 때문\nAvoidance : 자원의 요청과 할당관계에서 위와 같은 정보가 OS에 전달된다면 OS는 이 상황을 피하도록 대비를 할 수 있다 - 미래를 알고 피하는 것 - 그래서 OS는 deadlock posible 한 상황이면 리소스를 아예 할당해주지 않는다\n\n정보가 없는 경우 §\n\nPrevention : 이러한 정보가 없어도 저 4개의 필요조건중 하나라도 피할 수 있도록 잘 조정하는 것을 의미한다 - 미래는 모르지만 미리미리 방지하는 것\nDetection &amp; Recovery : 프로세스가 deadlock에 걸렸는지 아닌지를 계속 확인하고 걸렸으면 여기에서 빠져나오도록 일부를 kill한다던가 하는 등의 복구작업을 하는 것을 의미한다 - 여기서 deadlock을 탐지하는 방법은 프로세스들을 계속 관찰하면서 이 프로세스가 종료될 수 있는 시나리오가 있느냐를 확인하는 것이다 - 따라서 deadlock인것처럼 보여도 연관된 프로세스가 순차적으로 종료될 수 있는 그런 시나리오가 존재한다면 이것은 deadlock이 아닌 것이다\n\nPrevention strategy §\n\n아까도 말했지만 4가지 조건들을 회피해 deadlock이 걸리지 않게 하는 것\n간접(Indirect) 적인 방법 - Circular wait외의 나머지(Mutual exclusion, Hold&amp;Wait, No pre-emption) 이 세가지중 하나라도 발생하지 않도록 조치하는것\n직접(Direct) 적인 방법 - Circular wait가 일어나지 않게 조치하는 것\n\nMutual exclusion의 경우에는 리소스를 상호배타적으로 할당하지 않는 것이다\n\n하지만 리소스의 특성상 이놈이 상호배타적으로 할당해야만 하는놈인지 아니면 상호배타적으로 안해도 되는지 를OS가 알기가 힘드므로 쉽지 않다\n\n\nHold&amp;wait은 방지가 가능하다 - 프로세스가 시작하면 여기에 필요한 자원들을 중간에 끊지 않고 한번에 다 할당시킨다(serial하게)\n\n하지만 여기에는 몇가지 단점이 있다\n프로세스가 시작하면 거기에 필요한 자원들을 모두 할당하므로 이놈이 사용하지 않을 때 에도 먹고 있게 되어 비효율적이 될 수도 있다\n또한 어떤 리소스가 필요한지 실행시점에 다 알 수 없는 경우도 있다\n따라서 OS는 별로 선호하지 않는 방식이다\n\n\nNo pre-emption : 우선순위가 같은 경우에 OS가 프로세스 하나의 편을 일방적으로 들어서 나머지 프로세스의 리소스를 다 뺏어버리는 방법\n\n하지만 리소스를 뺏어버리면 그 프로세스는 그만큼 딜레이되는 것이므로 형평성의 문제가 있어 OS입장에서는 간편하지만 문제가 생길 수도 있다\n\n\nCircular wait : 리소스 할당에 원칙을 매기는 것으로 해결할 수 있다\n\n예를들면 오름차순으로 먹고 요청하는 것은 가능하지만 내림차순은 안된다고 했을 때 circular wait가 일어나려면 반드시 한번은 내림차순으로 가야되므로 이놈에게 리소스를 할당해주지 않으면 된다\n구체적인 예를 들어보면 프로세스 P가 R1먹고 R2요청하는 것은 오름차순이므로 허용, 다른 프로세스 Q가 R2먹고 R1 요청하는 것은 내림차순이니까 안된다고 했을 때 Circular wait이 성립하지 않으므로 deadlock이 발생하지 않는다\n\n\n\n\nprevention strategy는 아주 보수적인 해결방법이다 - avoidance와 다르게 미래를 잘 알지 못하는 상황에서 deadlock이 걸릴지 안걸릴지를 판단해야되므로 보수적으로 할 수밖에 없다\n\nAvoidance Strategy §\nDeadlock이 걸리지 않는 경우 §\n\n\nClaim matrix : 프로세스가 종료되는데 필요한 리소스들의 갯수\nAllocation matrix : 현제 프로세스들에게 할당된 리소스의 갯수\nC - A : 프로세스가 종료되기 위해 더 필요한 리소스의 갯수\nResource vector : 리소스를 동시에 할당받을 수 있는 프로세스의 통 갯수 - 아까의 allocation graph에서 검은 점의 갯수라고 보면 된다\nAvailable vector : 현재 프로세스들이 할당받은 다음 더 할당받을 수 있는 프로세스의 갯수 - 잔여분\nClaim matrix와 Resource vector를 아까말한 정보라고 하는 것이다 - 프로세스가 얼마나 자원을 필요로 할 지, 자원을 얼마까지 할당해줄 수가 있는지에 대한 정보가 존재하기 때문에 OS가 Avoidance strategy를 사용할 수 있는 것\n여기서 보면 P2가 R3를 하나 필요로 하는데 R3도 한개가 남으므로 줄 수 있다. 따라서 얘가 종료되고 남은 리소스를 전부 반환하면 Available vector는 623이 될 것이다. 이제 얘네들을 가지고 P1, P3, P4를 하나씩 끝내보면 모두 종료되는 시나리오가 존재하므로 이 경우에는 deadlock이 걸리지 않을 수 있다\n\nDeadlock이 걸리는 경우 §\n\n\n윗쪽의 상태를 보면 아직 종료 시나리오가 존재한다 - P2에게 102를 할당해주면 P2가 종료되며 순차적으로 종료될 수 있기 때문 - 이렇게 종료 시나리오가 존재하는 상태를 safe state라고 한다\n하지만 P1에게 101을 할당해주면 아래와 같이 종료 시나리오가 나오지 않게 된다\n왜냐면 아래쪽을 보면 모든 프로세스가 R1을 필요로 하는데 R1의 잔고가 하나도 남아있지 않은 상황이다. 따라서 프로세스 종료 시나리오가 나오지 않기 때문에 이 경우 추후에 deadlock이 발생하게 된다\n하지만 아직은 deadlock이 아니다 : 아직 P1이후로는 아무도 리소스를 요청하지 않았기 때문에 deadlock이라고는 할 수 없는것 - 즉, 아직 할당해줄 수 있는 자원이 남았기 때문에 이 범위 안에서 리소스를 요청하게 되면 그것을 수락할 수 있기 때문이다\n그래도 worst case를 가정했을 때 - 만약 저 프로세스들 중 어느 누구라도 R1을 요청하는 상황 - deadlock이 걸리게 되고 따라서 종료시나리오가 나오지 않는 것이라고 판단하는 것이다 - 이렇게 deadlock은 아니지만 종료 시나리오가 나오지 않는 그러한 상태를 unsafe state라고 한다\n따라서 OS는 P1한테 101을 주면 unsafe state이 걸린다는것을 알 수 있으므로 P1이 101을 요청해왔을때 이것을 거절하는 식으로 deadlock을 avoid할 수 있다\n이렇게 요청이 들어왔을때 unsafe state로 바뀌는지를 계산해 할당여부를 결정하는 식으로 avoid하게 된다\n이렇게 할당할때 조심스럽게 다 계한하고 위험요소가 없을 때 할당하는 것(worst case를 판단해서 할당여부를 결정하는 것)을 banker’s algorithm이라고 한다\n하지만 프로세스가 얼마만큼의 리소스를 필요로 하는지 알기 어렵기 때문에 - 저 claim matrix와 resource vector를 알아내는게 쉬운일이 아니기 때문에 avoid를 하는 것은 쉬운일이 아니다\navoidance는 미래를 알고 대비하는 것 이기 때문에 보수와 방임의 중간정도이다\n\nDetection strategy §\n\n\nDetection의 경우에는 저 Claim matrix를 알 수가 없고 단지 Request matrix만 알고있는 상황이라는 점에서 Avoidance와는 좀 다르다 - 여기서 request matrix는 앞으로 더 요청할 수도 있지만 일단 지금은 요정도 요청한다이런 의미의 표이다\n그래서 Request matrix와 Available vector를 가지고 프로세스 종료 시나리오를 짜봣을때 시나리오가 안나오면 deadlock이라고 판단하게 되는 것 이다 - 시나리오 짜는 방법은 저 request matrix 이후 더 이상 요청을 하지 않고 종료된다는 가정 하에 종료 시나리오를 짜는 방법이다\n\nRecovery strategy §\n\n프로세스들을 다 죽일수도 있지만 그럼 처음부터 다다시 해야되므로 효율적이지 않다\n방법1 : git reset HEAD^마냥 그 주기적으로 detection을 하고 이전 detection했을때의 상태를 저장해놨다가 deadlock이 발생하면 이 지점으로 다시 돌아가는 방법으로 해결할 수도 있다\n방법2 : deadlock이 풀릴때까지 프로세스를 하나씩 뱉게 하거나 죽여버리는 것이다\nDetection &amp; Recovery는 방임형 해결방법이다 - 걍 냅뒀다가 deadlock이 발생하면 해결하는 것 이므로\n\n밥먹는 철학자 문제 §\n\n철학자는 스파게티를 먹는데 2개의 포크가 필요하다\n포크 하나를 동시에 두명이 들 수 없다\n이 경우 deadlock이 걸리는 상황은 모든 사람이 왼쪽(혹은 오른쪽)의 포크만 들고 기다리는 상태이다\n해결법1 - 한번에 4명에게만 포크를 들 수 있는 자격을 준다\n해결법2 - 한번에 짝수번째/홀수번째에게만 포크를 들 수 있는 자격을 준다\n해결법3 - 포크를 드는 순서를 다르게 한다 - 기준을 한명 정해서 그사람을 기준으로 짝수번째 위치의 사람은 왼쪽거를 먼저 들고, 홀수번째의 사람은 오른쪽꺼를 먼저들게 하는 식으로 하면\n"},"os.spring.2021.cnu.ac.kr/7.-메모리-관리":{"title":"7. 메모리 관리","links":[],"tags":[],"content":"Overlay 기법 §\n\n옛날에는 메모리가 부족하기 때문에 프로그램의 일부분만 메모리에 올려놓고 올려놓은 부분을 전부 실행하고 나면 나머지 부분을 올려서 프로그램을 구동햇다\n새로 올라온 부분은 이전 부분을 지워버리게 되는데 이것을 이제 overwrite라고 한다\n근데 이제 프로그램을 잘못 나눠서 나머지 부분을 실행시키는데 앞부분의 자원이 필요해지면 또 아래서 갖고와야 되므로 프로그램의 구동시간이 오래 걸리게 된다 - 따라서 제대로 나눌 수 있도록 잘 프로그래밍 하는 것이 중요했다 이말이야\n이런 프로그램을 나눠 순차적으로 메모리에 올리며 구동하는 것을 Overlay기법이라고 한다\n얘는 이제 swapping이랑은 다르다 - swapping은 바꿔치기하는거고 overlay는 덮어쓰는 개념\n\nMemory, Program Partition §\n\n이제 multiprogramming을 하기 위해 여러개의 프로그램을 메모리에 올리고싶어졌다\n그래서 메모리를 쪼개서(memory partition)여러 프로그램을 올리게 되는데\n메모리를 쪼개다 보면 프로그램이 그 공간 안에 다 안들어갈 수가 있으므로 프로그램도 쪼개게 된다(program partition)\nOS는 이제 메모리를 어떻게 쪼개고 프로그램도 어떻게 쪼개서 여기에 집어넣을건지를 관리해야 한다\n\nAddress Translation §\n\n우리가 코드를 짤때 쓰는 변수같은것들은 다 symbolic address이다 - 우리가 변수에 값을 저장한다는 말은 그 변수가 의미하는 주소에 저장된 값이 그것이라는 소리이므로\n근데 이제 컴파일 과정을 통해 오브젝트파일(c언어에서 .o 파일)로 바뀌게 되면 이 주소는 logical(relative) address가 된다 - 얘는 프로그램의 시작주소를 0이라고 했을때 해당 symbolic address가 저장된 곳의 위치 - 시작점과 현위치의 차이점이라고 생각하면 된다이다.\n이게 실행가능한 파일(executable code, machine code)가 되어 실행되면 실제로 메모리에 저장된 주소인 physical(absolute) address가 된다\n\n얘는 실제 주소를 가리켜야 되므로 레지스터 하나에다가 프로세스가 적재된 메모리의 첫 시작점을 저장하고 거기에 relative address를 더해 physical address를 구하게 된다\n다만 여기서 시작 주소라는 것은 PCB를 제외한 곳의 시작주소이다\n그래서 시작주소는 Base register, 끝주소는 Bounds register에 저장된다\nbounds register는 경계선을 그어줌으로써 허용된 범위 밖을 참조하지 못하게 하는 기능을 한다\n\n\n근데 swapping이 일어나게 돼 얘가 하드로 내려갔다가 다시 올라오면 원래 있던 그 위치로 올라오게 되는 것이 아니다. 따라서 프로세스의 첫주소가 바뀌게 되는데 이렇게 swapping에 의해 프로세스의 첫주소가 바뀌어 physical address가 바뀌는 것을 Relocate라고 한다\nOS는 이놈이 swapping 되어 다시 올라올때 어떻게 첫주소가 바뀌는지를 관리해야 한다 - relocation돼도 문제없이 physical address를 얻어낼 수 있도록\n\nOS가 메모리 관리를 위해 해야되는 것 §\n\nRelocation : 이걸 추적하고있어야됨\nProtection : 남의 영역에 침범하지 않도록 관리\nSharing : 프로세스 간 공유 메모리가 있을 때 protection을 지키는 선 한에서 문제없이 공유될 수 있도록 해야 함\nLogical organization, Physical organization : 실제로는 프로그램이 여러개로 나뉘어서 메모리에 적재되지만 나뉘어지지 않은것처럼 생각하도록 동작해야됨 - 이때 유저 입장에서 붙어있는걸로 생각하는 것이 Logical organization이고 컴퓨터입장에서 나뉘어있는것으로 생각하는 것이 Physical organization이다\n\nFixed partitioning §\n\nFixed partitioning : 메모리를 나눌때 고정크기로 나누는 것\n\nEqual-size partitioning §\n\n그냥 딱 정해진 크기로만 자르는 것\n하지만 얘한테는 다음과 같은 문제점이 있다 :\n\n프로그램이 잘라진 크기보다 더 크면 프로그램을 잘라서 올리는 overlay기법을 사용해야 된다\n반대로 프로그램의 사이즈가 너무 작게 되면 나머지 공간들이 낭비된다 - 이 낭비되는 공간을 internal fragmentation이라고 한다\n\n\n따라서 나누는 크기가 너무 크면 internal fragmentation이 커지고 너무 작으면 overlay기법에 의해 IO request가 너무 많이 발생해 문제가 된다\n\nUnequal-size partitioning §\n\n얘는 이제 프로그램의 크기에 딱 맞게 메모리를 나누는게 아니고 약간 호텔에서 1-2인실, 3-4인실 있는것처럼 여러개의 사이즈로 미리 나눈 다음 프로그램의 크기에 맞게 이 나뉘어진 공간에 넣는구조이다\n이렇게 넣을때는 각 방마다 큐를 만들어서 미리 프로그램들을 분배해서 이 큐에 넣어놓는 방법도 있고 큐를 하나만 써서 메모리에 적재될때마다 그때그때 분배하는 방법도 있다.\n하지만 얘한테도 단점이 있다 :\n\n나눈 파티션의 갯수가 결국에는 메모리에 올라갈 수 있는 user program의 갯수가 된다. 따라서 fixed 보다는 올릴 수 있는 프로그램의 수가 적어지게 된다\n얘도 internal fragment가 생긴다\n\n\n\nDynamic partitioning §\n\nDynamic partitioning : 메모리를 나눌 때 프로그램의 크기에 따라 유동적으로 나누는 것 - 그냥 프로그램의 사이즈와 동일하게 나뉘어진다\n이제 얘는 다음과 같은 문제점이 있다 :\n\n프로그램이 메모리에 적재되어있다가 나가면 그 아래에 있던애가 위로 땡겨져서 빈공간을 채우는게 아니라 그냥 비워진 상태로 있게 된다\n근데 그 이후 이 공간보다 작은 프로그램이 여기 적재되면 남는공간이 생기는데 이 공간의 크기가 작을 경우 어떤 프로그램도 들어오지 못하는 수가 있다 - 이런 공간들을 External Fragmentation이라고 하며 이런 공간들이 많아지면 역시 메모리가 비효율적으로 돌아가게 된다\n즉, 메모리가 남는 현상에 대해 fixed의 경우에는 internal이란 이름을 붙인거고 dynamic의 경우에는 external이라고 이름을 붙인 것\n\n\n위와 같은 현상을 방지하기 위해 저 비워진 공간을 비워두지 않고 땡겨서 공간들을 다 합쳐 이 공간들을 활용하는 방법이 나온다. 이것을 Compaction이라고 하며 윈도우에서 “디스크 조각 모음”이라고 하는 것(물론 얘는 메모리가 아니라 하드의 빈공간을 합치는거다)이 여기에 해당한다\n\n적재 알고리즘 §\n\n일단 프로그램이 얼마의 메모리를 먹을지는 적재시점에 알기는 어렵다 - 그래서 대략적으로 추정해서 적재하게 됨\n아래와 같은 적재 알고리즘들을 Placement Policy - 적재정책이라고 하더라\nFirst fit : 메모리의 처음부터 찾기 시작해 가장 먼저 등장하는 적재 가능한 공간에 넣는 것\nBest fit : 메모리 전체를 다 뒤져서 제일 적게 External fragment가 생기는 곳에 넣는 것\nWorst fit : 메모리 전체를 다 뒤져서 제일 많이 External fragment가 생기는 곳에 넣는 것 - Worst라고 해서 안좋은게 아니다 - 저게 크면 저부분에 또 다른 프로그램이 올라갈 확률도 많아지므로\nNext fit : 제일 최근에 넣었던 부분 바로 옆에다가 적재하는 것\n저것들 중에 Best, worst가 적재하는데 제일 오래 걸린다\nBuddy system : 얘는 프로그램의 크기에 따라 메모리를 자르긴 하되 2의 배수에 맞춰서 메모리를 자르는 방식이다 - 만약에 100k를 요청하게 되면 128k의 메모리 공간에 적재하는 것 - 메모리 공간을 절반으로 자르고 자르고 해서 제일 잘 맞는 곳에다가 적재하게 된다\n\nPaging §\n\n일단 메모리를 고정크기로 잘게 나눈다. 이 나눈 고정크기의 메모리 조각을 frame이라고 한다\n그리고 프로그램도 같은 크기로 잘게 나눈다. 이 나눈 고정크기의 프로그램 조각은 page라고 한다\n이 둘의 크기가 같기 때문에 하나의 페이지는 하나의 프레임에 올라가게 된다\n고정크기를 활용하기 때문에 fixed partitioning의 상위호환이라 볼 수 있다\n\nPage table §\n\n얘는 프로그램을 메모리에 적재할 때 연속된 공간에 적재하지 않을 수도 있다\n대신 해당 프로그램이 어디어디에 적재되어있는지를 알려주는 역할을 하는 page table이 존재하게 된다\n전에 PCB를 모아놓은 Process table이 있다고 했는데 여기에 page table도 같이 들어있다\n이 page table은 배열처럼 인덱스마다 프로그램이 적재된 페이지의 번호를 저장한다 - 인덱스는 page번호(프로그램을 프레임 크기만큼 잘라서 앞에서부터 0, 1, … 이렇게 번호를 매긴 것), 안에 저장돼있는 값은 frame 번호(메모리 전체를 frame크기만큼 잘라서 0, 1, … 이렇게 번호를 매긴 것)\n따라서 page 번호는 프로그램을 앞에서 잘라 매긴것이므로 logical address를 표현할 때 사용되고 frame번호는 메모리를 앞에서부터 잘라 매긴 것 이므로 physical address를 표현할 때 사용되는 것이다\nfree frame table도 존재해서 남은 프레임들의 번호도 저장하게 된다\n\nPaging에서의 physical address 구하기 §\n\n\nRelative address는 수치상으로 시작점부터 얼마나 떨어져 있는지를 나타내는 개념이고\nLogical address는 relative address를 page 번호를 이용해 나타낸 개념이라는 차이점이 있다 - 어쨋든 둘 다 시작점을 기준으로 거리를 나타내는 개념이다\n왼쪽의 프로세스를 page크기인 1k로 자르면 오른쪽 그림처럼 나온다. Relative address 1502는 1024 + 478이므로 page 하나와 478만큼의 거리만큼 떨어진 곳이 해당 주소가되는 거고 이걸 logical address로 표현하면 page1번 시작점으로부터 478만큼 떨어져 있다는 의미로 page# = 1, Offset = 478이 되는 것이다 - Offset은 페이지의 시작점으로부터 얼마나 떨어져있는지를 나타내는 것\n이것을 이진법으로 계산한 것이 위쪽에 나와있는 수치들이다. 1024는 2의 10제곱이므로 16비트로 표현된 relative address에서 6비트 /10비트로 나누면 앞쪽부분이 page#, 뒤쪽부분이 Offset이 되는 것이다\n\n\n\n이것을 이용해 physical address를 나타내는 것은 이 그림에 나와 있다.\n일단 page# 이 1 이므로 이것을 page table의 인덱스로 넣어주면 거기 저장되어있는 값이 frame# 가 되는것이다\n따라서 이 frame# 을 6-bit page# 에다 넣어주면 바로 physical address가 나오게 되는 것 이다 - page table에 가서 frame# 만 가져다가 붙여주면 되기 때문에 address translation이 아주 간편하다\n\nSegmentation §\n\n이제 얘는 고정크기로 나누는게 아니고 메모리를 프로그램의 function(module)크기로 나눠서 적재하는 기술\n메모리와 프로그램을 같은 크기로 나누되 그 크기는 프로그램의 function(module)의 크기를 따라간다고 생각하면 된다\n이렇게 하는 이유는 memory sharing을 할때도 function(module)단위로 하게 되므로 이것의 크기를 기준으로 나누는게 좋겟다고 생각한것\n이렇게 function(module)을 기준으로 나눈 조각조각을 segmentation이라고 한다\n얘는 가변크기이기 때문에 dynamic partitioning의 상위호환이라고 볼 수 있다\n\nSegmentation에서 physical address 구하기 §\n\n\n얘는 paging처럼 크기가 고정되어 있지 않으므로 앞의 몇비트는 segment# 를 나타내는데 쓰이고 나머지는 Offset을 나타내는데 쓰이는 식으로 구성된다 - paging처럼 relative address에서 몇비트를 자른다고 해서 바로 segment# 가 구해지는게 아니다\n그래서 예시를 보면 segment# 에 4비트가 할당되어 있으므로 한 프로그램이 가질 수 있는 총 segment# 의 갯수는 2의 4제곱인 것이고 그 뒤에 offset으로 12비트가 할당되어 있으니 한 segment는 최대 크기가 2의 12제곱이 되는 것이다\n프로세스 전체를 segment0 750, segment1 1950으로 자른 다음(자르는 기준은 당연히 module이겠쥬?) 계산해보면 logical address segment1의 offset 752부분이 relational address의 1502와 같아지게 되는 것\n\n\n\n그래서 이 logical address로 physical address를 구하는 방법이 위 그림이다\nsegment table은 segment가 어디서 시작하는지에 대한 주소인 base와 한 segment의 길이인 length를 담고 있는 배열이다.\nlogical address의 앞 4비트를 이용해 인덱스를 알아내고, 그 인덱스로 가서 뒤의 16비트를 가져오면 그게 segment의 시작점 주소가 된다. - 이번에는 paging과 다르게 풀 주소값이 저장되어 있으므로 이 값을 offset이랑 더해 physical address를 얻어내는 것\n그리고 length는 offset값이 정상인지를 검사하는 용도로 쓰인다. 즉, segment의 길이가 length이므로 offset이 저 값보다 작아야 정상인 것\n\nPaged Segmentation §\n\n얘는 이제 저 둘을 합친 개념이다. 즉, function(module)별로 메모리에 적재를 하되 얘네들을 여러 frame에 걸쳐서 적재를 하는 것을 Paged segmentation이라고 한다\n즉, function(module)하나를 여러 연속된 frame에 걸쳐 적재하는 것\n"},"os.spring.2021.cnu.ac.kr/8.-가상메모리":{"title":"8. 가상메모리","links":[],"tags":[],"content":"가상메모리 §\n\n봐봐라\n실제로는 프로그램의 전부가 메모리에 올라가는 것이 아닌 프로그램의 페이지 일부만 메모리에 올라가게 된다\n그리고 실제로는 페이지들이 하드에나 메모리에나 연속된 공간에 있지 않고 다 흩어져 있다\n하지만 우리가 생각할때는 이 페이지들이 전부 메모리에 연속적으로 적재되어있다고 생각하고 프로그램을 짜게 된다 - 이렇게 사용자입장에서 생각하기 편하게 하려고 착각을 유도하는 기법을 가상 메모리(Virtual Memory) 라고 한다\n\n이렇게 가상 메모리 기법을 적용한 paging을 일반 paging과 구분해 Virtual Memory Paging이라고도 부르더라\n마찬가지로 가상 메모리 기법을 적용한 segmentation을 Virtual Memory Segmentation이라고 한다\n\n\n이렇게 함으로써 우선 메모리 사이즈보다 더 용량이 큰 프로그램도 메모리에 적재시킬 수 있고, 프로그램 전부가 올라가지 않기 때문에 더 많은 프로그램을 적재할 수 있어 Multiprogramming에서도 이점이 있다(Multiprogramming level을 높일 수 있다)\n\n그리고 이것은 프로그램 개발자의 관점에서도 프로그램 크기에 따라 다르게 프로그래밍 할 필요가 없다는 이점이기도 하다\n\n\n이때 원하는 페이지가 메모리에 적재되어있지 않고 하드에 들어있을때 Page fault가 일어나게 된다 - 이렇게 page fault가 일어나면 block을 먹고 IO operation이 일어나며 가져오고난 뒤에는 인터럽트를 걸고 다시 ready상태로 바뀐 다음에 dispatch되면 실행되는 과정을 거치는 것\n가상메모리가 잘 구동되기 위해서는 물리적으로 메모리 공간을 나눠 page가 들어올 frame들을 구성하는 하드웨어적인 역할 과 page replacement같은 기능을 수행할 소프트웨어적(운영체제적)인 역할 이 중요하다\n\nPage 사이즈 정하기 §\n\nPage 사이즈가 작으면 만약에 page fault가 일어났을때 한번에 가져오는 양이 적기 때문에 page fault가 자주 일어나게 된다\n또한 page table의 사이즈가 커져 PCB가 커지기 때문에 많은양의 메모리를 먹게 된다\n하지만 반대로 page 사이즈가 너무 크면 작은 프로그램의 경우에는 page하나에 담기고 남은 부분이 internal fragmentation이 되기 때문에 메모리의 낭비가 생기게 된다\n이렇듯 운영체제를 설계할때는 항상 대조되는 선택지의 장단점이 존재하기 때문에(Trade-off라고 한다) 이것을 잘 조화시켜서 최선의 결과를 내는 Optimal Design이 중요하다\n요즘의 경우에는 메인메모리의 값이 그렇게 비싸지 않기 때문에 fragmentation이 그렇게 큰 문제가 안돼 page의 사이즈를 크게 하는것이 추세란다\n\n\n\n첫번째 그래프에서 왜 사이즈가 작을때 page fault가 작아지는지는 모르겠음 - 어중간할때는 왜 큰지도 모르겠음\n어쨋든 사이즈가 커지면 한번에 많이 갖고오므로 page fault가 잘 안일어난다는게 중헌것이고\n두번째 그래프는 프로세스 하나에 대해 frame이 몇개가 할당되는지에 대한 그래프다. 높을수록 프로세스 하나에 많은 frame을 할당받으므로 메모리에 올라갈 수 있는 프로세스의 갯수는 적어지고 대신 보다시피 page fault rate는 적어진다\n\n\n\n근데 할당되는 프레임의 갯수가 많아지면 rate가 줄어야 정상인데 replacement algorithm 이 잘못되면 저렇게 rate가 치솟는 현상이 생기고 이것을 Belady’s anomaly라고 한다\n\nPage Replacement §\n\n이전에 프로세스가 메모리에 들어와야 되는데 메모리에 자리가 없으면 한놈이 자리를 비켜주고 하드로 내려가는거를 swapping이라고 했는데\nPaging기법에서도 동일하게 메모리에 자리가 없으면 어느 한 놈이 자리를 비켜주는 동작을 하게 되고 이것을 Page Replacement라고 한다\n근데 이때 아무 page나 내려보내게 되면 프로그램이 비효율적으로 동작할 수도 있다\n\n즉, page 교체 알고리즘에 따라서 동작의 효율성도 달라질 수 있다는 소리임\n뭐 예를 들면 우선순위가 비교적 높은 놈의 page를 내려보내면 얘를 조만간 다시 갖고 올라와야되기 때문에 page fault가 자주 일어나 IO request도 자주 일어나게 되는 것\n\n\n그리고 page는 어차피 원본의 page가 하드디스크에 저장되어있기 때문에 메모리에 적재되어있던 page와 하드디스크에 있던 원본의 page가 차이가 없으면 하드로 내려보낼 때 굳이 새로 write하지 않고 하드에서 올라오는 page를 그 자리에 overwite하게 된다\n하지만 메모리에 올라와있던 page에 변경이 생기게 되면 그제서야 하드에 write하는 작업을 하게 된다\n그리고 이제 안그래도 IO가 일어나서 기다렸는데 자리가 없어서 replacement까지 일어나면 OS입장에서는 굉장히 기다리는 시간이 아까우므로 OS는 항상 일정한 수만큼 blank(비어있는) frame을 만들어놓는다 - 그래서 IO가 끝나면 바로바로 올릴 수 있게\n\n위에꺼를 반영한 paging / segmentation §\n\n\n여기서 페이지 테이블의 한 행의 구조를 나타낸 것이 아래 그림인데 보면 frame number만 있는게 아니고 앞에 Control Bit가 붙는다\n얘는 데통에서 헤더마냥 frame / page 의 여러가지 정보를 담는 부분이다\n일단 P는 이 page가 현재 메모리에 적재되어있냐를 나타내는 비트(Present)이다.\n\n즉, 이게 enable되어 있으면 frame number부분에 유효한 number가 들어가 있을 것이고\ndisable되어 있으면 메모리에 적재되어있지 않다는 뜻으로 유효하지 않은 number가 들어있게 된다\n\n\n그리고 M은 이 page가 변경되었냐를 나타내는 비트(Modified)이다\n\n위에서 설명한것처럼 page replacement를 할 때 변경되지 않았으면 굳이 하드에 write를 하지 않아도 되기 때문\n\n\nsegmentation의 경우에도 앞에서 배운거랑 마찬가지되 P, M이 붙게 된다\n\nPaging의 address translation 방법 복습 §\n\n\n가상 주소에서 offset은 그대로 가고 page# 을 이용해 frame# 를 찾는거\n레지스터에 저장된 page table의 시작점, 즉. page table ptr을 이용해 page table로 이동하고, page# 를 인덱스로 하여 frame# 을 얻어내 physical address를 얻어내는 것\n\nThrashing §\n\n\n봐봐라\n메모리에 많은 프로세스가 올라가게 되면, 즉, multiprogramming level이 올라가게 되면 당연히 cpu utilization도 늘어난다\n근데 multiprogramming level이 늘어난다고 무조건적으로 좋은것은 또 아니다 이말이야\n\n왜냐면 multiprogramming level이 늘어나면 하나의 프로세스에게 할당되는 공간이 줄어들고 그러면 page fault가 더 자주 일어나게 되기 때문이다\n그래서 저 위의 그래프에서 보이듯이 일정수준까지는 multiprogramming level이 늘어갈수록 cpu utilization도 늘어나게 된다.\n하지만 그 수준을 넘어서게 되면 위에서 설명한것처럼 page fault가 자주 일어나 cpu utilization이 급격하게 하락하게 된다\n이 지점을 Thrashing이라고 하는 것. 즉, multiprogramming level이 과도하게 많아지면 page fault가 너무 자주 일어나 cpu utilization이 급락하는 것을 의미한다\n따라서 운영체제 입장에서는 Thrashing은 반드시 막아야 되는 현상이다\n\n\n따라서 multiprogramming level이 너무 낮으면 프로세스 하나가 블락을 먹었을때 대체제의 선택폭이 좁아져 cpu utilization이 안좋고 또 너무 높으면 thrashing이 일어나기 때문에 안좋아져서 적절한 level을 잡는 것이 중요 하다\n\nLocality - 지역성 §\n\n만약에 프로그램에 while문이 하나 있다고 하고 이부분이 세개의 page로 나뉘어졌다고 해보자\n근데 만약 메모리에 공간이 없어서 두개의 frame밖에 할당하지 못한다면 루프가 돌때마다 page fault가 일어나므로 아주 효율성이 떨어질 것이다\n따라서 다음과 같은 경우에는 해당 프로세스에게 3개 이상의 frame을 할당하는 것이 효율성을 높이게 된다\n이렇듯 프로세스를 이루는 page들 중에서도 집중적으로 실행되는 page들을 중간에 끊지 않고 전부 메모리에 올려 page fault를 줄이는 것을 지역성(Locality) 이라고 한다\n\nCombined segmentation &amp; paging §\n\n\n이부분은 별로 설명 안함 - 가상메모리에 page# 와 seg# 둘 다 있어서 page table과 segment table을 둘 다 이용한댄다\n\nMulti-Level Hierarchical Page Table §\n\n\npage table을 다계층 구조로 만들어 page table의 사이즈를 줄이는 기법이다\n\n봐봐라\n만약에 page# 에 20비트가 할당되어있고 offset이 12비트인 32비트 체제라면 page table의 길이는 2의 20승이다\n하지만 프로그램의 크기가 작아서 page가 몇개 되지 않는다면 2의 20승 중에 일부만 사용하고 나머지는 버리게 되는 셈이다\n근데 이것을 두개의 계층으로 나누면 첫 10비트는 첫번째 계층 table에서의 index를 나타내고 나머지 10비트는 두번째 계층 table에서의 index를 나타내는데\n만약에 프로그램을 구성하는 page의 갯수가 2의 10제곱보다 작으면 하나의 2^10 사이즈 테이블로 모든 page# 에 대응되는 frame# 을 저장할 수 있자네\n이때 이 2^10 사이즈 테이블이 2계층 테이블인거고 이 2계층 테이블들로 접근할 수 있도록 얘네들의 주소를 담고 있는 테이블이 1계층 테이블인 것이다\n따라서 page의 사이즈가 2^10보다 작으면 1계층 테이블에는 하나의 원소만 존재하고 2계층 table하나만 있어도 모든 page에 대응되는 frame을 저장할 수 있으므로 메모리를 2^11 만 차지하게 되는 것 - 계층구조를 도입하기 전인 2^20에 비해 엄청난 양의 공간을 절약할 수 있다\n\n\n이런식으로 가상주소의 page# 구역을 여러개로 쪼개 page table하나로 모든 page에 대응하는 것이 아닌 page table을 계층적으로 구조화해 동적으로 page table이 생성되며 메모리를 절약하는 방식 이 Multi-Level Hierarchical Page Table인 것이다\n다만 이 방식에 장점만 있는 것은 아니다 - 다계층이 될 수록 address translation은 복잡해지기 때문에 수행시간이 오래 걸리는 것 = 공간과 시간이 반비례하는 현상이 여기서도 나타나게 되는 것이다\n\n\n\n따라서 보면\n\n첫 10비트와 page table ptr를 통해 알아낸 1계층 테이블로 이 가상주소의 frame# 을 담고 있는 2계층 테이블의 주소를 알아낸다\n그리고 2계층 테이블로 가서 두번째 10비트를 이용해 frame# 을 알아내게 되는 것\n\n\n\nInverted Page Table §\n\n\n봐봐라\n일단 Inverted Page Table의 개념은 프로세스들마다 존재하는 page table을 하나로 합쳐 OS에 하나만 존재하는 테이블로 만드는 것이다\n이렇게 바꾸는 과정은 약간 데베식의 설명을 곁들이면 하나의 frame# 을 특정하기 위해서는 page# 와 pid를 기본키로 하면 특정할 수 있다\n\n근데 프로세스마다 존재하는 page table은 이미 pid가 PCB에 저장되어있기 때문에 page# 만으로 하나의 frame# 을 특정할 수 있었던 것 인데\n이것을 이제 하나의 테이블로 합치면 pid는 알 수가 없기 때문에 pid 어트리뷰트를 하나 추가하고 거기에 대응되는 frame# 을 저장하는 것 - 저기 그림에서 Chain이라고 표시된 부분이 frame# 이 저장되는 부분이다\n근데 하나의 메모리 공간을 여러 프로세스가 공유하는 경우도 생긴다 - 뭐 공유 메모리라던가, 하나의 프로그램을 여러번 실행시켜 read-only인 코드는 여러개의 프로세스가 공유하는 등\n이것을 지원해주기 위해 chain값으로 다른 프로세스의 페이지가 담긴 frame# 을 넣어서 참조하게 할 수 있다\n\n\n따라서 page# 을 가져와서 테이블에서 자신과 page# 와 pid가 같은 인스턴스를 찾아 chain 어트리뷰트의 값인 frame# 을 받아 address translation 을 하는 것\n이때에는 찾는 과정을 빠르게 하기 위해 hash function을 이용한다 - 파이썬 딕셔너리할때 그 해시임\n\nLookaside Buffer §\n\n얘는 저장장치의 한 종류인데\n보통 하나의 값을 배열에서 찾거나 할때는 처음부터 serial하게 쭉쭉 찾아나가자네?(O(n))\n근데 이걸 사용하면 배열의 모든 원소를 한번에 비교해 원하는 값을 찾는 것 같은 기능을 제공해준다(O(1))\n저장장치의 한 종류이므로 하드웨어이고 이런 강력한 기능을 제공하는 대신 좀 비싸다\naddress translation을 담당하는 lookaside buffer를 **Traslation Lookaside Buffer(TLB)**라 하고 얘는 레지스터의 한 종류이다\n\n얘를 이용해 address translation을 하는 방법 §\n\n\nPage table의 일부분을 저 TLB로 올린다\n이제 가상주소 하나를 translation할 때 page# 을 저기 TLB에 먼저 넣어본다\n만약에 hit(찾음) 이면 바로 frame# 가 나오게 되고 miss(못찾음) 이면 이제 그제서야 page table로 가서 serial하게 찾게 된다 - page table의 일부분만 TLB에 올라갈 수 있으므로 miss될 수 있다\n찾으면 Locality를 활용하기 위해 TLB에 이 page를 넣어놓는다 - 또 사용되면 빠르게 hit시키기 위해 → 그리고 translation을 해 frame# 을 얻어내는 것\n하지만 page table에서 봤더니 얘가 메모리에 없을 수도 있다 - 그러면 page fault handling routine이 실행되어 이놈을 갖고오고 처음부터 다시 하게 되는 것\n\n\n이 방법은 운이 없어서 miss가 뜨면 TLB에 접근하는 시간만큼 손해이긴 하다\n하지만 위에서 말한 Locality를 이용하면 hit의 비율을 90퍼센트 이상으로 끌어올릴 수 있고 이러면 serial하게 비교하는 경우가 거의 없기 때문에 아주 빠르게 address translation이 가능하다\n\nCache §\n\n캐시도 TLB와 비슷하게 one-time search를 지원해주는 저장장치이다\nphysical address를 구하고 나서 원래는 이 주소에 해당하는 메모리 공간으로 가 instruction을 실행하는데\n메모리에 가기 전에 먼저 cache에 가서 이 주소에 대한 instruction이 이미 존재하는지를 찾는다\n그래서 만약에 hit라면 바로 cpu로 올려 실행하게 되는 것 이고\n아니면 그제서야 메인메모리의 해당 주소로 가게 되는 것\n"},"os.spring.2021.cnu.ac.kr/9.-Segmentation":{"title":"9. Segmentation","links":[],"tags":[],"content":"Segmentation §\nSegmentation 의 장단점 §\n\n우선 장점은 모듈 단위로 끊기 때문에 모듈의 protection과 data shraing이 잘된다는 거고\n단점은 이제 external fragmentation이 발생한다는 것과 이것을 최소화하는 것이 힘들다는 것이다\n\nAddress Translation §\n\n\n이전에도 한번 설명한거같은데\n일단 Seg# 를 인덱스로 하고 Seg Table Ptr을 이용해 테이블에 접근하고\n거기서 Base는 Segment의 시작주소가 담겨있으므로 이거에 offset을 더하면 된다\n그리고 Length는 Segment의 길이로 offset은 이것보다 커서는 안된다\nPaging과 Segmentation의 Address Translation 차이점을 잘 기억해라\n\nSegmentation Paging §\n\n\n그래서 보통은 Segmentation과 Paging을 섞은 Segmentation Paging을 사용한다\n얘는 Module단위로 Segment으로 나뉘긴 하는데 이 각각의 Segment들은 일정한 크기의 Page로 나뉘는 것\n따라서 Logical address도 ( Seg# - Page# - offset ) 순서로 구성된다\n\nAddress Translation §\n\n\n보면 이제 일단 Seg Table Ptr를 이용해 테이블에 접근하고 Seg# 를 인덱스로 해서 해당 원소에 접근한다\n근데 여기서 중요한 것은 Seg# 를 인덱스로 한 곳에는 Page Table의 주소가 들어있다. 즉, Segment table은 Process마다 하나씩 갖지만 Page Table은 Segment마다 하나씩 갖게 된다\n그렇게 Page table로 접근해 Page# 를 인덱스로 해서 frame# 을 알아낸다\n그리고 offset앞에 frame# 을 딱 붙여주기만 하면 변환이 마무리되는 것\n\n\n\n따라서 주소와 테이블 인스턴스는 저렇게 구성된다\n아까 말한것처럼 Segment Base에 Page Table의 시작주소가 들어가게 되는 것\n그리고 Page Table도 기존처럼 변경 유무를 저장해 replacement를 쉽게 하는 등의 기능들을 지원하기 위해 Pbit와 Mbit같은 Control Bits가 존재한다\n\nOS Policies for Virtual Memory §\n\n아래의 용어들을 다 알아야된다\n\n\nFetch Policy §\n\nFetch Policy : 언제 페이지를 하드에서부터 갖고올 것이냐\nDemand Paging : 요구가 있을때 갖고옴. 즉, 참조를 할때 그제서야 갖고오는 정책\n\n당연히 메모리는 적게먹는다. 하지만 Page fault가 많이 일어나게 되는 단점이 있다\n\n\nPrepaging : 하드에서 갖고올때 걔만갖고오는게 아니고 다음에 쓸거같은애들도 같이 갖고 옴\n\n예를들면 page# 1 을 가져올때 page# 2도 나중에 쓰게될 확률이 높으므로 얘도 같이 가져오는 것\n메모리는 좀 더 먹지만 page fault가 적게 일어난다는 장점이 있다\n따라서 오늘날 주로 쓰이는 OS정책임\n\n\n\nPlacement Policy §\n\nPlacement Policy : best fit 같은애들. segment를 빈공간 어디에 적재할 것인가\n당연히 paging기법을 사용하면 이런거를 고민할일이 없기 때문에 요즘은 별로 중요하지 않은 정책이다\n\nReplacement Policy §\n\nReplacement Policy : Page fault가 일어났을 때 어떤애를 선택하여 아래로 내려보낼 것인가 - 교체대상 선정\nFrame Lock : 커널같은 중요한 프로세스들은 하드로 내려가면 안되기 때문에 lock을 걸어서 replacement 대상에서 제외하는 것\n\n\n\nReplacement Algorithm 예시 - 이거 시험문제 나온다 - 어떤 알고리즘을 선택했을때 앞에서 배운 Anomaly(이상현상)이 일어나는지 생각해볼것 - 정 모르겠으면 구글링해서 찾아봐라 - 안알려주노 ㅅㅂ\n위에 나열돼있는 숫자들이 요청된 페이지 번호, 그리고 그 아래가 프로세스에 할당된 프레임의 모습이다 - 3개로 일정하고 자신의 프로세스 내에 있는 페이지를 버리므로 local이라고 할 수 있다 - 예시에서는 초기에 적재되는 page fault는 무시하고 page fault가 일어나 replace가 일어나야되는 것만 카운트했다\n\nOPT(Optimal) : Replacement가 일어났을 때 미래의 페이지 사용을 보고 안쓰이거나 가장 나중에 쓰이는 (혹은 가장 최근에 사용된 - 가장 최근에 사용된 놈은 다시 사용할 가능성이 비교적 낮다고 판단)페이지를 내려보낸다 - 당연히 미래의 일을 알아야되므로 구현이 불가능 하며 다른 알고리즘과의 비교를 위해 존재하는 것이다 - 위의 예시에서는 3번의 Fault가 일어나며 제일 좋은 성능을 보여주지만\nLRU(Least Recently Use) : 제일 오래전에 사용된 놈을 버리는 구조\nFIFO(First In First Out) : 이건 뭔지알제? 제일 먼저 들어온놈이 먼저 나가는 구조 - 얘는 LRU랑 헷갈리면 안된다 - LRU는 제일 오래전에 사용된거고 FIFO는 제일 오래전에 메모리로 올라온거임\nCLOCK(Secondary Chance Algorithm) :\n\n\n\n\n\n이게 뭔뜻이냐면 원 밖에 있는 숫자는 frame# 을 의미 하고 저 한칸한칸에는 해당 프레임에 할당된 page# 와 몇번사용(참조)했는지(use)가 저장되어있다\n그리고 저 시계바늘이 룰렛마냥 방출될 애를 가리키는 역할이다\n일단 이러한 구조때문에 CLOCK이라는 이름이 붙어있는 것\n그리고 이 알고리즘이 구동하는 방식때문에 Second Chance Alg라는 이름이 붙었는데\n저 시계바늘이 가리키고있는 놈의 use가 0이 아니면 얘를 방출시키지 않고 다음칸으로 넘어가며 use를 0으로 초기화하기 때문에 한번 더 기회를 준다는 의미에서 저런 이름이 붙은 것이다\n이제 반대로 시계바늘이 가리키고있는놈의 use가 0일 경우에는 그놈을 방출시키고 새로운 페이지를 들이는 것\n따라서 위의 예시에서 frame# 2, 3의 use가 0으로 바뀌고 4번에 새로운 페이지가 들어오며 들어옴과 동시에 한번 사용하기 때문에 use는 1로 되어있는 것이다\n이렇게 되면 use가 0이라는 것은 시계바늘이 한바퀴 돌때동안 사용되지 않았다는 뜻이므로 가장 오래전에 사용된거랑 비슷하다 - LRU와 유사한 효과, 성능을 낸다\n반대로 use가 0이되고 나서 시계바늘이 한바퀴 돌때동안 사용되었다면 다시 use가 올라가므로 시계바늘이 다시 돌아왔을 때 방출되지 않고 다시 0으로 바뀌게 되는것\nPage Buffering : 얘는 뭐냐면\n\n만약 메모리의 일정부분을 free로 유지하기 위해 페이지 한놈을 하드로 내려보냈다고 해보자\n근데 실행되다가 이놈이 다시 필요해진 순간이 왔을때 page table로 가서 Pbit를 보면 당연히 하드로 내려갔으므로 없다고 뜰것이다 이말이야\n근데 만약에 아직 이자리에 다른 프레임이 overwrite되지 않았으면 이놈은 free이긴 해도 데이터는 그대로 남아있을거란말이지\n그래서 바로 IO를 때려 하드에서 갖고오기보다는 데이터가 아직 overwrite되지 않았을 수도 있으므로 free인 저 공간을 다시 조사해 원래의 페이지가 남아있으면 다시 Pbit를 바꾸고 그대로 사용하는 개념이다\n\n\n\nResident Set Management §\n\nResident Set Size : 한개의 프로세스에 몇개의 프레임을 할당할 것 인가\n\nFixed : 고정된 갯수의 프레임을 할당\nVariable : 가변갯수의 프레임을 할당 - 요즘 추세란다\n\n\n\n\n\nWorking Set Model : 걍 단순하다 - 특정 시점에 Window size(할당되는 프레임 최대 갯수)만큼의 최근 페이지 참조(위의 예시에서 한 시점 기준 window size만큼 위에있는만큼의 페이지를 묶어서)를 보고 그거를 집합으로 묶어 그 시점에의 할당 프레임 갯수를 정하는 것\n\n알고리즘이 간단하고 Locality가 반영된다는 장점 이 있음\n하지만 실제로 써보니까 Locality도 제대로 반영 안되고 에 따라 너무 할당되는 갯수도 달라지고 window size를 정하기도 어려운 등의 문제가 있더라\n\n\n\n\n\nVariable-Interval Sampled Working Set(VSWS) - 얘는 이제 page fault rate의 상한선과 하한선을 정해놓고 할당갯수를 변화시키면서 rate가 너무 높으면 할당갯수를 늘리고 rate가 하한선보다 떨어져서 할당갯수가 너무 많으면 줄이고 하는식으로 유동적으로 할당갯수를 줄이는 방식이다\nReplacement Scope : 하드로 내려보낼 페이지를 정하는 범위\n\nGlobal : 현재 프로세스가 아닌 다른 프로세스의 페이지를 내려보냄 - 속도를 위해 요즘은 얘를 사용한댄다\nLocal : 현재 프로세스의 페이지를 내려보냄\n\n\n\nCleaning Policy §\n\nCleaning Policy : 프로세스가 종료되고 프레임들을 비우는 것에 대한 정책\n메모리에 있는 페이지가 변경되었을 경우에 변경될때마다 하드에 있는 페이지를 바꿔주기(Demand Cleaning)보다는\n메모리에 있는놈이 하드로 내려갈때 변경사항을 한번에 업데이트해주는 방법(Precleaning)을 이용한댄다\n\nLoad Control §\n\nLoad Control : 프로세스를 메모리에 올려주는 Loader와 관련된 정책 - 몇개의 프로세스를 올려 multiprogramming level을 어떻게 가져가 최적의 cpu utilization을 낼 것인가(Thrasing을 내지 않을 것인가) - 위에서의 Resident Set Management와도 연결되는 내용\n여기서 multiprogramming level이 너무 높아 page fault가 너무 많이 일어나 프로세스를 내쫒을때는 다음과 같은 룰들을 적용한다(이게 전부는 아님 - 참고)\n\n우선순위가 낮은놈\nfault를 많이 일으키는 놈\n마지막으로 실행된놈\n가장 적은 프레임을 가지고있거나\n가장 사이즈가 큰 프로세스\n\n\n"}}